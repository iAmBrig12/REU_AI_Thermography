{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "spectrum_train = pd.read_excel('spectrum_train.xlsx')\n",
    "spectrum_test = pd.read_excel('spectrum_valid.xlsx')\n",
    "temp_train = pd.read_excel('temp_train.xlsx')\n",
    "temp_test = pd.read_excel('temp_valid.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_train_scaled = spectrum_train.multiply(10**12)\n",
    "spectrum_test_scaled = spectrum_test.multiply(10**12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the supported device\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "# convert a df to tensor to be used in pytorch\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = df_to_tensor(temp_train)\n",
    "output_data = df_to_tensor(spectrum_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[350.6424, 357.4240, 338.0000,  ..., 267.9975, 252.9999, 238.0000],\n",
       "        [352.1875, 360.3629, 342.0451,  ..., 269.5426, 252.9999, 236.4549],\n",
       "        [350.6424, 357.4240, 338.0000,  ..., 267.9975, 252.9999, 238.0000],\n",
       "        ...,\n",
       "        [597.3622, 585.6775, 574.4026,  ..., 493.7609, 505.0429, 515.4084],\n",
       "        [595.8171, 582.7385, 570.3576,  ..., 492.2158, 505.0429, 516.9536],\n",
       "        [601.9975, 594.4943, 586.5379,  ..., 498.3961, 505.0429, 510.7732]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1119,  0.0821,  0.0643,  ...,  0.3437,  0.3360,  0.3290],\n",
       "        [ 0.1240,  0.0904,  0.0701,  ...,  0.3269,  0.3197,  0.3131],\n",
       "        [ 0.1119,  0.0821,  0.0643,  ...,  0.3437,  0.3360,  0.3290],\n",
       "        ...,\n",
       "        [10.8134, 10.6301, 10.5865,  ..., 21.8142, 20.7956, 19.8604],\n",
       "        [10.6221, 10.5147, 10.5277,  ..., 22.0530, 21.0220, 20.0754],\n",
       "        [11.4288, 11.0081, 10.7881,  ..., 21.1053, 20.1236, 19.2221]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.fc6 = nn.Linear(128, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 11\n",
    "output_size = 66\n",
    "model = Net(input_size=input_size, output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)  # Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 1.132634\n",
      "Epoch 2/15, Loss: 0.889480\n",
      "Epoch 3/15, Loss: 0.440525\n",
      "Epoch 4/15, Loss: 0.195986\n",
      "Epoch 5/15, Loss: 0.206026\n",
      "Epoch 6/15, Loss: 0.263091\n",
      "Epoch 7/15, Loss: 0.285002\n",
      "Epoch 8/15, Loss: 0.292297\n",
      "Epoch 9/15, Loss: 0.307327\n",
      "Epoch 10/15, Loss: 0.319834\n",
      "Epoch 11/15, Loss: 0.335866\n",
      "Epoch 12/15, Loss: 0.356722\n",
      "Epoch 13/15, Loss: 0.390587\n",
      "Epoch 14/15, Loss: 0.396699\n",
      "Epoch 15/15, Loss: 0.416665\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "batch_size = 1\n",
    "num_batches = len(input_data) // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in range(num_batches):\n",
    "        start = batch * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        inputs = input_data[start:end]\n",
    "        targets = output_data[start:end]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss for this epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(df_to_tensor(temp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>...</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.904681</td>\n",
       "      <td>2.887842</td>\n",
       "      <td>3.061507</td>\n",
       "      <td>2.779536</td>\n",
       "      <td>2.297568</td>\n",
       "      <td>3.373097</td>\n",
       "      <td>3.314639</td>\n",
       "      <td>3.022262</td>\n",
       "      <td>3.131035</td>\n",
       "      <td>3.154243</td>\n",
       "      <td>...</td>\n",
       "      <td>7.350365</td>\n",
       "      <td>7.288757</td>\n",
       "      <td>7.283387</td>\n",
       "      <td>7.151779</td>\n",
       "      <td>7.005003</td>\n",
       "      <td>6.900735</td>\n",
       "      <td>7.020926</td>\n",
       "      <td>7.104105</td>\n",
       "      <td>6.962034</td>\n",
       "      <td>6.268903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.816605</td>\n",
       "      <td>2.753494</td>\n",
       "      <td>2.972967</td>\n",
       "      <td>2.677421</td>\n",
       "      <td>2.132849</td>\n",
       "      <td>3.243225</td>\n",
       "      <td>3.110487</td>\n",
       "      <td>2.825399</td>\n",
       "      <td>2.980277</td>\n",
       "      <td>2.969292</td>\n",
       "      <td>...</td>\n",
       "      <td>7.124895</td>\n",
       "      <td>7.065416</td>\n",
       "      <td>7.018618</td>\n",
       "      <td>6.852043</td>\n",
       "      <td>6.730331</td>\n",
       "      <td>6.591538</td>\n",
       "      <td>6.762316</td>\n",
       "      <td>6.850696</td>\n",
       "      <td>6.760643</td>\n",
       "      <td>6.042833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.904681</td>\n",
       "      <td>2.887842</td>\n",
       "      <td>3.061507</td>\n",
       "      <td>2.779536</td>\n",
       "      <td>2.297568</td>\n",
       "      <td>3.373097</td>\n",
       "      <td>3.314639</td>\n",
       "      <td>3.022262</td>\n",
       "      <td>3.131035</td>\n",
       "      <td>3.154243</td>\n",
       "      <td>...</td>\n",
       "      <td>7.350365</td>\n",
       "      <td>7.288757</td>\n",
       "      <td>7.283387</td>\n",
       "      <td>7.151779</td>\n",
       "      <td>7.005003</td>\n",
       "      <td>6.900735</td>\n",
       "      <td>7.020926</td>\n",
       "      <td>7.104105</td>\n",
       "      <td>6.962034</td>\n",
       "      <td>6.268903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.456863</td>\n",
       "      <td>2.284718</td>\n",
       "      <td>2.646086</td>\n",
       "      <td>2.371874</td>\n",
       "      <td>1.765545</td>\n",
       "      <td>2.959602</td>\n",
       "      <td>2.580714</td>\n",
       "      <td>2.404639</td>\n",
       "      <td>2.631273</td>\n",
       "      <td>2.496146</td>\n",
       "      <td>...</td>\n",
       "      <td>6.393233</td>\n",
       "      <td>6.290544</td>\n",
       "      <td>6.251361</td>\n",
       "      <td>6.015221</td>\n",
       "      <td>5.978204</td>\n",
       "      <td>5.774881</td>\n",
       "      <td>5.918357</td>\n",
       "      <td>6.056137</td>\n",
       "      <td>6.088280</td>\n",
       "      <td>5.330615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.839986</td>\n",
       "      <td>2.802385</td>\n",
       "      <td>2.963780</td>\n",
       "      <td>2.716825</td>\n",
       "      <td>2.207425</td>\n",
       "      <td>3.284668</td>\n",
       "      <td>3.225956</td>\n",
       "      <td>2.946444</td>\n",
       "      <td>3.034296</td>\n",
       "      <td>3.064332</td>\n",
       "      <td>...</td>\n",
       "      <td>7.216177</td>\n",
       "      <td>7.114171</td>\n",
       "      <td>7.112974</td>\n",
       "      <td>6.985060</td>\n",
       "      <td>6.839896</td>\n",
       "      <td>6.741595</td>\n",
       "      <td>6.834182</td>\n",
       "      <td>6.938564</td>\n",
       "      <td>6.791967</td>\n",
       "      <td>6.126687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  \\\n",
       "0  2.904681  2.887842  3.061507  2.779536  2.297568  3.373097  3.314639   \n",
       "1  2.816605  2.753494  2.972967  2.677421  2.132849  3.243225  3.110487   \n",
       "2  2.904681  2.887842  3.061507  2.779536  2.297568  3.373097  3.314639   \n",
       "3  2.456863  2.284718  2.646086  2.371874  1.765545  2.959602  2.580714   \n",
       "4  2.839986  2.802385  2.963780  2.716825  2.207425  3.284668  3.225956   \n",
       "\n",
       "   0.000005  0.000005  0.000005  ...  0.000008  0.000008  0.000008  0.000008  \\\n",
       "0  3.022262  3.131035  3.154243  ...  7.350365  7.288757  7.283387  7.151779   \n",
       "1  2.825399  2.980277  2.969292  ...  7.124895  7.065416  7.018618  6.852043   \n",
       "2  3.022262  3.131035  3.154243  ...  7.350365  7.288757  7.283387  7.151779   \n",
       "3  2.404639  2.631273  2.496146  ...  6.393233  6.290544  6.251361  6.015221   \n",
       "4  2.946444  3.034296  3.064332  ...  7.216177  7.114171  7.112974  6.985060   \n",
       "\n",
       "   0.000008  0.000008  0.000008  0.000008  0.000008  0.000008  \n",
       "0  7.005003  6.900735  7.020926  7.104105  6.962034  6.268903  \n",
       "1  6.730331  6.591538  6.762316  6.850696  6.760643  6.042833  \n",
       "2  7.005003  6.900735  7.020926  7.104105  6.962034  6.268903  \n",
       "3  5.978204  5.774881  5.918357  6.056137  6.088280  5.330615  \n",
       "4  6.839896  6.741595  6.834182  6.938564  6.791967  6.126687  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(predictions.detach().numpy(), columns=spectrum_test.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>...</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.373538</td>\n",
       "      <td>2.602481</td>\n",
       "      <td>2.775814</td>\n",
       "      <td>2.935397</td>\n",
       "      <td>3.074856</td>\n",
       "      <td>3.220465</td>\n",
       "      <td>3.363583</td>\n",
       "      <td>3.505908</td>\n",
       "      <td>3.647634</td>\n",
       "      <td>3.790090</td>\n",
       "      <td>...</td>\n",
       "      <td>10.069020</td>\n",
       "      <td>10.146292</td>\n",
       "      <td>10.208057</td>\n",
       "      <td>10.243674</td>\n",
       "      <td>10.246583</td>\n",
       "      <td>10.192531</td>\n",
       "      <td>10.036903</td>\n",
       "      <td>9.737349</td>\n",
       "      <td>9.326093</td>\n",
       "      <td>8.947765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.027413</td>\n",
       "      <td>2.150030</td>\n",
       "      <td>2.250785</td>\n",
       "      <td>2.362463</td>\n",
       "      <td>2.467873</td>\n",
       "      <td>2.581041</td>\n",
       "      <td>2.694600</td>\n",
       "      <td>2.809533</td>\n",
       "      <td>2.925638</td>\n",
       "      <td>3.043688</td>\n",
       "      <td>...</td>\n",
       "      <td>8.794491</td>\n",
       "      <td>8.871859</td>\n",
       "      <td>8.934365</td>\n",
       "      <td>8.973221</td>\n",
       "      <td>8.983096</td>\n",
       "      <td>8.942860</td>\n",
       "      <td>8.813263</td>\n",
       "      <td>8.556884</td>\n",
       "      <td>8.201778</td>\n",
       "      <td>7.875021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.470590</td>\n",
       "      <td>2.726463</td>\n",
       "      <td>2.921211</td>\n",
       "      <td>3.095970</td>\n",
       "      <td>3.246416</td>\n",
       "      <td>3.402639</td>\n",
       "      <td>3.555543</td>\n",
       "      <td>3.706972</td>\n",
       "      <td>3.857192</td>\n",
       "      <td>4.007671</td>\n",
       "      <td>...</td>\n",
       "      <td>10.460966</td>\n",
       "      <td>10.538142</td>\n",
       "      <td>10.599540</td>\n",
       "      <td>10.633985</td>\n",
       "      <td>10.634567</td>\n",
       "      <td>10.576088</td>\n",
       "      <td>10.412293</td>\n",
       "      <td>10.099323</td>\n",
       "      <td>9.670691</td>\n",
       "      <td>9.276407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.950271</td>\n",
       "      <td>2.046041</td>\n",
       "      <td>2.131383</td>\n",
       "      <td>2.233903</td>\n",
       "      <td>2.333012</td>\n",
       "      <td>2.440313</td>\n",
       "      <td>2.548641</td>\n",
       "      <td>2.658761</td>\n",
       "      <td>2.770347</td>\n",
       "      <td>2.884035</td>\n",
       "      <td>...</td>\n",
       "      <td>8.542764</td>\n",
       "      <td>8.620148</td>\n",
       "      <td>8.682729</td>\n",
       "      <td>8.722118</td>\n",
       "      <td>8.733251</td>\n",
       "      <td>8.695631</td>\n",
       "      <td>8.571070</td>\n",
       "      <td>8.323129</td>\n",
       "      <td>7.979041</td>\n",
       "      <td>7.662406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.523524</td>\n",
       "      <td>2.771409</td>\n",
       "      <td>2.957469</td>\n",
       "      <td>3.126776</td>\n",
       "      <td>3.273742</td>\n",
       "      <td>3.426844</td>\n",
       "      <td>3.576945</td>\n",
       "      <td>3.725913</td>\n",
       "      <td>3.874010</td>\n",
       "      <td>4.022686</td>\n",
       "      <td>...</td>\n",
       "      <td>10.456130</td>\n",
       "      <td>10.533535</td>\n",
       "      <td>10.595041</td>\n",
       "      <td>10.629530</td>\n",
       "      <td>10.630143</td>\n",
       "      <td>10.571716</td>\n",
       "      <td>10.408014</td>\n",
       "      <td>10.095198</td>\n",
       "      <td>9.666764</td>\n",
       "      <td>9.272662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  \\\n",
       "0  2.373538  2.602481  2.775814  2.935397  3.074856  3.220465  3.363583   \n",
       "1  2.027413  2.150030  2.250785  2.362463  2.467873  2.581041  2.694600   \n",
       "2  2.470590  2.726463  2.921211  3.095970  3.246416  3.402639  3.555543   \n",
       "3  1.950271  2.046041  2.131383  2.233903  2.333012  2.440313  2.548641   \n",
       "4  2.523524  2.771409  2.957469  3.126776  3.273742  3.426844  3.576945   \n",
       "\n",
       "   0.000005  0.000005  0.000005  ...   0.000008   0.000008   0.000008  \\\n",
       "0  3.505908  3.647634  3.790090  ...  10.069020  10.146292  10.208057   \n",
       "1  2.809533  2.925638  3.043688  ...   8.794491   8.871859   8.934365   \n",
       "2  3.706972  3.857192  4.007671  ...  10.460966  10.538142  10.599540   \n",
       "3  2.658761  2.770347  2.884035  ...   8.542764   8.620148   8.682729   \n",
       "4  3.725913  3.874010  4.022686  ...  10.456130  10.533535  10.595041   \n",
       "\n",
       "    0.000008   0.000008   0.000008   0.000008   0.000008  0.000008  0.000008  \n",
       "0  10.243674  10.246583  10.192531  10.036903   9.737349  9.326093  8.947765  \n",
       "1   8.973221   8.983096   8.942860   8.813263   8.556884  8.201778  7.875021  \n",
       "2  10.633985  10.634567  10.576088  10.412293  10.099323  9.670691  9.276407  \n",
       "3   8.722118   8.733251   8.695631   8.571070   8.323129  7.979041  7.662406  \n",
       "4  10.629530  10.630143  10.571716  10.408014  10.095198  9.666764  9.272662  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrum_test_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
