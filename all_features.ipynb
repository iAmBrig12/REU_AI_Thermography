{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "spectrum_train = pd.read_excel('spectrum_train.xlsx')\n",
    "spectrum_test = pd.read_excel('spectrum_valid.xlsx')\n",
    "temp_train = pd.read_excel('temp_train.xlsx')\n",
    "temp_test = pd.read_excel('temp_valid.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_train_scaled = spectrum_train.multiply(10**12)\n",
    "spectrum_test_scaled = spectrum_test.multiply(10**12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the supported device\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "# convert a df to tensor to be used in pytorch\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = df_to_tensor(temp_train)\n",
    "output_data = df_to_tensor(spectrum_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[350.6424, 357.4240, 338.0000,  ..., 267.9975, 252.9999, 238.0000],\n",
       "        [352.1875, 360.3629, 342.0451,  ..., 269.5426, 252.9999, 236.4549],\n",
       "        [350.6424, 357.4240, 338.0000,  ..., 267.9975, 252.9999, 238.0000],\n",
       "        ...,\n",
       "        [597.3622, 585.6775, 574.4026,  ..., 493.7609, 505.0429, 515.4084],\n",
       "        [595.8171, 582.7385, 570.3576,  ..., 492.2158, 505.0429, 516.9536],\n",
       "        [601.9975, 594.4943, 586.5379,  ..., 498.3961, 505.0429, 510.7732]])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1119,  0.0821,  0.0643,  ...,  0.3437,  0.3360,  0.3290],\n",
       "        [ 0.1240,  0.0904,  0.0701,  ...,  0.3269,  0.3197,  0.3131],\n",
       "        [ 0.1119,  0.0821,  0.0643,  ...,  0.3437,  0.3360,  0.3290],\n",
       "        ...,\n",
       "        [10.8134, 10.6301, 10.5865,  ..., 21.8142, 20.7956, 19.8604],\n",
       "        [10.6221, 10.5147, 10.5277,  ..., 22.0530, 21.0220, 20.0754],\n",
       "        [11.4288, 11.0081, 10.7881,  ..., 21.1053, 20.1236, 19.2221]])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.fc6 = nn.Linear(128, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 11\n",
    "output_size = 66\n",
    "model = Net(input_size=input_size, output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)  # Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 1.227836\n",
      "Epoch 2/15, Loss: 1.090207\n",
      "Epoch 3/15, Loss: 0.696722\n",
      "Epoch 4/15, Loss: 0.454796\n",
      "Epoch 5/15, Loss: 0.273489\n",
      "Epoch 6/15, Loss: 0.237316\n",
      "Epoch 7/15, Loss: 0.241296\n",
      "Epoch 8/15, Loss: 0.252911\n",
      "Epoch 9/15, Loss: 0.257222\n",
      "Epoch 10/15, Loss: 0.254695\n",
      "Epoch 11/15, Loss: 0.261782\n",
      "Epoch 12/15, Loss: 0.263810\n",
      "Epoch 13/15, Loss: 0.251714\n",
      "Epoch 14/15, Loss: 0.279464\n",
      "Epoch 15/15, Loss: 0.279204\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "batch_size = 1\n",
    "num_batches = len(input_data) // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in range(num_batches):\n",
    "        start = batch * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        inputs = input_data[start:end]\n",
    "        targets = output_data[start:end]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss for this epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(df_to_tensor(temp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>...</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.790601</td>\n",
       "      <td>3.734772</td>\n",
       "      <td>3.551773</td>\n",
       "      <td>3.518033</td>\n",
       "      <td>3.052246</td>\n",
       "      <td>3.713205</td>\n",
       "      <td>3.674874</td>\n",
       "      <td>3.340815</td>\n",
       "      <td>3.953950</td>\n",
       "      <td>3.784270</td>\n",
       "      <td>...</td>\n",
       "      <td>7.757231</td>\n",
       "      <td>7.541261</td>\n",
       "      <td>7.631447</td>\n",
       "      <td>8.034568</td>\n",
       "      <td>7.899240</td>\n",
       "      <td>8.103604</td>\n",
       "      <td>7.596833</td>\n",
       "      <td>7.521339</td>\n",
       "      <td>6.925596</td>\n",
       "      <td>7.045845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.660755</td>\n",
       "      <td>3.675390</td>\n",
       "      <td>3.459227</td>\n",
       "      <td>3.438999</td>\n",
       "      <td>2.937411</td>\n",
       "      <td>3.658012</td>\n",
       "      <td>3.575735</td>\n",
       "      <td>3.212343</td>\n",
       "      <td>3.859975</td>\n",
       "      <td>3.660512</td>\n",
       "      <td>...</td>\n",
       "      <td>7.546351</td>\n",
       "      <td>7.315151</td>\n",
       "      <td>7.375307</td>\n",
       "      <td>7.875371</td>\n",
       "      <td>7.722021</td>\n",
       "      <td>7.908733</td>\n",
       "      <td>7.400218</td>\n",
       "      <td>7.344554</td>\n",
       "      <td>6.724810</td>\n",
       "      <td>6.910841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.790601</td>\n",
       "      <td>3.734772</td>\n",
       "      <td>3.551773</td>\n",
       "      <td>3.518033</td>\n",
       "      <td>3.052246</td>\n",
       "      <td>3.713205</td>\n",
       "      <td>3.674874</td>\n",
       "      <td>3.340815</td>\n",
       "      <td>3.953950</td>\n",
       "      <td>3.784270</td>\n",
       "      <td>...</td>\n",
       "      <td>7.757231</td>\n",
       "      <td>7.541261</td>\n",
       "      <td>7.631447</td>\n",
       "      <td>8.034568</td>\n",
       "      <td>7.899240</td>\n",
       "      <td>8.103604</td>\n",
       "      <td>7.596833</td>\n",
       "      <td>7.521339</td>\n",
       "      <td>6.925596</td>\n",
       "      <td>7.045845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.341000</td>\n",
       "      <td>3.510140</td>\n",
       "      <td>3.161989</td>\n",
       "      <td>3.232858</td>\n",
       "      <td>2.632300</td>\n",
       "      <td>3.531012</td>\n",
       "      <td>3.296155</td>\n",
       "      <td>2.866755</td>\n",
       "      <td>3.551401</td>\n",
       "      <td>3.293714</td>\n",
       "      <td>...</td>\n",
       "      <td>6.968811</td>\n",
       "      <td>6.701468</td>\n",
       "      <td>6.693804</td>\n",
       "      <td>7.436040</td>\n",
       "      <td>7.243237</td>\n",
       "      <td>7.320110</td>\n",
       "      <td>6.845436</td>\n",
       "      <td>6.842308</td>\n",
       "      <td>6.210735</td>\n",
       "      <td>6.525501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.718299</td>\n",
       "      <td>3.626016</td>\n",
       "      <td>3.467902</td>\n",
       "      <td>3.460244</td>\n",
       "      <td>3.005140</td>\n",
       "      <td>3.585514</td>\n",
       "      <td>3.559272</td>\n",
       "      <td>3.253601</td>\n",
       "      <td>3.837587</td>\n",
       "      <td>3.687777</td>\n",
       "      <td>...</td>\n",
       "      <td>7.566105</td>\n",
       "      <td>7.376872</td>\n",
       "      <td>7.497670</td>\n",
       "      <td>7.827976</td>\n",
       "      <td>7.699324</td>\n",
       "      <td>7.931044</td>\n",
       "      <td>7.439087</td>\n",
       "      <td>7.325128</td>\n",
       "      <td>6.785043</td>\n",
       "      <td>6.879838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  \\\n",
       "0  2.790601  3.734772  3.551773  3.518033  3.052246  3.713205  3.674874   \n",
       "1  2.660755  3.675390  3.459227  3.438999  2.937411  3.658012  3.575735   \n",
       "2  2.790601  3.734772  3.551773  3.518033  3.052246  3.713205  3.674874   \n",
       "3  2.341000  3.510140  3.161989  3.232858  2.632300  3.531012  3.296155   \n",
       "4  2.718299  3.626016  3.467902  3.460244  3.005140  3.585514  3.559272   \n",
       "\n",
       "   0.000005  0.000005  0.000005  ...  0.000008  0.000008  0.000008  0.000008  \\\n",
       "0  3.340815  3.953950  3.784270  ...  7.757231  7.541261  7.631447  8.034568   \n",
       "1  3.212343  3.859975  3.660512  ...  7.546351  7.315151  7.375307  7.875371   \n",
       "2  3.340815  3.953950  3.784270  ...  7.757231  7.541261  7.631447  8.034568   \n",
       "3  2.866755  3.551401  3.293714  ...  6.968811  6.701468  6.693804  7.436040   \n",
       "4  3.253601  3.837587  3.687777  ...  7.566105  7.376872  7.497670  7.827976   \n",
       "\n",
       "   0.000008  0.000008  0.000008  0.000008  0.000008  0.000008  \n",
       "0  7.899240  8.103604  7.596833  7.521339  6.925596  7.045845  \n",
       "1  7.722021  7.908733  7.400218  7.344554  6.724810  6.910841  \n",
       "2  7.899240  8.103604  7.596833  7.521339  6.925596  7.045845  \n",
       "3  7.243237  7.320110  6.845436  6.842308  6.210735  6.525501  \n",
       "4  7.699324  7.931044  7.439087  7.325128  6.785043  6.879838  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(predictions.detach().numpy(), columns=spectrum_test.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>...</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.373538</td>\n",
       "      <td>2.602481</td>\n",
       "      <td>2.775814</td>\n",
       "      <td>2.935397</td>\n",
       "      <td>3.074856</td>\n",
       "      <td>3.220465</td>\n",
       "      <td>3.363583</td>\n",
       "      <td>3.505908</td>\n",
       "      <td>3.647634</td>\n",
       "      <td>3.790090</td>\n",
       "      <td>...</td>\n",
       "      <td>10.069020</td>\n",
       "      <td>10.146292</td>\n",
       "      <td>10.208057</td>\n",
       "      <td>10.243674</td>\n",
       "      <td>10.246583</td>\n",
       "      <td>10.192531</td>\n",
       "      <td>10.036903</td>\n",
       "      <td>9.737349</td>\n",
       "      <td>9.326093</td>\n",
       "      <td>8.947765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.027413</td>\n",
       "      <td>2.150030</td>\n",
       "      <td>2.250785</td>\n",
       "      <td>2.362463</td>\n",
       "      <td>2.467873</td>\n",
       "      <td>2.581041</td>\n",
       "      <td>2.694600</td>\n",
       "      <td>2.809533</td>\n",
       "      <td>2.925638</td>\n",
       "      <td>3.043688</td>\n",
       "      <td>...</td>\n",
       "      <td>8.794491</td>\n",
       "      <td>8.871859</td>\n",
       "      <td>8.934365</td>\n",
       "      <td>8.973221</td>\n",
       "      <td>8.983096</td>\n",
       "      <td>8.942860</td>\n",
       "      <td>8.813263</td>\n",
       "      <td>8.556884</td>\n",
       "      <td>8.201778</td>\n",
       "      <td>7.875021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.470590</td>\n",
       "      <td>2.726463</td>\n",
       "      <td>2.921211</td>\n",
       "      <td>3.095970</td>\n",
       "      <td>3.246416</td>\n",
       "      <td>3.402639</td>\n",
       "      <td>3.555543</td>\n",
       "      <td>3.706972</td>\n",
       "      <td>3.857192</td>\n",
       "      <td>4.007671</td>\n",
       "      <td>...</td>\n",
       "      <td>10.460966</td>\n",
       "      <td>10.538142</td>\n",
       "      <td>10.599540</td>\n",
       "      <td>10.633985</td>\n",
       "      <td>10.634567</td>\n",
       "      <td>10.576088</td>\n",
       "      <td>10.412293</td>\n",
       "      <td>10.099323</td>\n",
       "      <td>9.670691</td>\n",
       "      <td>9.276407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.950271</td>\n",
       "      <td>2.046041</td>\n",
       "      <td>2.131383</td>\n",
       "      <td>2.233903</td>\n",
       "      <td>2.333012</td>\n",
       "      <td>2.440313</td>\n",
       "      <td>2.548641</td>\n",
       "      <td>2.658761</td>\n",
       "      <td>2.770347</td>\n",
       "      <td>2.884035</td>\n",
       "      <td>...</td>\n",
       "      <td>8.542764</td>\n",
       "      <td>8.620148</td>\n",
       "      <td>8.682729</td>\n",
       "      <td>8.722118</td>\n",
       "      <td>8.733251</td>\n",
       "      <td>8.695631</td>\n",
       "      <td>8.571070</td>\n",
       "      <td>8.323129</td>\n",
       "      <td>7.979041</td>\n",
       "      <td>7.662406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.523524</td>\n",
       "      <td>2.771409</td>\n",
       "      <td>2.957469</td>\n",
       "      <td>3.126776</td>\n",
       "      <td>3.273742</td>\n",
       "      <td>3.426844</td>\n",
       "      <td>3.576945</td>\n",
       "      <td>3.725913</td>\n",
       "      <td>3.874010</td>\n",
       "      <td>4.022686</td>\n",
       "      <td>...</td>\n",
       "      <td>10.456130</td>\n",
       "      <td>10.533535</td>\n",
       "      <td>10.595041</td>\n",
       "      <td>10.629530</td>\n",
       "      <td>10.630143</td>\n",
       "      <td>10.571716</td>\n",
       "      <td>10.408014</td>\n",
       "      <td>10.095198</td>\n",
       "      <td>9.666764</td>\n",
       "      <td>9.272662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  \\\n",
       "0  2.373538  2.602481  2.775814  2.935397  3.074856  3.220465  3.363583   \n",
       "1  2.027413  2.150030  2.250785  2.362463  2.467873  2.581041  2.694600   \n",
       "2  2.470590  2.726463  2.921211  3.095970  3.246416  3.402639  3.555543   \n",
       "3  1.950271  2.046041  2.131383  2.233903  2.333012  2.440313  2.548641   \n",
       "4  2.523524  2.771409  2.957469  3.126776  3.273742  3.426844  3.576945   \n",
       "\n",
       "   0.000005  0.000005  0.000005  ...   0.000008   0.000008   0.000008  \\\n",
       "0  3.505908  3.647634  3.790090  ...  10.069020  10.146292  10.208057   \n",
       "1  2.809533  2.925638  3.043688  ...   8.794491   8.871859   8.934365   \n",
       "2  3.706972  3.857192  4.007671  ...  10.460966  10.538142  10.599540   \n",
       "3  2.658761  2.770347  2.884035  ...   8.542764   8.620148   8.682729   \n",
       "4  3.725913  3.874010  4.022686  ...  10.456130  10.533535  10.595041   \n",
       "\n",
       "    0.000008   0.000008   0.000008   0.000008   0.000008  0.000008  0.000008  \n",
       "0  10.243674  10.246583  10.192531  10.036903   9.737349  9.326093  8.947765  \n",
       "1   8.973221   8.983096   8.942860   8.813263   8.556884  8.201778  7.875021  \n",
       "2  10.633985  10.634567  10.576088  10.412293  10.099323  9.670691  9.276407  \n",
       "3   8.722118   8.733251   8.695631   8.571070   8.323129  7.979041  7.662406  \n",
       "4  10.629530  10.630143  10.571716  10.408014  10.095198  9.666764  9.272662  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrum_test_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
