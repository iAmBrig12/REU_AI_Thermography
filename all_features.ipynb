{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "spectrum_train = pd.read_excel('spectrum_train.xlsx')\n",
    "spectrum_test = pd.read_excel('spectrum_valid.xlsx')\n",
    "temp_train = pd.read_excel('temp_train.xlsx')\n",
    "temp_test = pd.read_excel('temp_valid.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_train_scaled = spectrum_train.multiply(10**12)\n",
    "spectrum_test_scaled = spectrum_test.multiply(10**12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the supported device\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "# convert a df to tensor to be used in pytorch\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = df_to_tensor(temp_train)\n",
    "output_data = df_to_tensor(spectrum_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[350.6424, 357.4240, 338.0000,  ..., 267.9975, 252.9999, 238.0000],\n",
       "        [352.1875, 360.3629, 342.0451,  ..., 269.5426, 252.9999, 236.4549],\n",
       "        [350.6424, 357.4240, 338.0000,  ..., 267.9975, 252.9999, 238.0000],\n",
       "        ...,\n",
       "        [597.3622, 585.6775, 574.4026,  ..., 493.7609, 505.0429, 515.4084],\n",
       "        [595.8171, 582.7385, 570.3576,  ..., 492.2158, 505.0429, 516.9536],\n",
       "        [601.9975, 594.4943, 586.5379,  ..., 498.3961, 505.0429, 510.7732]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1119,  0.0821,  0.0643,  ...,  0.3437,  0.3360,  0.3290],\n",
       "        [ 0.1240,  0.0904,  0.0701,  ...,  0.3269,  0.3197,  0.3131],\n",
       "        [ 0.1119,  0.0821,  0.0643,  ...,  0.3437,  0.3360,  0.3290],\n",
       "        ...,\n",
       "        [10.8134, 10.6301, 10.5865,  ..., 21.8142, 20.7956, 19.8604],\n",
       "        [10.6221, 10.5147, 10.5277,  ..., 22.0530, 21.0220, 20.0754],\n",
       "        [11.4288, 11.0081, 10.7881,  ..., 21.1053, 20.1236, 19.2221]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 128)\n",
    "        self.fc5 = nn.Linear(128, 128)\n",
    "        self.fc6 = nn.Linear(128, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 11\n",
    "output_size = 66\n",
    "model = Net(input_size=input_size, output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 6.383619\n",
      "Epoch 20/100, Loss: 8.144225\n",
      "Epoch 30/100, Loss: 11.092988\n",
      "Epoch 40/100, Loss: 19.777275\n",
      "Epoch 50/100, Loss: 22.170179\n",
      "Epoch 60/100, Loss: 21.935501\n",
      "Epoch 70/100, Loss: 21.264130\n",
      "Epoch 80/100, Loss: 20.477892\n",
      "Epoch 90/100, Loss: 20.263536\n",
      "Epoch 100/100, Loss: 20.305302\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "num_batches = len(input_data) // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in range(num_batches):\n",
    "        start = batch * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        inputs = input_data[start:end]\n",
    "        targets = output_data[start:end]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss for this epoch\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(df_to_tensor(temp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>...</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.957020</td>\n",
       "      <td>0.823448</td>\n",
       "      <td>0.706688</td>\n",
       "      <td>0.745883</td>\n",
       "      <td>0.885037</td>\n",
       "      <td>0.672862</td>\n",
       "      <td>0.815175</td>\n",
       "      <td>0.802330</td>\n",
       "      <td>0.905220</td>\n",
       "      <td>0.869727</td>\n",
       "      <td>...</td>\n",
       "      <td>1.945669</td>\n",
       "      <td>1.855932</td>\n",
       "      <td>1.922320</td>\n",
       "      <td>1.913216</td>\n",
       "      <td>2.048449</td>\n",
       "      <td>1.995728</td>\n",
       "      <td>2.076719</td>\n",
       "      <td>2.051072</td>\n",
       "      <td>1.843851</td>\n",
       "      <td>1.887731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.840085</td>\n",
       "      <td>0.644758</td>\n",
       "      <td>0.701988</td>\n",
       "      <td>0.644552</td>\n",
       "      <td>0.779771</td>\n",
       "      <td>0.532637</td>\n",
       "      <td>0.597444</td>\n",
       "      <td>0.697043</td>\n",
       "      <td>0.792870</td>\n",
       "      <td>0.687446</td>\n",
       "      <td>...</td>\n",
       "      <td>1.541514</td>\n",
       "      <td>1.558240</td>\n",
       "      <td>1.475706</td>\n",
       "      <td>1.540913</td>\n",
       "      <td>1.641199</td>\n",
       "      <td>1.627997</td>\n",
       "      <td>1.688710</td>\n",
       "      <td>1.685466</td>\n",
       "      <td>1.564429</td>\n",
       "      <td>1.575002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.957020</td>\n",
       "      <td>0.823448</td>\n",
       "      <td>0.706688</td>\n",
       "      <td>0.745883</td>\n",
       "      <td>0.885037</td>\n",
       "      <td>0.672862</td>\n",
       "      <td>0.815175</td>\n",
       "      <td>0.802330</td>\n",
       "      <td>0.905220</td>\n",
       "      <td>0.869727</td>\n",
       "      <td>...</td>\n",
       "      <td>1.945669</td>\n",
       "      <td>1.855932</td>\n",
       "      <td>1.922320</td>\n",
       "      <td>1.913216</td>\n",
       "      <td>2.048449</td>\n",
       "      <td>1.995728</td>\n",
       "      <td>2.076719</td>\n",
       "      <td>2.051072</td>\n",
       "      <td>1.843851</td>\n",
       "      <td>1.887731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528585</td>\n",
       "      <td>0.407341</td>\n",
       "      <td>0.527655</td>\n",
       "      <td>0.439027</td>\n",
       "      <td>0.537667</td>\n",
       "      <td>0.188951</td>\n",
       "      <td>0.159860</td>\n",
       "      <td>0.601456</td>\n",
       "      <td>0.512289</td>\n",
       "      <td>0.221047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830938</td>\n",
       "      <td>1.005566</td>\n",
       "      <td>0.363318</td>\n",
       "      <td>0.779375</td>\n",
       "      <td>0.838134</td>\n",
       "      <td>0.909691</td>\n",
       "      <td>1.024762</td>\n",
       "      <td>0.903071</td>\n",
       "      <td>1.046144</td>\n",
       "      <td>0.868963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.046932</td>\n",
       "      <td>0.922871</td>\n",
       "      <td>0.721506</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.921470</td>\n",
       "      <td>0.774855</td>\n",
       "      <td>0.891189</td>\n",
       "      <td>0.903957</td>\n",
       "      <td>0.957144</td>\n",
       "      <td>0.990339</td>\n",
       "      <td>...</td>\n",
       "      <td>2.221480</td>\n",
       "      <td>2.061422</td>\n",
       "      <td>2.189156</td>\n",
       "      <td>2.104810</td>\n",
       "      <td>2.271966</td>\n",
       "      <td>2.216904</td>\n",
       "      <td>2.282218</td>\n",
       "      <td>2.255555</td>\n",
       "      <td>2.026062</td>\n",
       "      <td>2.036279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  \\\n",
       "0  0.957020  0.823448  0.706688  0.745883  0.885037  0.672862  0.815175   \n",
       "1  0.840085  0.644758  0.701988  0.644552  0.779771  0.532637  0.597444   \n",
       "2  0.957020  0.823448  0.706688  0.745883  0.885037  0.672862  0.815175   \n",
       "3  0.528585  0.407341  0.527655  0.439027  0.537667  0.188951  0.159860   \n",
       "4  1.046932  0.922871  0.721506  0.824719  0.921470  0.774855  0.891189   \n",
       "\n",
       "   0.000005  0.000005  0.000005  ...  0.000008  0.000008  0.000008  0.000008  \\\n",
       "0  0.802330  0.905220  0.869727  ...  1.945669  1.855932  1.922320  1.913216   \n",
       "1  0.697043  0.792870  0.687446  ...  1.541514  1.558240  1.475706  1.540913   \n",
       "2  0.802330  0.905220  0.869727  ...  1.945669  1.855932  1.922320  1.913216   \n",
       "3  0.601456  0.512289  0.221047  ...  0.830938  1.005566  0.363318  0.779375   \n",
       "4  0.903957  0.957144  0.990339  ...  2.221480  2.061422  2.189156  2.104810   \n",
       "\n",
       "   0.000008  0.000008  0.000008  0.000008  0.000008  0.000008  \n",
       "0  2.048449  1.995728  2.076719  2.051072  1.843851  1.887731  \n",
       "1  1.641199  1.627997  1.688710  1.685466  1.564429  1.575002  \n",
       "2  2.048449  1.995728  2.076719  2.051072  1.843851  1.887731  \n",
       "3  0.838134  0.909691  1.024762  0.903071  1.046144  0.868963  \n",
       "4  2.271966  2.216904  2.282218  2.255555  2.026062  2.036279  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(predictions.detach().numpy(), columns=spectrum_test.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>...</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.373538</td>\n",
       "      <td>2.602481</td>\n",
       "      <td>2.775814</td>\n",
       "      <td>2.935397</td>\n",
       "      <td>3.074856</td>\n",
       "      <td>3.220465</td>\n",
       "      <td>3.363583</td>\n",
       "      <td>3.505908</td>\n",
       "      <td>3.647634</td>\n",
       "      <td>3.790090</td>\n",
       "      <td>...</td>\n",
       "      <td>10.069020</td>\n",
       "      <td>10.146292</td>\n",
       "      <td>10.208057</td>\n",
       "      <td>10.243674</td>\n",
       "      <td>10.246583</td>\n",
       "      <td>10.192531</td>\n",
       "      <td>10.036903</td>\n",
       "      <td>9.737349</td>\n",
       "      <td>9.326093</td>\n",
       "      <td>8.947765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.027413</td>\n",
       "      <td>2.150030</td>\n",
       "      <td>2.250785</td>\n",
       "      <td>2.362463</td>\n",
       "      <td>2.467873</td>\n",
       "      <td>2.581041</td>\n",
       "      <td>2.694600</td>\n",
       "      <td>2.809533</td>\n",
       "      <td>2.925638</td>\n",
       "      <td>3.043688</td>\n",
       "      <td>...</td>\n",
       "      <td>8.794491</td>\n",
       "      <td>8.871859</td>\n",
       "      <td>8.934365</td>\n",
       "      <td>8.973221</td>\n",
       "      <td>8.983096</td>\n",
       "      <td>8.942860</td>\n",
       "      <td>8.813263</td>\n",
       "      <td>8.556884</td>\n",
       "      <td>8.201778</td>\n",
       "      <td>7.875021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.470590</td>\n",
       "      <td>2.726463</td>\n",
       "      <td>2.921211</td>\n",
       "      <td>3.095970</td>\n",
       "      <td>3.246416</td>\n",
       "      <td>3.402639</td>\n",
       "      <td>3.555543</td>\n",
       "      <td>3.706972</td>\n",
       "      <td>3.857192</td>\n",
       "      <td>4.007671</td>\n",
       "      <td>...</td>\n",
       "      <td>10.460966</td>\n",
       "      <td>10.538142</td>\n",
       "      <td>10.599540</td>\n",
       "      <td>10.633985</td>\n",
       "      <td>10.634567</td>\n",
       "      <td>10.576088</td>\n",
       "      <td>10.412293</td>\n",
       "      <td>10.099323</td>\n",
       "      <td>9.670691</td>\n",
       "      <td>9.276407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.950271</td>\n",
       "      <td>2.046041</td>\n",
       "      <td>2.131383</td>\n",
       "      <td>2.233903</td>\n",
       "      <td>2.333012</td>\n",
       "      <td>2.440313</td>\n",
       "      <td>2.548641</td>\n",
       "      <td>2.658761</td>\n",
       "      <td>2.770347</td>\n",
       "      <td>2.884035</td>\n",
       "      <td>...</td>\n",
       "      <td>8.542764</td>\n",
       "      <td>8.620148</td>\n",
       "      <td>8.682729</td>\n",
       "      <td>8.722118</td>\n",
       "      <td>8.733251</td>\n",
       "      <td>8.695631</td>\n",
       "      <td>8.571070</td>\n",
       "      <td>8.323129</td>\n",
       "      <td>7.979041</td>\n",
       "      <td>7.662406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.523524</td>\n",
       "      <td>2.771409</td>\n",
       "      <td>2.957469</td>\n",
       "      <td>3.126776</td>\n",
       "      <td>3.273742</td>\n",
       "      <td>3.426844</td>\n",
       "      <td>3.576945</td>\n",
       "      <td>3.725913</td>\n",
       "      <td>3.874010</td>\n",
       "      <td>4.022686</td>\n",
       "      <td>...</td>\n",
       "      <td>10.456130</td>\n",
       "      <td>10.533535</td>\n",
       "      <td>10.595041</td>\n",
       "      <td>10.629530</td>\n",
       "      <td>10.630143</td>\n",
       "      <td>10.571716</td>\n",
       "      <td>10.408014</td>\n",
       "      <td>10.095198</td>\n",
       "      <td>9.666764</td>\n",
       "      <td>9.272662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  \\\n",
       "0  2.373538  2.602481  2.775814  2.935397  3.074856  3.220465  3.363583   \n",
       "1  2.027413  2.150030  2.250785  2.362463  2.467873  2.581041  2.694600   \n",
       "2  2.470590  2.726463  2.921211  3.095970  3.246416  3.402639  3.555543   \n",
       "3  1.950271  2.046041  2.131383  2.233903  2.333012  2.440313  2.548641   \n",
       "4  2.523524  2.771409  2.957469  3.126776  3.273742  3.426844  3.576945   \n",
       "\n",
       "   0.000005  0.000005  0.000005  ...   0.000008   0.000008   0.000008  \\\n",
       "0  3.505908  3.647634  3.790090  ...  10.069020  10.146292  10.208057   \n",
       "1  2.809533  2.925638  3.043688  ...   8.794491   8.871859   8.934365   \n",
       "2  3.706972  3.857192  4.007671  ...  10.460966  10.538142  10.599540   \n",
       "3  2.658761  2.770347  2.884035  ...   8.542764   8.620148   8.682729   \n",
       "4  3.725913  3.874010  4.022686  ...  10.456130  10.533535  10.595041   \n",
       "\n",
       "    0.000008   0.000008   0.000008   0.000008   0.000008  0.000008  0.000008  \n",
       "0  10.243674  10.246583  10.192531  10.036903   9.737349  9.326093  8.947765  \n",
       "1   8.973221   8.983096   8.942860   8.813263   8.556884  8.201778  7.875021  \n",
       "2  10.633985  10.634567  10.576088  10.412293  10.099323  9.670691  9.276407  \n",
       "3   8.722118   8.733251   8.695631   8.571070   8.323129  7.979041  7.662406  \n",
       "4  10.629530  10.630143  10.571716  10.408014  10.095198  9.666764  9.272662  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrum_test_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
