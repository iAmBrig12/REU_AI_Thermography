{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from thermography_dataset_one_layer import ThermDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'lr':0.01,\n",
    "        'epochs':1000,\n",
    "        'noise':0,\n",
    "        'train size':0.7,\n",
    "        'spec scale':10**12\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_tensor(df):\n",
    "    return torch.tensor(df.values, dtype=torch.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('combined_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,11:]\n",
    "y = df.iloc[:,:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(lambda x: x*args['spec scale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=args['train size'], random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.index = range(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>0.000005</th>\n",
       "      <th>...</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.532133</td>\n",
       "      <td>0.638418</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.802254</td>\n",
       "      <td>0.866701</td>\n",
       "      <td>0.933640</td>\n",
       "      <td>1.000501</td>\n",
       "      <td>1.067615</td>\n",
       "      <td>1.134905</td>\n",
       "      <td>1.202684</td>\n",
       "      <td>...</td>\n",
       "      <td>5.303224</td>\n",
       "      <td>5.372908</td>\n",
       "      <td>5.430458</td>\n",
       "      <td>5.471816</td>\n",
       "      <td>5.494759</td>\n",
       "      <td>5.486708</td>\n",
       "      <td>5.423339</td>\n",
       "      <td>5.281082</td>\n",
       "      <td>5.076630</td>\n",
       "      <td>4.888354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.414041</td>\n",
       "      <td>0.457451</td>\n",
       "      <td>0.496973</td>\n",
       "      <td>0.537416</td>\n",
       "      <td>0.575507</td>\n",
       "      <td>0.616503</td>\n",
       "      <td>0.658605</td>\n",
       "      <td>0.701921</td>\n",
       "      <td>0.746277</td>\n",
       "      <td>0.791765</td>\n",
       "      <td>...</td>\n",
       "      <td>4.100028</td>\n",
       "      <td>4.163747</td>\n",
       "      <td>4.216513</td>\n",
       "      <td>4.255809</td>\n",
       "      <td>4.280443</td>\n",
       "      <td>4.280814</td>\n",
       "      <td>4.237858</td>\n",
       "      <td>4.132937</td>\n",
       "      <td>3.978863</td>\n",
       "      <td>3.836942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.465971</td>\n",
       "      <td>0.535950</td>\n",
       "      <td>0.599500</td>\n",
       "      <td>0.657984</td>\n",
       "      <td>0.709998</td>\n",
       "      <td>0.764922</td>\n",
       "      <td>0.820523</td>\n",
       "      <td>0.876953</td>\n",
       "      <td>0.934031</td>\n",
       "      <td>0.991913</td>\n",
       "      <td>...</td>\n",
       "      <td>4.857763</td>\n",
       "      <td>4.927424</td>\n",
       "      <td>4.984310</td>\n",
       "      <td>5.025386</td>\n",
       "      <td>5.049202</td>\n",
       "      <td>5.044452</td>\n",
       "      <td>4.988772</td>\n",
       "      <td>4.860395</td>\n",
       "      <td>4.674584</td>\n",
       "      <td>4.503457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.383691</td>\n",
       "      <td>0.450965</td>\n",
       "      <td>0.514631</td>\n",
       "      <td>0.572481</td>\n",
       "      <td>0.623304</td>\n",
       "      <td>0.676948</td>\n",
       "      <td>0.731329</td>\n",
       "      <td>0.786481</td>\n",
       "      <td>0.842163</td>\n",
       "      <td>0.898461</td>\n",
       "      <td>...</td>\n",
       "      <td>4.744066</td>\n",
       "      <td>4.813846</td>\n",
       "      <td>4.870592</td>\n",
       "      <td>4.911579</td>\n",
       "      <td>4.935582</td>\n",
       "      <td>4.931638</td>\n",
       "      <td>4.877883</td>\n",
       "      <td>4.753013</td>\n",
       "      <td>4.571928</td>\n",
       "      <td>4.405149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.202562</td>\n",
       "      <td>0.201751</td>\n",
       "      <td>0.203200</td>\n",
       "      <td>0.210987</td>\n",
       "      <td>0.221130</td>\n",
       "      <td>0.232812</td>\n",
       "      <td>0.245369</td>\n",
       "      <td>0.258871</td>\n",
       "      <td>0.273278</td>\n",
       "      <td>0.288644</td>\n",
       "      <td>...</td>\n",
       "      <td>1.673267</td>\n",
       "      <td>1.706698</td>\n",
       "      <td>1.737154</td>\n",
       "      <td>1.762956</td>\n",
       "      <td>1.783029</td>\n",
       "      <td>1.793023</td>\n",
       "      <td>1.784698</td>\n",
       "      <td>1.749866</td>\n",
       "      <td>1.693567</td>\n",
       "      <td>1.641708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>0.289292</td>\n",
       "      <td>0.303189</td>\n",
       "      <td>0.315865</td>\n",
       "      <td>0.332897</td>\n",
       "      <td>0.350998</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.391281</td>\n",
       "      <td>0.412664</td>\n",
       "      <td>0.434948</td>\n",
       "      <td>0.458279</td>\n",
       "      <td>...</td>\n",
       "      <td>2.185162</td>\n",
       "      <td>2.223102</td>\n",
       "      <td>2.258088</td>\n",
       "      <td>2.287536</td>\n",
       "      <td>2.309717</td>\n",
       "      <td>2.318868</td>\n",
       "      <td>2.304381</td>\n",
       "      <td>2.255814</td>\n",
       "      <td>2.179809</td>\n",
       "      <td>2.109786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>0.381550</td>\n",
       "      <td>0.470170</td>\n",
       "      <td>0.548909</td>\n",
       "      <td>0.615927</td>\n",
       "      <td>0.673070</td>\n",
       "      <td>0.732666</td>\n",
       "      <td>0.792570</td>\n",
       "      <td>0.852905</td>\n",
       "      <td>0.913487</td>\n",
       "      <td>0.974471</td>\n",
       "      <td>...</td>\n",
       "      <td>5.003251</td>\n",
       "      <td>5.074765</td>\n",
       "      <td>5.132710</td>\n",
       "      <td>5.174146</td>\n",
       "      <td>5.197733</td>\n",
       "      <td>5.191909</td>\n",
       "      <td>5.133690</td>\n",
       "      <td>5.000708</td>\n",
       "      <td>4.808701</td>\n",
       "      <td>4.631874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>0.453996</td>\n",
       "      <td>0.544847</td>\n",
       "      <td>0.620312</td>\n",
       "      <td>0.684716</td>\n",
       "      <td>0.740257</td>\n",
       "      <td>0.798081</td>\n",
       "      <td>0.856012</td>\n",
       "      <td>0.914347</td>\n",
       "      <td>0.973024</td>\n",
       "      <td>1.032310</td>\n",
       "      <td>...</td>\n",
       "      <td>4.783330</td>\n",
       "      <td>4.849700</td>\n",
       "      <td>4.904975</td>\n",
       "      <td>4.945541</td>\n",
       "      <td>4.969423</td>\n",
       "      <td>4.965237</td>\n",
       "      <td>4.910910</td>\n",
       "      <td>4.784997</td>\n",
       "      <td>4.602506</td>\n",
       "      <td>4.434433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>0.325858</td>\n",
       "      <td>0.330976</td>\n",
       "      <td>0.332963</td>\n",
       "      <td>0.341853</td>\n",
       "      <td>0.353758</td>\n",
       "      <td>0.367173</td>\n",
       "      <td>0.381218</td>\n",
       "      <td>0.396176</td>\n",
       "      <td>0.412134</td>\n",
       "      <td>0.429284</td>\n",
       "      <td>...</td>\n",
       "      <td>1.653589</td>\n",
       "      <td>1.682302</td>\n",
       "      <td>1.710493</td>\n",
       "      <td>1.735484</td>\n",
       "      <td>1.755333</td>\n",
       "      <td>1.765342</td>\n",
       "      <td>1.757317</td>\n",
       "      <td>1.723186</td>\n",
       "      <td>1.667904</td>\n",
       "      <td>1.616983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>0.382323</td>\n",
       "      <td>0.443196</td>\n",
       "      <td>0.497557</td>\n",
       "      <td>0.547403</td>\n",
       "      <td>0.591868</td>\n",
       "      <td>0.638816</td>\n",
       "      <td>0.686397</td>\n",
       "      <td>0.734750</td>\n",
       "      <td>0.783736</td>\n",
       "      <td>0.833505</td>\n",
       "      <td>...</td>\n",
       "      <td>4.197061</td>\n",
       "      <td>4.259449</td>\n",
       "      <td>4.311814</td>\n",
       "      <td>4.351090</td>\n",
       "      <td>4.375623</td>\n",
       "      <td>4.375401</td>\n",
       "      <td>4.330910</td>\n",
       "      <td>4.223122</td>\n",
       "      <td>4.065150</td>\n",
       "      <td>3.919641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1540 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  \\\n",
       "0     0.532133  0.638418  0.726998  0.802254  0.866701  0.933640  1.000501   \n",
       "1     0.414041  0.457451  0.496973  0.537416  0.575507  0.616503  0.658605   \n",
       "2     0.465971  0.535950  0.599500  0.657984  0.709998  0.764922  0.820523   \n",
       "3     0.383691  0.450965  0.514631  0.572481  0.623304  0.676948  0.731329   \n",
       "4     0.202562  0.201751  0.203200  0.210987  0.221130  0.232812  0.245369   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1535  0.289292  0.303189  0.315865  0.332897  0.350998  0.370787  0.391281   \n",
       "1536  0.381550  0.470170  0.548909  0.615927  0.673070  0.732666  0.792570   \n",
       "1537  0.453996  0.544847  0.620312  0.684716  0.740257  0.798081  0.856012   \n",
       "1538  0.325858  0.330976  0.332963  0.341853  0.353758  0.367173  0.381218   \n",
       "1539  0.382323  0.443196  0.497557  0.547403  0.591868  0.638816  0.686397   \n",
       "\n",
       "      0.000005  0.000005  0.000005  ...  0.000008  0.000008  0.000008  \\\n",
       "0     1.067615  1.134905  1.202684  ...  5.303224  5.372908  5.430458   \n",
       "1     0.701921  0.746277  0.791765  ...  4.100028  4.163747  4.216513   \n",
       "2     0.876953  0.934031  0.991913  ...  4.857763  4.927424  4.984310   \n",
       "3     0.786481  0.842163  0.898461  ...  4.744066  4.813846  4.870592   \n",
       "4     0.258871  0.273278  0.288644  ...  1.673267  1.706698  1.737154   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1535  0.412664  0.434948  0.458279  ...  2.185162  2.223102  2.258088   \n",
       "1536  0.852905  0.913487  0.974471  ...  5.003251  5.074765  5.132710   \n",
       "1537  0.914347  0.973024  1.032310  ...  4.783330  4.849700  4.904975   \n",
       "1538  0.396176  0.412134  0.429284  ...  1.653589  1.682302  1.710493   \n",
       "1539  0.734750  0.783736  0.833505  ...  4.197061  4.259449  4.311814   \n",
       "\n",
       "      0.000008  0.000008  0.000008  0.000008  0.000008  0.000008  0.000008  \n",
       "0     5.471816  5.494759  5.486708  5.423339  5.281082  5.076630  4.888354  \n",
       "1     4.255809  4.280443  4.280814  4.237858  4.132937  3.978863  3.836942  \n",
       "2     5.025386  5.049202  5.044452  4.988772  4.860395  4.674584  4.503457  \n",
       "3     4.911579  4.935582  4.931638  4.877883  4.753013  4.571928  4.405149  \n",
       "4     1.762956  1.783029  1.793023  1.784698  1.749866  1.693567  1.641708  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1535  2.287536  2.309717  2.318868  2.304381  2.255814  2.179809  2.109786  \n",
       "1536  5.174146  5.197733  5.191909  5.133690  5.000708  4.808701  4.631874  \n",
       "1537  4.945541  4.969423  4.965237  4.910910  4.784997  4.602506  4.434433  \n",
       "1538  1.735484  1.755333  1.765342  1.757317  1.723186  1.667904  1.616983  \n",
       "1539  4.351090  4.375623  4.375401  4.330910  4.223122  4.065150  3.919641  \n",
       "\n",
       "[1540 rows x 66 columns]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin1 = nn.Linear(input_size, 45)\n",
    "        self.lin2 = nn.Linear(45, 60)\n",
    "        self.lin3 = nn.Linear(60, 75)\n",
    "        self.lin4 = nn.Linear(75, 60)\n",
    "        self.lin_fin = nn.Linear(60, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.lin1(x))\n",
    "        x = F.leaky_relu(self.lin2(x))\n",
    "        x = F.leaky_relu(self.lin3(x))\n",
    "        x = F.leaky_relu(self.lin4(x))\n",
    "        x = self.lin_fin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(X_train)\n",
    "input_size = 66\n",
    "output_size = 1\n",
    "\n",
    "# store models in descending order (11, 10, 9...)\n",
    "models = []\n",
    "for i in range(11):\n",
    "    models.append(Net(input_size+i, output_size))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = args['lr']\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, loss = 2752.0791015625\n",
      "epoch: 200, loss = 7.036067962646484\n",
      "epoch: 300, loss = 69.91508483886719\n",
      "epoch: 400, loss = 4.636088848114014\n",
      "epoch: 500, loss = 50.512393951416016\n",
      "epoch: 600, loss = 3.556549310684204\n",
      "epoch: 700, loss = 1555.991455078125\n",
      "epoch: 800, loss = 2.9847617149353027\n",
      "epoch: 900, loss = 2.350904703140259\n",
      "epoch: 1000, loss = 2.598435401916504\n",
      "best loss: 2.2616794109344482 in epoch 920\n",
      "\n",
      "Layer 10\n",
      "epoch: 100, loss = 234.97190856933594\n",
      "epoch: 200, loss = 139.09730529785156\n",
      "epoch: 300, loss = 34.00491714477539\n",
      "epoch: 400, loss = 30.07916259765625\n",
      "epoch: 500, loss = 28.405794143676758\n",
      "epoch: 600, loss = 27.220569610595703\n",
      "epoch: 700, loss = 26.901823043823242\n",
      "epoch: 800, loss = 114.8257064819336\n",
      "epoch: 900, loss = 22.061317443847656\n",
      "epoch: 1000, loss = 41.66435623168945\n",
      "best loss: 21.14292335510254 in epoch 978\n",
      "\n",
      "Layer 9\n",
      "epoch: 100, loss = 55.565269470214844\n",
      "epoch: 200, loss = 37.12224578857422\n",
      "epoch: 300, loss = 34.95804977416992\n",
      "epoch: 400, loss = 34.571754455566406\n",
      "epoch: 500, loss = 34.532474517822266\n",
      "epoch: 600, loss = 33.8066520690918\n",
      "epoch: 700, loss = 33.41439437866211\n",
      "epoch: 800, loss = 33.06208801269531\n",
      "epoch: 900, loss = 32.679927825927734\n",
      "epoch: 1000, loss = 32.45735549926758\n",
      "best loss: 32.28675079345703 in epoch 999\n",
      "\n",
      "Layer 8\n",
      "epoch: 100, loss = 129.8437957763672\n",
      "epoch: 200, loss = 55.332359313964844\n",
      "epoch: 300, loss = 51.55491638183594\n",
      "epoch: 400, loss = 50.54823303222656\n",
      "epoch: 500, loss = 49.64436721801758\n",
      "epoch: 600, loss = 51.37385940551758\n",
      "epoch: 700, loss = 46.995155334472656\n",
      "epoch: 800, loss = 45.70726013183594\n",
      "epoch: 900, loss = 44.32802200317383\n",
      "epoch: 1000, loss = 42.92699432373047\n",
      "best loss: 42.92699432373047 in epoch 1000\n",
      "\n",
      "Layer 7\n",
      "epoch: 100, loss = 155.39181518554688\n",
      "epoch: 200, loss = 107.12126922607422\n",
      "epoch: 300, loss = 106.7438735961914\n",
      "epoch: 400, loss = 106.38749694824219\n",
      "epoch: 500, loss = 105.9364242553711\n",
      "epoch: 600, loss = 105.35910034179688\n",
      "epoch: 700, loss = 104.60706329345703\n",
      "epoch: 800, loss = 103.61583709716797\n",
      "epoch: 900, loss = 102.3147201538086\n",
      "epoch: 1000, loss = 100.65440368652344\n",
      "best loss: 100.65440368652344 in epoch 1000\n",
      "\n",
      "Layer 6\n",
      "epoch: 100, loss = 177.42271423339844\n",
      "epoch: 200, loss = 154.5679168701172\n",
      "epoch: 300, loss = 151.16140747070312\n",
      "epoch: 400, loss = 147.76651000976562\n",
      "epoch: 500, loss = 144.147216796875\n",
      "epoch: 600, loss = 140.31556701660156\n",
      "epoch: 700, loss = 136.28067016601562\n",
      "epoch: 800, loss = 132.1396942138672\n",
      "epoch: 900, loss = 128.15090942382812\n",
      "epoch: 1000, loss = 124.66110229492188\n",
      "best loss: 124.66110229492188 in epoch 1000\n",
      "\n",
      "Layer 5\n",
      "epoch: 100, loss = 194.31687927246094\n",
      "epoch: 200, loss = 154.45997619628906\n",
      "epoch: 300, loss = 150.8649139404297\n",
      "epoch: 400, loss = 148.0955810546875\n",
      "epoch: 500, loss = 145.20538330078125\n",
      "epoch: 600, loss = 142.27059936523438\n",
      "epoch: 700, loss = 139.38116455078125\n",
      "epoch: 800, loss = 136.6266632080078\n",
      "epoch: 900, loss = 134.10597229003906\n",
      "epoch: 1000, loss = 131.84449768066406\n",
      "best loss: 131.84449768066406 in epoch 1000\n",
      "\n",
      "Layer 4\n",
      "epoch: 100, loss = 203.7989044189453\n",
      "epoch: 200, loss = 171.17083740234375\n",
      "epoch: 300, loss = 166.83078002929688\n",
      "epoch: 400, loss = 163.67405700683594\n",
      "epoch: 500, loss = 160.51373291015625\n",
      "epoch: 600, loss = 157.2832794189453\n",
      "epoch: 700, loss = 154.06399536132812\n",
      "epoch: 800, loss = 150.95472717285156\n",
      "epoch: 900, loss = 148.06166076660156\n",
      "epoch: 1000, loss = 145.49591064453125\n",
      "best loss: 145.49591064453125 in epoch 1000\n",
      "\n",
      "Layer 3\n",
      "epoch: 100, loss = 229.13101196289062\n",
      "epoch: 200, loss = 202.42431640625\n",
      "epoch: 300, loss = 196.524658203125\n",
      "epoch: 400, loss = 191.2015380859375\n",
      "epoch: 500, loss = 185.68902587890625\n",
      "epoch: 600, loss = 180.09567260742188\n",
      "epoch: 700, loss = 174.5361785888672\n",
      "epoch: 800, loss = 169.20498657226562\n",
      "epoch: 900, loss = 164.4525146484375\n",
      "epoch: 1000, loss = 160.75418090820312\n",
      "best loss: 160.75418090820312 in epoch 1000\n",
      "\n",
      "Layer 2\n",
      "epoch: 100, loss = 323.5838317871094\n",
      "epoch: 200, loss = 301.41839599609375\n",
      "epoch: 300, loss = 298.4686279296875\n",
      "epoch: 400, loss = 284.8506774902344\n",
      "epoch: 500, loss = 282.49554443359375\n",
      "epoch: 600, loss = 282.1502990722656\n",
      "epoch: 700, loss = 280.4237365722656\n",
      "epoch: 800, loss = 279.4581298828125\n",
      "epoch: 900, loss = 280.916748046875\n",
      "epoch: 1000, loss = 279.2489318847656\n",
      "best loss: 278.8439636230469 in epoch 944\n",
      "\n",
      "Layer 1\n",
      "epoch: 100, loss = 878.06103515625\n",
      "epoch: 200, loss = 856.2050170898438\n",
      "epoch: 300, loss = 849.4348754882812\n",
      "epoch: 400, loss = 845.7086181640625\n",
      "epoch: 500, loss = 842.0193481445312\n",
      "epoch: 600, loss = 838.1228637695312\n",
      "epoch: 700, loss = 834.0701293945312\n",
      "epoch: 800, loss = 829.9517822265625\n",
      "epoch: 900, loss = 825.9298095703125\n",
      "epoch: 1000, loss = 822.2769775390625\n",
      "best loss: 822.2769775390625 in epoch 1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_losses = []\n",
    "\n",
    "for i in range(11):\n",
    "    best_loss = np.inf\n",
    "    best_epoch = 0\n",
    "\n",
    "    print(f'Layer {11-i}')\n",
    "\n",
    "    optimizer = torch.optim.Adam(models[i].parameters(), lr=learning_rate)\n",
    "    model = models[i]\n",
    "\n",
    "    inputs = df_to_tensor(X_train)\n",
    "    outputs = df_to_tensor(y_train.iloc[:,10-i]).reshape(-1,1)\n",
    "\n",
    "    for epoch in range(args['epochs']):\n",
    "        # empty gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        pred = model(inputs)\n",
    "\n",
    "        # loss\n",
    "        loss = criterion(pred, outputs)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % int(args['epochs']/10) == 0:\n",
    "            print(f'epoch: {epoch+1}, loss = {loss}')\n",
    "\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "    best_losses.append(best_loss.item())\n",
    "    \n",
    "    X_train[f'layer {11-i} predictions'] = pd.DataFrame(pred.detach().numpy())\n",
    "    print(f'best loss: {best_loss} in epoch {best_epoch}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_losses.reverse()\n",
    "plt.plot(best_losses)\n",
    "\n",
    "plt.title(\"Best Loss over Layers\")\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(X_test):\n",
    "    df = X_test\n",
    "\n",
    "    for i in range(11):\n",
    "        inputs = df_to_tensor(df)\n",
    "        pred = models[i](inputs)\n",
    "        df[f'layer {11-i} predictions'] = pd.DataFrame(pred.detach().numpy())\n",
    "\n",
    "    return df.loc[:, 'layer 11 predictions':'layer 1 predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer 11 predictions</th>\n",
       "      <th>layer 10 predictions</th>\n",
       "      <th>layer 9 predictions</th>\n",
       "      <th>layer 8 predictions</th>\n",
       "      <th>layer 7 predictions</th>\n",
       "      <th>layer 6 predictions</th>\n",
       "      <th>layer 5 predictions</th>\n",
       "      <th>layer 4 predictions</th>\n",
       "      <th>layer 3 predictions</th>\n",
       "      <th>layer 2 predictions</th>\n",
       "      <th>layer 1 predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>311.239990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>367.628479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      layer 11 predictions  layer 10 predictions  layer 9 predictions  \\\n",
       "1124                   NaN                   NaN                  NaN   \n",
       "235             311.239990                   NaN                  NaN   \n",
       "585             367.628479                   NaN                  NaN   \n",
       "1469                   NaN                   NaN                  NaN   \n",
       "2066                   NaN                   NaN                  NaN   \n",
       "...                    ...                   ...                  ...   \n",
       "1593                   NaN                   NaN                  NaN   \n",
       "1831                   NaN                   NaN                  NaN   \n",
       "737                    NaN                   NaN                  NaN   \n",
       "2098                   NaN                   NaN                  NaN   \n",
       "1928                   NaN                   NaN                  NaN   \n",
       "\n",
       "      layer 8 predictions  layer 7 predictions  layer 6 predictions  \\\n",
       "1124                  NaN                  NaN                  NaN   \n",
       "235                   NaN                  NaN                  NaN   \n",
       "585                   NaN                  NaN                  NaN   \n",
       "1469                  NaN                  NaN                  NaN   \n",
       "2066                  NaN                  NaN                  NaN   \n",
       "...                   ...                  ...                  ...   \n",
       "1593                  NaN                  NaN                  NaN   \n",
       "1831                  NaN                  NaN                  NaN   \n",
       "737                   NaN                  NaN                  NaN   \n",
       "2098                  NaN                  NaN                  NaN   \n",
       "1928                  NaN                  NaN                  NaN   \n",
       "\n",
       "      layer 5 predictions  layer 4 predictions  layer 3 predictions  \\\n",
       "1124                  NaN                  NaN                  NaN   \n",
       "235                   NaN                  NaN                  NaN   \n",
       "585                   NaN                  NaN                  NaN   \n",
       "1469                  NaN                  NaN                  NaN   \n",
       "2066                  NaN                  NaN                  NaN   \n",
       "...                   ...                  ...                  ...   \n",
       "1593                  NaN                  NaN                  NaN   \n",
       "1831                  NaN                  NaN                  NaN   \n",
       "737                   NaN                  NaN                  NaN   \n",
       "2098                  NaN                  NaN                  NaN   \n",
       "1928                  NaN                  NaN                  NaN   \n",
       "\n",
       "      layer 2 predictions  layer 1 predictions  \n",
       "1124                  NaN                  NaN  \n",
       "235                   NaN                  NaN  \n",
       "585                   NaN                  NaN  \n",
       "1469                  NaN                  NaN  \n",
       "2066                  NaN                  NaN  \n",
       "...                   ...                  ...  \n",
       "1593                  NaN                  NaN  \n",
       "1831                  NaN                  NaN  \n",
       "737                   NaN                  NaN  \n",
       "2098                  NaN                  NaN  \n",
       "1928                  NaN                  NaN  \n",
       "\n",
       "[660 rows x 11 columns]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
