{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from thermography_dataset_one_layer import ThermDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'lr':0.01,\n",
    "        'epochs':1000,\n",
    "        'noise':0,\n",
    "        'train size':0.7,\n",
    "        'spec scale':10**12\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_tensor(df):\n",
    "    return torch.tensor(df.values, dtype=torch.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('wide_range.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,11:]\n",
    "y = df.iloc[:,:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(lambda x: x*args['spec scale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=args['train size'], random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.index = range(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.000004</th>\n",
       "      <th>0.000004</th>\n",
       "      <th>0.000004</th>\n",
       "      <th>0.000004</th>\n",
       "      <th>0.000004</th>\n",
       "      <th>0.000004</th>\n",
       "      <th>0.000004</th>\n",
       "      <th>0.000004</th>\n",
       "      <th>0.000004</th>\n",
       "      <th>0.000004</th>\n",
       "      <th>...</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "      <th>0.000008</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047328</td>\n",
       "      <td>0.044030</td>\n",
       "      <td>0.062621</td>\n",
       "      <td>0.050627</td>\n",
       "      <td>0.071193</td>\n",
       "      <td>0.068130</td>\n",
       "      <td>0.101914</td>\n",
       "      <td>0.075729</td>\n",
       "      <td>0.108325</td>\n",
       "      <td>0.133987</td>\n",
       "      <td>...</td>\n",
       "      <td>3.652357</td>\n",
       "      <td>3.706860</td>\n",
       "      <td>3.754378</td>\n",
       "      <td>3.791491</td>\n",
       "      <td>3.816109</td>\n",
       "      <td>3.819172</td>\n",
       "      <td>3.783524</td>\n",
       "      <td>3.692427</td>\n",
       "      <td>3.557224</td>\n",
       "      <td>3.432674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038770</td>\n",
       "      <td>0.035673</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.056641</td>\n",
       "      <td>0.054457</td>\n",
       "      <td>0.082382</td>\n",
       "      <td>0.062676</td>\n",
       "      <td>0.091149</td>\n",
       "      <td>0.114388</td>\n",
       "      <td>...</td>\n",
       "      <td>2.320425</td>\n",
       "      <td>2.355479</td>\n",
       "      <td>2.389728</td>\n",
       "      <td>2.419447</td>\n",
       "      <td>2.441954</td>\n",
       "      <td>2.450765</td>\n",
       "      <td>2.434611</td>\n",
       "      <td>2.382484</td>\n",
       "      <td>2.301435</td>\n",
       "      <td>2.226764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017471</td>\n",
       "      <td>0.015108</td>\n",
       "      <td>0.019534</td>\n",
       "      <td>0.015249</td>\n",
       "      <td>0.021160</td>\n",
       "      <td>0.020663</td>\n",
       "      <td>0.033139</td>\n",
       "      <td>0.028438</td>\n",
       "      <td>0.044417</td>\n",
       "      <td>0.059315</td>\n",
       "      <td>...</td>\n",
       "      <td>1.783106</td>\n",
       "      <td>1.818651</td>\n",
       "      <td>1.850644</td>\n",
       "      <td>1.877459</td>\n",
       "      <td>1.898089</td>\n",
       "      <td>1.907974</td>\n",
       "      <td>1.898374</td>\n",
       "      <td>1.860607</td>\n",
       "      <td>1.800060</td>\n",
       "      <td>1.744286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024575</td>\n",
       "      <td>0.020517</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>0.019283</td>\n",
       "      <td>0.026321</td>\n",
       "      <td>0.025631</td>\n",
       "      <td>0.041952</td>\n",
       "      <td>0.037789</td>\n",
       "      <td>0.060454</td>\n",
       "      <td>0.082459</td>\n",
       "      <td>...</td>\n",
       "      <td>4.617065</td>\n",
       "      <td>4.680924</td>\n",
       "      <td>4.734778</td>\n",
       "      <td>4.774832</td>\n",
       "      <td>4.798921</td>\n",
       "      <td>4.795918</td>\n",
       "      <td>4.744459</td>\n",
       "      <td>4.623791</td>\n",
       "      <td>4.448374</td>\n",
       "      <td>4.286812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012262</td>\n",
       "      <td>0.010760</td>\n",
       "      <td>0.014171</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.015674</td>\n",
       "      <td>0.015384</td>\n",
       "      <td>0.024641</td>\n",
       "      <td>0.020957</td>\n",
       "      <td>0.032692</td>\n",
       "      <td>0.043657</td>\n",
       "      <td>...</td>\n",
       "      <td>1.639148</td>\n",
       "      <td>1.670154</td>\n",
       "      <td>1.699314</td>\n",
       "      <td>1.724537</td>\n",
       "      <td>1.744379</td>\n",
       "      <td>1.754398</td>\n",
       "      <td>1.746490</td>\n",
       "      <td>1.712636</td>\n",
       "      <td>1.657755</td>\n",
       "      <td>1.607205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>0.008816</td>\n",
       "      <td>0.007552</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>0.010369</td>\n",
       "      <td>0.010237</td>\n",
       "      <td>0.016819</td>\n",
       "      <td>0.015040</td>\n",
       "      <td>0.024138</td>\n",
       "      <td>0.032982</td>\n",
       "      <td>...</td>\n",
       "      <td>1.737692</td>\n",
       "      <td>1.768599</td>\n",
       "      <td>1.798230</td>\n",
       "      <td>1.824086</td>\n",
       "      <td>1.844388</td>\n",
       "      <td>1.854326</td>\n",
       "      <td>1.845326</td>\n",
       "      <td>1.808934</td>\n",
       "      <td>1.750374</td>\n",
       "      <td>1.696432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>0.022660</td>\n",
       "      <td>0.019827</td>\n",
       "      <td>0.026071</td>\n",
       "      <td>0.020487</td>\n",
       "      <td>0.028498</td>\n",
       "      <td>0.027720</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.036680</td>\n",
       "      <td>0.056381</td>\n",
       "      <td>0.074280</td>\n",
       "      <td>...</td>\n",
       "      <td>1.875067</td>\n",
       "      <td>1.911222</td>\n",
       "      <td>1.943955</td>\n",
       "      <td>1.971422</td>\n",
       "      <td>1.992454</td>\n",
       "      <td>2.002216</td>\n",
       "      <td>1.991539</td>\n",
       "      <td>1.951336</td>\n",
       "      <td>1.887281</td>\n",
       "      <td>1.828272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>0.054368</td>\n",
       "      <td>0.049658</td>\n",
       "      <td>0.069249</td>\n",
       "      <td>0.055489</td>\n",
       "      <td>0.077627</td>\n",
       "      <td>0.074266</td>\n",
       "      <td>0.111904</td>\n",
       "      <td>0.084833</td>\n",
       "      <td>0.122915</td>\n",
       "      <td>0.153867</td>\n",
       "      <td>...</td>\n",
       "      <td>5.344826</td>\n",
       "      <td>5.409761</td>\n",
       "      <td>5.465227</td>\n",
       "      <td>5.505966</td>\n",
       "      <td>5.528740</td>\n",
       "      <td>5.520424</td>\n",
       "      <td>5.456460</td>\n",
       "      <td>5.313137</td>\n",
       "      <td>5.107256</td>\n",
       "      <td>4.917666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>0.017072</td>\n",
       "      <td>0.014896</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>0.015351</td>\n",
       "      <td>0.021409</td>\n",
       "      <td>0.020917</td>\n",
       "      <td>0.033378</td>\n",
       "      <td>0.028303</td>\n",
       "      <td>0.043981</td>\n",
       "      <td>0.058593</td>\n",
       "      <td>...</td>\n",
       "      <td>2.570995</td>\n",
       "      <td>2.615463</td>\n",
       "      <td>2.655006</td>\n",
       "      <td>2.687193</td>\n",
       "      <td>2.710532</td>\n",
       "      <td>2.718533</td>\n",
       "      <td>2.698864</td>\n",
       "      <td>2.639391</td>\n",
       "      <td>2.547993</td>\n",
       "      <td>2.463787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>0.021359</td>\n",
       "      <td>0.019676</td>\n",
       "      <td>0.027645</td>\n",
       "      <td>0.022377</td>\n",
       "      <td>0.031646</td>\n",
       "      <td>0.030620</td>\n",
       "      <td>0.046760</td>\n",
       "      <td>0.036060</td>\n",
       "      <td>0.052949</td>\n",
       "      <td>0.067222</td>\n",
       "      <td>...</td>\n",
       "      <td>3.392286</td>\n",
       "      <td>3.448372</td>\n",
       "      <td>3.495906</td>\n",
       "      <td>3.532569</td>\n",
       "      <td>3.557166</td>\n",
       "      <td>3.561590</td>\n",
       "      <td>3.529876</td>\n",
       "      <td>3.446362</td>\n",
       "      <td>3.321571</td>\n",
       "      <td>3.206608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1540 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0.000004  0.000004  0.000004  0.000004  0.000004  0.000004  0.000004  \\\n",
       "0     0.047328  0.044030  0.062621  0.050627  0.071193  0.068130  0.101914   \n",
       "1     0.038770  0.035673  0.050047  0.040308  0.056641  0.054457  0.082382   \n",
       "2     0.017471  0.015108  0.019534  0.015249  0.021160  0.020663  0.033139   \n",
       "3     0.024575  0.020517  0.025340  0.019283  0.026321  0.025631  0.041952   \n",
       "4     0.012262  0.010760  0.014171  0.011194  0.015674  0.015384  0.024641   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1535  0.008816  0.007552  0.009605  0.007467  0.010369  0.010237  0.016819   \n",
       "1536  0.022660  0.019827  0.026071  0.020487  0.028498  0.027720  0.043868   \n",
       "1537  0.054368  0.049658  0.069249  0.055489  0.077627  0.074266  0.111904   \n",
       "1538  0.017072  0.014896  0.019520  0.015351  0.021409  0.020917  0.033378   \n",
       "1539  0.021359  0.019676  0.027645  0.022377  0.031646  0.030620  0.046760   \n",
       "\n",
       "      0.000004  0.000004  0.000004  ...  0.000008  0.000008  0.000008  \\\n",
       "0     0.075729  0.108325  0.133987  ...  3.652357  3.706860  3.754378   \n",
       "1     0.062676  0.091149  0.114388  ...  2.320425  2.355479  2.389728   \n",
       "2     0.028438  0.044417  0.059315  ...  1.783106  1.818651  1.850644   \n",
       "3     0.037789  0.060454  0.082459  ...  4.617065  4.680924  4.734778   \n",
       "4     0.020957  0.032692  0.043657  ...  1.639148  1.670154  1.699314   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1535  0.015040  0.024138  0.032982  ...  1.737692  1.768599  1.798230   \n",
       "1536  0.036680  0.056381  0.074280  ...  1.875067  1.911222  1.943955   \n",
       "1537  0.084833  0.122915  0.153867  ...  5.344826  5.409761  5.465227   \n",
       "1538  0.028303  0.043981  0.058593  ...  2.570995  2.615463  2.655006   \n",
       "1539  0.036060  0.052949  0.067222  ...  3.392286  3.448372  3.495906   \n",
       "\n",
       "      0.000008  0.000008  0.000008  0.000008  0.000008  0.000008  0.000008  \n",
       "0     3.791491  3.816109  3.819172  3.783524  3.692427  3.557224  3.432674  \n",
       "1     2.419447  2.441954  2.450765  2.434611  2.382484  2.301435  2.226764  \n",
       "2     1.877459  1.898089  1.907974  1.898374  1.860607  1.800060  1.744286  \n",
       "3     4.774832  4.798921  4.795918  4.744459  4.623791  4.448374  4.286812  \n",
       "4     1.724537  1.744379  1.754398  1.746490  1.712636  1.657755  1.607205  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1535  1.824086  1.844388  1.854326  1.845326  1.808934  1.750374  1.696432  \n",
       "1536  1.971422  1.992454  2.002216  1.991539  1.951336  1.887281  1.828272  \n",
       "1537  5.505966  5.528740  5.520424  5.456460  5.313137  5.107256  4.917666  \n",
       "1538  2.687193  2.710532  2.718533  2.698864  2.639391  2.547993  2.463787  \n",
       "1539  3.532569  3.557166  3.561590  3.529876  3.446362  3.321571  3.206608  \n",
       "\n",
       "[1540 rows x 86 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin1 = nn.Linear(input_size, 45)\n",
    "        self.lin2 = nn.Linear(45, 60)\n",
    "        self.lin3 = nn.Linear(60, 75)\n",
    "        self.lin4 = nn.Linear(75, 60)\n",
    "        self.lin_fin = nn.Linear(60, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.lin1(x))\n",
    "        x = F.leaky_relu(self.lin2(x))\n",
    "        x = F.leaky_relu(self.lin3(x))\n",
    "        x = F.leaky_relu(self.lin4(x))\n",
    "        x = self.lin_fin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(X_train.columns)\n",
    "output_size = 1\n",
    "\n",
    "# store models in descending order (11, 10, 9...)\n",
    "models = []\n",
    "for i in range(11):\n",
    "    models.append(Net(input_size+i, output_size))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = args['lr']\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 11\n",
      "epoch: 100, loss = 2050.893310546875\n",
      "epoch: 200, loss = 147.2422332763672\n",
      "epoch: 300, loss = 101.12718963623047\n",
      "epoch: 400, loss = 43.082366943359375\n",
      "epoch: 500, loss = 110.62384033203125\n",
      "epoch: 600, loss = 180.87449645996094\n",
      "epoch: 700, loss = 369.86370849609375\n",
      "epoch: 800, loss = 195.1044921875\n",
      "epoch: 900, loss = 52.24626541137695\n",
      "epoch: 1000, loss = 5.139861583709717\n",
      "best loss: 5.1317057609558105 in epoch 997\n",
      "\n",
      "Layer 10\n",
      "epoch: 100, loss = 257.9526062011719\n",
      "epoch: 200, loss = 222.361572265625\n",
      "epoch: 300, loss = 185.10105895996094\n",
      "epoch: 400, loss = 144.8880157470703\n",
      "epoch: 500, loss = 67.22673797607422\n",
      "epoch: 600, loss = 34.51642608642578\n",
      "epoch: 700, loss = 27.50002098083496\n",
      "epoch: 800, loss = 23.28859519958496\n",
      "epoch: 900, loss = 19.964380264282227\n",
      "epoch: 1000, loss = 18.791385650634766\n",
      "best loss: 18.355316162109375 in epoch 972\n",
      "\n",
      "Layer 9\n",
      "epoch: 100, loss = 54.01609802246094\n",
      "epoch: 200, loss = 44.34083938598633\n",
      "epoch: 300, loss = 39.58961486816406\n",
      "epoch: 400, loss = 38.607234954833984\n",
      "epoch: 500, loss = 37.778804779052734\n",
      "epoch: 600, loss = 37.00041198730469\n",
      "epoch: 700, loss = 36.355648040771484\n",
      "epoch: 800, loss = 36.53693771362305\n",
      "epoch: 900, loss = 35.49481964111328\n",
      "epoch: 1000, loss = 35.23997497558594\n",
      "best loss: 35.18479919433594 in epoch 998\n",
      "\n",
      "Layer 8\n",
      "epoch: 100, loss = 71.99404907226562\n",
      "epoch: 200, loss = 65.52973175048828\n",
      "epoch: 300, loss = 59.27018737792969\n",
      "epoch: 400, loss = 56.35445785522461\n",
      "epoch: 500, loss = 54.657222747802734\n",
      "epoch: 600, loss = 57.52354049682617\n",
      "epoch: 700, loss = 77.69983673095703\n",
      "epoch: 800, loss = 50.613311767578125\n",
      "epoch: 900, loss = 50.421085357666016\n",
      "epoch: 1000, loss = 70.29829406738281\n",
      "best loss: 49.53720474243164 in epoch 970\n",
      "\n",
      "Layer 7\n",
      "epoch: 100, loss = 119.53324890136719\n",
      "epoch: 200, loss = 111.97649383544922\n",
      "epoch: 300, loss = 110.52009582519531\n",
      "epoch: 400, loss = 108.93612670898438\n",
      "epoch: 500, loss = 107.21915435791016\n",
      "epoch: 600, loss = 105.37214660644531\n",
      "epoch: 700, loss = 103.26592254638672\n",
      "epoch: 800, loss = 101.22908782958984\n",
      "epoch: 900, loss = 98.80796813964844\n",
      "epoch: 1000, loss = 96.09148406982422\n",
      "best loss: 96.09148406982422 in epoch 1000\n",
      "\n",
      "Layer 6\n",
      "epoch: 100, loss = 186.22804260253906\n",
      "epoch: 200, loss = 159.53631591796875\n",
      "epoch: 300, loss = 156.07562255859375\n",
      "epoch: 400, loss = 152.2865753173828\n",
      "epoch: 500, loss = 148.28079223632812\n",
      "epoch: 600, loss = 144.11245727539062\n",
      "epoch: 700, loss = 140.1785125732422\n",
      "epoch: 800, loss = 122.04723358154297\n",
      "epoch: 900, loss = 118.1640625\n",
      "epoch: 1000, loss = 100.1269760131836\n",
      "best loss: 99.88916015625 in epoch 998\n",
      "\n",
      "Layer 5\n",
      "epoch: 100, loss = 189.826171875\n",
      "epoch: 200, loss = 138.411376953125\n",
      "epoch: 300, loss = 132.9033966064453\n",
      "epoch: 400, loss = 129.977294921875\n",
      "epoch: 500, loss = 126.82099151611328\n",
      "epoch: 600, loss = 123.46591186523438\n",
      "epoch: 700, loss = 119.95026397705078\n",
      "epoch: 800, loss = 116.29389190673828\n",
      "epoch: 900, loss = 112.50737762451172\n",
      "epoch: 1000, loss = 108.5977783203125\n",
      "best loss: 108.5977783203125 in epoch 1000\n",
      "\n",
      "Layer 4\n",
      "epoch: 100, loss = 168.82647705078125\n",
      "epoch: 200, loss = 141.9503173828125\n",
      "epoch: 300, loss = 137.2700653076172\n",
      "epoch: 400, loss = 133.73402404785156\n",
      "epoch: 500, loss = 129.90457153320312\n",
      "epoch: 600, loss = 125.83694458007812\n",
      "epoch: 700, loss = 121.58230590820312\n",
      "epoch: 800, loss = 117.18458557128906\n",
      "epoch: 900, loss = 112.59049224853516\n",
      "epoch: 1000, loss = 108.30659484863281\n",
      "best loss: 108.30659484863281 in epoch 1000\n",
      "\n",
      "Layer 3\n",
      "epoch: 100, loss = 152.5570831298828\n",
      "epoch: 200, loss = 136.2188720703125\n",
      "epoch: 300, loss = 131.39791870117188\n",
      "epoch: 400, loss = 126.28282928466797\n",
      "epoch: 500, loss = 120.58036804199219\n",
      "epoch: 600, loss = 114.09193420410156\n",
      "epoch: 700, loss = 106.4834213256836\n",
      "epoch: 800, loss = 97.82959747314453\n",
      "epoch: 900, loss = 88.72185516357422\n",
      "epoch: 1000, loss = 86.34058380126953\n",
      "best loss: 85.95503234863281 in epoch 933\n",
      "\n",
      "Layer 2\n",
      "epoch: 100, loss = 266.7696533203125\n",
      "epoch: 200, loss = 248.248046875\n",
      "epoch: 300, loss = 240.50186157226562\n",
      "epoch: 400, loss = 231.77664184570312\n",
      "epoch: 500, loss = 221.9067840576172\n",
      "epoch: 600, loss = 210.6245574951172\n",
      "epoch: 700, loss = 219.7314910888672\n",
      "epoch: 800, loss = 711.648193359375\n",
      "epoch: 900, loss = 194.93646240234375\n",
      "epoch: 1000, loss = 197.35488891601562\n",
      "best loss: 183.41798400878906 in epoch 975\n",
      "\n",
      "Layer 1\n",
      "epoch: 100, loss = 767.130859375\n",
      "epoch: 200, loss = 725.8720703125\n",
      "epoch: 300, loss = 692.8726196289062\n",
      "epoch: 400, loss = 707.8927612304688\n",
      "epoch: 500, loss = 604.6849365234375\n",
      "epoch: 600, loss = 585.2975463867188\n",
      "epoch: 700, loss = 592.4881591796875\n",
      "epoch: 800, loss = 494.00567626953125\n",
      "epoch: 900, loss = 525.465087890625\n",
      "epoch: 1000, loss = 465.4630126953125\n",
      "best loss: 465.4630126953125 in epoch 1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_losses = []\n",
    "\n",
    "for i in range(11):\n",
    "    best_loss = np.inf\n",
    "    best_epoch = 0\n",
    "\n",
    "    print(f'Layer {11-i}')\n",
    "\n",
    "    optimizer = torch.optim.Adam(models[i].parameters(), lr=learning_rate)\n",
    "    model = models[i]\n",
    "\n",
    "    inputs = df_to_tensor(X_train)\n",
    "    outputs = df_to_tensor(y_train.iloc[:,10-i]).reshape(-1,1)\n",
    "\n",
    "    for epoch in range(args['epochs']):\n",
    "        # empty gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        pred = model(inputs)\n",
    "\n",
    "        # loss\n",
    "        loss = criterion(pred, outputs)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % int(args['epochs']/10) == 0:\n",
    "            print(f'epoch: {epoch+1}, loss = {loss}')\n",
    "\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "    best_losses.append(best_loss.item())\n",
    "    \n",
    "    X_train[f'layer {11-i} predictions'] = pd.DataFrame(pred.detach().numpy())\n",
    "    print(f'best loss: {best_loss} in epoch {best_epoch}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNtUlEQVR4nO3deXhTVf4/8HeSNumWpXvpBmWnUEoBC5VdkMqirCqKiMKMjhYRmXFhVFRcQPy6IQjizA8YBEURUFBkE5GlbC1l37cWSltKSdI1TZP7+6NtIJatJelNbt+v58lDe5fcz43M5M05554jEwRBABEREZFEycUugIiIiMiZGHaIiIhI0hh2iIiISNIYdoiIiEjSGHaIiIhI0hh2iIiISNIYdoiIiEjSGHaIiIhI0hh2iIiISNIYdoiIiEjSGHaIRLRw4ULIZDK7V0hICPr06YO1a9c67bolJSV4++238ccff9zR8X/88QdkMhmWL1/utJoaGplMhgkTJohdBlGD4CF2AUQETJs2DTExMRAEAbm5uVi4cCEGDhyI1atXY/DgwQ6/XklJCd555x0AQO/evR3+/kREroRhh8gFDBgwAJ07d7b9Pn78eISGhuLbb791Stgh5ysrK4NSqYRcLo0G9OLiYvj6+opdBlGdSON/hUQSo9Pp4O3tDQ8P+3+PWK1WfPbZZ2jbti28vLwQGhqKZ599FlevXrU7bu/evUhOTkZQUBC8vb0RExODcePGAQDOnTuH4OBgAMA777xj6z57++2377ruM2fO4OGHH0ZAQAB8fHzQtWtX/PLLLzWO++KLL9C2bVv4+PjA398fnTt3xtKlS237CwsLMWnSJDRp0gQqlQohISG4//77kZ6eftsa9u3bhwEDBkCj0cDPzw99+/bFzp07bfv37t0LmUyGRYsW1Th33bp1kMlkWLNmjW3bxYsXMW7cOISGhkKlUqFt27b4f//v/9mdV93N99133+GNN95AREQEfHx8YDQa7+hzu5mffvoJgwYNQnh4OFQqFZo1a4Z3330XFovFdsxbb70FT09PXL58ucb5zzzzDHQ6HcrKymzb1q5dix49esDX1xdqtRqDBg3C4cOH7c576qmn4Ofnh9OnT2PgwIFQq9UYPXo0AODkyZMYMWIEwsLC4OXlhcjISIwaNQoGg+Gu7pXImdiyQ+QCDAYD8vPzIQgC8vLy8MUXX6CoqAhPPPGE3XHPPvssFi5ciKeffhoTJ07E2bNnMXv2bOzbtw/bt2+Hp6cn8vLy0L9/fwQHB+O1116DTqfDuXPnsGLFCgBAcHAw5s6di+eeew7Dhg3D8OHDAQDt27e/q3vIzc3Fvffei5KSEkycOBGBgYFYtGgRHnroISxfvhzDhg0DAHz99deYOHEiRo4ciRdffBFlZWU4cOAAdu3ahccffxwA8I9//APLly/HhAkTEBsbiytXrmDbtm04evQoOnbseNMaDh8+jB49ekCj0eCVV16Bp6cnvvrqK/Tu3RtbtmxBly5d0LlzZzRt2hTff/89xo4da3f+smXL4O/vj+TkZNs9de3a1Ta+Jjg4GGvXrsX48eNhNBoxadIku/PfffddKJVK/Otf/4LJZIJSqbyrz3ThwoXw8/PD5MmT4efnh99//x1Tp06F0WjERx99BAAYM2YMpk2bhmXLltmNASovL8fy5csxYsQIeHl5AQAWL16MsWPHIjk5GR9++CFKSkowd+5cdO/eHfv27UOTJk1s51dUVCA5ORndu3fH//3f/8HHxwfl5eVITk6GyWTCCy+8gLCwMFy8eBFr1qyBXq+HVqu9q/slchqBiESzYMECAUCNl0qlEhYuXGh37NatWwUAwpIlS+y2//bbb3bbV65cKQAQ9uzZc9PrXr58WQAgvPXWW3dU5+bNmwUAwg8//HDTYyZNmiQAELZu3WrbVlhYKMTExAhNmjQRLBaLIAiCMGTIEKFt27a3vJ5WqxVSUlLuqLbrDR06VFAqlcLp06dt27KzswW1Wi307NnTtm3KlCmCp6enUFBQYNtmMpkEnU4njBs3zrZt/PjxQqNGjYT8/Hy764waNUrQarVCSUmJIAjXPp+mTZvatt0OgNve443e69lnnxV8fHyEsrIy27akpCShS5cudsetWLFCACBs3rxZEITK/xY6nU74+9//bndcTk6OoNVq7baPHTtWACC89tprdsfu27fvtn8PiFwRu7GIXMCcOXOwYcMGbNiwAd988w369OmDv/3tb7bWGAD44YcfoNVqcf/99yM/P9/26tSpE/z8/LB582YAlV1gALBmzRqYzeZ6u4dff/0ViYmJ6N69u22bn58fnnnmGZw7dw5Hjhyx1XfhwgXs2bPnpu+l0+mwa9cuZGdn3/H1LRYL1q9fj6FDh6Jp06a27Y0aNcLjjz+Obdu22bqVHn30UZjNZrvPd/369dDr9Xj00UcBAIIg4Mcff8SDDz4IQRDsPvPk5GQYDIYa3Wpjx46Ft7f3Hdd8O9e/V2FhIfLz89GjRw+UlJTg2LFjtn1PPvkkdu3ahdOnT9u2LVmyBFFRUejVqxcAYMOGDdDr9Xjsscfs7kWhUKBLly62vz/Xe+655+x+r265WbduHUpKShx2n0TOxrBD5AISExPRr18/9OvXD6NHj8Yvv/yC2NhYTJgwAeXl5QAqx0oYDAaEhIQgODjY7lVUVIS8vDwAQK9evTBixAi88847CAoKwpAhQ7BgwQKYTCan3sP58+fRqlWrGtvbtGlj2w8Ar776Kvz8/JCYmIgWLVogJSUF27dvtztn5syZOHToEKKiopCYmIi3334bZ86cueX1L1++jJKSkpvWYLVakZWVBQCIj49H69atsWzZMtsxy5YtQ1BQEO677z7b++n1esyfP7/G5/30008DgO0zrxYTE3PLGmvr8OHDGDZsGLRaLTQaDYKDg21dm9ePkXn00UehUqmwZMkS2741a9Zg9OjRkMlkACr//gDAfffdV+N+1q9fX+NePDw8EBkZWeP+Jk+ejP/85z8ICgpCcnIy5syZw/E65PI4ZofIBcnlcvTp0weff/45Tp48ibZt28JqtSIkJMT2hfZX1YOOq+fD2blzJ1avXo1169Zh3Lhx+Pjjj7Fz5074+fnV563U0KZNGxw/fhxr1qzBb7/9hh9//BFffvklpk6dansc/pFHHkGPHj2wcuVKrF+/Hh999BE+/PBDrFixAgMGDHBIHY8++ijef/995OfnQ61W4+eff8Zjjz1mGxRutVoBAE888USNsT3V/jrOyZGtOnq9Hr169YJGo8G0adPQrFkzeHl5IT09Ha+++qqtPgDw9/fH4MGDsWTJEkydOhXLly+HyWSyG/NVffzixYsRFhZW43p/HQyvUqlu+CTZxx9/jKeeego//fQT1q9fj4kTJ2L69OnYuXNnjXBE5DLE7kcjasiqx+zcaHxNSkqKAEDYuXOnIAiC8PzzzwsKheKOx4Rcb8mSJQIA4euvvxYEQRDy8/MdPmanZcuWQmJiYo3tM2bMEAAIBw8evOF5JpNJGDRokKBQKITS0tIbHpObmytEREQI3bp1u+n1KyoqBB8fH+GRRx6pse8f//iHIJfLBYPBYNt25MgRAYAwb9482zin6vEt1e+nVquFxx577KbXrHYnn89f4TZjdqpr2rJli932+fPn16hVEAThp59+EgAIu3fvFvr06SMkJCTY7f/+++8FAMK6detuW9vYsWMFX1/fO7qP7du3CwCE119//Y6OJxIDu7GIXJDZbMb69euhVCpt3UCPPPIILBYL3n333RrHV1RUQK/XAwCuXr0KQRDs9nfo0AEAbF1ZPj4+AGA7xxEGDhyI3bt3IzU11batuLgY8+fPR5MmTRAbGwsAuHLlit15SqUSsbGxEAQBZrMZFoulRrdISEgIwsPDb9kVp1Ao0L9/f/z00084d+6cbXtubi6WLl2K7t27Q6PR2La3adMGcXFxWLZsGZYtW4ZGjRqhZ8+edu83YsQI/Pjjjzh06FCN693oUW9HUigUAGD337K8vBxffvnlDY8fMGAAgoKC8OGHH2LLli01nuRLTk6GRqPBBx98cMOxXHdyP0ajERUVFXbb4uLiIJfLnd5NSnQ32I1F5ALWrl1rG3Cal5eHpUuX4uTJk3jttddsX9C9evXCs88+i+nTpyMjIwP9+/eHp6cnTp48iR9++AGff/45Ro4ciUWLFuHLL7/EsGHD0KxZMxQWFuLrr7+GRqPBwIEDAVR2t8TGxmLZsmVo2bIlAgIC0K5dO7Rr1+6Wdf744492A2OrjR07Fq+99hq+/fZbDBgwABMnTkRAQAAWLVqEs2fP4scff7R1ifTv3x9hYWHo1q0bQkNDcfToUcyePRuDBg2CWq2GXq9HZGQkRo4cifj4ePj5+WHjxo3Ys2cPPv7441vW995772HDhg3o3r07nn/+eXh4eOCrr76CyWTCzJkzaxz/6KOPYurUqfDy8sL48eNrdNvMmDEDmzdvRpcuXfD3v/8dsbGxKCgoQHp6OjZu3IiCgoJb1nM7e/fuxXvvvVdje+/evXHvvffC398fY8eOxcSJEyGTybB48eIaQbaap6cnRo0ahdmzZ0OhUOCxxx6z26/RaDB37lyMGTMGHTt2xKhRoxAcHIzMzEz88ssv6NatG2bPnn3Len///XdMmDABDz/8MFq2bImKigosXrzYFgyJXJa4DUtEDduNHj338vISOnToIMydO1ewWq01zpk/f77QqVMnwdvbW1Cr1UJcXJzwyiuvCNnZ2YIgCEJ6errw2GOPCdHR0YJKpRJCQkKEwYMHC3v37rV7nx07dgidOnUSlErlbbu0qrtpbvaqftz89OnTwsiRIwWdTid4eXkJiYmJwpo1a+ze66uvvhJ69uwpBAYGCiqVSmjWrJnw8ssv27qYTCaT8PLLLwvx8fGCWq0WfH19hfj4eOHLL7+8o880PT1dSE5OFvz8/AQfHx+hT58+wo4dO2547MmTJ233sG3bthsek5ubK6SkpAhRUVGCp6enEBYWJvTt21eYP39+jc+ntt1YN3u9++67giBUdhF17dpV8Pb2FsLDw4VXXnlFWLdu3Q27sQRBEHbv3i0AEPr373/T627evFlITk4WtFqt4OXlJTRr1kx46qmn7P5+3Kwb68yZM8K4ceOEZs2aCV5eXkJAQIDQp08fYePGjXd830RikAnCTf6ZQEREbmX//v3o0KED/ve//2HMmDFil0PkMjhmh4hIIr7++mv4+fnZZsUmokocs0NE5OZWr16NI0eOYP78+ZgwYQIX7CT6C3ZjERG5uSZNmiA3NxfJyclYvHgx1Gq12CURuRSGHSIiIpI0jtkhIiIiSWPYISIiIknjAGVUrhmTnZ0NtVptWzSPiIiIXJsgCCgsLER4ePgN13KrxrADIDs7G1FRUWKXQURERHWQlZV1y4VoGXYA25MLWVlZdmvnEBERkesyGo2Iioq67ROIDDuAretKo9Ew7BAREbmZ2w1B4QBlIiIikjSGHSIiIpI0hh0iIiKSNIYdIiIikjSGHSIiIpI0hh0iIiKSNIYdIiIikjSGHSIiIpI0hh0iIiKSNIYdIiIikjSGHSIiIpI0hh0iIiKSNIYdJyqvsCIjSw+LVRC7FCIiogaLYcdJrFYBXT7YiKFztuP05SKxyyEiImqwGHacRC6XoVWYGgCwL/OqyNUQERE1XAw7TpQQ7Q8A2JepF7cQIiKiBoxhx4kSonQAgHS27BAREYmGYceJqlt2TuYVwVhmFrkaIiKiholhx4mC1SpEBXhDEIADWQaxyyEiImqQGHacLCGqetwOu7KIiIjEwLDjZAnROgDAviy9qHUQERE1VAw7TnbtiayrEAROLkhERFTfGHacLLaRBkoPOa6WmHH+SonY5RARETU4DDtOpvSQo124BgCwL4vjdoiIiOobw0494OSCRERE4mHYqQe2QcoMO0RERPWOYaceVLfsHL1kRGm5ReRqiIiIGhaGnXoQrvVCiFqFCquAQ9mcXJCIiKg+MezUA5lMdl1XFgcpExER1SeGnXrCQcpERETiYNipJx2rwk46JxckIiKqVww79SQuQguFXIZcowmXDGVil0NERNRgMOzUE2+lAm0aqQGwK4uIiKg+MezUI66ATkREVP8YduoRV0AnIiKqfww79aj6iayDFw0or7CKXA0REVHDwLBTj5oE+kDn44nyCiuOXjKKXQ4REVGDwLBTj2QyGRKidAA4boeIiKi+MOzUM9vkghy3Q0REVC8YduoZV0AnIiKqXww79Sw+SgeZDMgsKEF+kUnscoiIiCSPYaeeabw80TzYDwCQwdYdIiIip2PYEcG1+XY4SJmIiMjZGHZE0JEroBMREdUbhh0RVD+RtT9LD4uVK6ATERE5E8OOCJqH+MFP5YHicgtO5BaKXQ4REZGkMeyIQCGXIT5KC4BdWURERM7GsCMSroBORERUPxh2RMIV0ImIiOoHw45IOlStkXUqrwiGUrO4xRAREUkYw45IAv1UaBzoA6DyqSwiIiJyDoYdEV1bAV0vah1ERERSxrAjomsroHOQMhERkbMw7Ijo+hXQBYGTCxIRETkDw46IWodpoPKQw1Bqxtn8YrHLISIikiSGHREpPeSIi+DkgkRERM7EsCOyjo05boeIiMiZXCbszJgxAzKZDJMmTbJtKysrQ0pKCgIDA+Hn54cRI0YgNzfX7rzMzEwMGjQIPj4+CAkJwcsvv4yKiop6rr7u+EQWERGRc7lE2NmzZw+++uortG/f3m77Sy+9hNWrV+OHH37Ali1bkJ2djeHDh9v2WywWDBo0COXl5dixYwcWLVqEhQsXYurUqfV9C3VW/UTWsZxClJS7T0gjIiJyF6KHnaKiIowePRpff/01/P39bdsNBgP++9//4pNPPsF9992HTp06YcGCBdixYwd27twJAFi/fj2OHDmCb775Bh06dMCAAQPw7rvvYs6cOSgvLxfrlmolTOuFRlovWKwCDlwwiF0OERGR5IgedlJSUjBo0CD069fPbntaWhrMZrPd9tatWyM6OhqpqakAgNTUVMTFxSE0NNR2THJyMoxGIw4fPlw/N+AA1z+CTkRERI7lIebFv/vuO6Snp2PPnj019uXk5ECpVEKn09ltDw0NRU5Oju2Y64NO9f7qfTdjMplgMplsvxuNxrregkMkRPnj14M5XAGdiIjICURr2cnKysKLL76IJUuWwMvLq16vPX36dGi1WtsrKiqqXq//V9evgM7JBYmIiBxLtLCTlpaGvLw8dOzYER4eHvDw8MCWLVswa9YseHh4IDQ0FOXl5dDr9Xbn5ebmIiwsDAAQFhZW4+ms6t+rj7mRKVOmwGAw2F5ZWVmOvblaahehhYdchsuFJlzUl4paCxERkdSIFnb69u2LgwcPIiMjw/bq3LkzRo8ebfvZ09MTmzZtsp1z/PhxZGZmIikpCQCQlJSEgwcPIi8vz3bMhg0boNFoEBsbe9Nrq1QqaDQau5eYvDwViA2vrIHjdoiIiBxLtDE7arUa7dq1s9vm6+uLwMBA2/bx48dj8uTJCAgIgEajwQsvvICkpCR07doVANC/f3/ExsZizJgxmDlzJnJycvDGG28gJSUFKpWq3u/pbiRE6XDgggH7MvV4MD5c7HKIiIgkQ/SnsW7l008/xeDBgzFixAj07NkTYWFhWLFihW2/QqHAmjVroFAokJSUhCeeeAJPPvkkpk2bJmLVdcMV0ImIiJxDJnBELIxGI7RaLQwGg2hdWuevFKPXR39AqZDj4Dv9ofJQiFIHERGRu7jT72+XbtlpSKIDfBDgq0S5xYoj2eI+Ck9ERCQlDDsuQiaTcZ0sIiIiJ2DYcSHXVkDXi1sIERGRhDDsuJBrLTscpExEROQoDDsupH2UDjIZcOFqKfIKy8Quh4iISBIYdlyIn8oDrULVADhuh4iIyFEYdlwMV0AnIiJyLIYdF5MQVTVImeN2iIiIHIJhx8VUt+wcuGBAhcUqbjFEREQSwLDjYpoF+0Gt8kCp2YLjuYVil0NEROT2GHZcjFwuQweO2yEiInIYhh0XxJmUiYiIHIdhxwVxBXQiIiLHYdhxQR2qWnbOXC6GvqRc3GKIiIjcHMOOC/L3VSImyBcAkMF1soiIiO4Kw46L4uSCREREjsGw46KujdvRi1sIERGRm2PYcVHVT2RlZF6F1SqIWwwREZEbY9hxUa3D1PDylMNYVoEz+cVil0NEROS2GHZclIdCjvaROgBAOtfJIiIiqjOGHRfGQcpERER3j2HHhXEFdCIiorvHsOPCqlt2TuQWoshUIW4xREREbophx4WFarwQofOGVQAOXNCLXQ4REZFbYthxcVwBnYiI6O4w7Lg4roBORER0dxh2XFz1TMoZWVchCJxckIiIqLYYdlxc23ANPBUy5BeV48LVUrHLISIicjsMOy7Oy1OBtuFaAJxckIiIqC4YdtwAJxckIiKqO4YdN8AV0ImIiOqOYccNVD+RdSTbgDKzRdxiiIiI3AzDjhuI9PdGkJ8KZouAw9lGscshIiJyKww7bkAmk103boeDlImIiGqDYcdNcJAyERFR3TDsuAmugE5ERFQ3DDtuon2kFnIZkG0oQ46hTOxyiIiI3AbDjpvwVXmgVZgGQOXSEURERHRnGHbcCMftEBER1R7DjhvhCuhERES1x7DjRqpnUj5wUQ+zxSpyNURERO6BYceNNA3yhcbLA2VmK47nFIpdDhERkVtg2HEjcrns2jpZfASdiIjojjDsuBkOUiYiIqodhh03wxXQiYiIaodhx810iNQBAM7mF+Nqcbm4xRAREbkBhh03o/XxRLNgXwBABlt3iIiIbothxw1Vd2Wlc5AyERHRbTHsuCEOUiYiIrpzDDtuqHoF9IwsPSxWQeRqiIiIXBvDjhtqGeoHH6UCRaYKnL5cJHY5RERELo1hxw15KORoH6kFwMkFiYiIbodhx01dm0lZL24hRERELo5hx01xBXQiIqI7w7Djpqpbdk7kFaKwzCxyNURERK6LYcdNBatViArwhiAABy4YxC6HiIjIZTHsuLHqR9A5SJmIiOjmGHbcGCcXJCIiuj2GHTd2/QrogsDJBYmIiG6EYceNxTbSQOkhR0FxOTILSsQuh4iIyCUx7LgxpYcc7cI1ANiVRUREdDMMO26OK6ATERHdmqhhZ+7cuWjfvj00Gg00Gg2SkpKwdu1a2/6ysjKkpKQgMDAQfn5+GDFiBHJzc+3eIzMzE4MGDYKPjw9CQkLw8ssvo6Kior5vRTQcpExERHRrooadyMhIzJgxA2lpadi7dy/uu+8+DBkyBIcPHwYAvPTSS1i9ejV++OEHbNmyBdnZ2Rg+fLjtfIvFgkGDBqG8vBw7duzAokWLsHDhQkydOlWsW6p31S07Ry8ZUVpuEbkaIiIi1yMTXOwxnoCAAHz00UcYOXIkgoODsXTpUowcORIAcOzYMbRp0wapqano2rUr1q5di8GDByM7OxuhoaEAgHnz5uHVV1/F5cuXoVQq7+iaRqMRWq0WBoMBGo3GaffmDIIgoMsHm5BXaMIP/0jCPU0CxC6JiIioXtzp97fLjNmxWCz47rvvUFxcjKSkJKSlpcFsNqNfv362Y1q3bo3o6GikpqYCAFJTUxEXF2cLOgCQnJwMo9Foax2SOplMdl1XFsftEBER/ZWH2AUcPHgQSUlJKCsrg5+fH1auXInY2FhkZGRAqVRCp9PZHR8aGoqcnBwAQE5Ojl3Qqd5fve9mTCYTTCaT7Xej0eiguxFHQrQ/1h3O5bgdIiKiGxC9ZadVq1bIyMjArl278Nxzz2Hs2LE4cuSIU685ffp0aLVa2ysqKsqp13M2roBORER0c6KHHaVSiebNm6NTp06YPn064uPj8fnnnyMsLAzl5eXQ6/V2x+fm5iIsLAwAEBYWVuPprOrfq4+5kSlTpsBgMNheWVlZjr2petY+UgeFXIYcYxkuGUrFLoeIiMiliB52/spqtcJkMqFTp07w9PTEpk2bbPuOHz+OzMxMJCUlAQCSkpJw8OBB5OXl2Y7ZsGEDNBoNYmNjb3oNlUple9y9+uXOvJUKtGmkBsDWHSIior8SdczOlClTMGDAAERHR6OwsBBLly7FH3/8gXXr1kGr1WL8+PGYPHkyAgICoNFo8MILLyApKQldu3YFAPTv3x+xsbEYM2YMZs6ciZycHLzxxhtISUmBSqUS89bqXUKUPw5dNGJf5lUMjGskdjlEREQuQ9Swk5eXhyeffBKXLl2CVqtF+/btsW7dOtx///0AgE8//RRyuRwjRoyAyWRCcnIyvvzyS9v5CoUCa9aswXPPPYekpCT4+vpi7NixmDZtmli3JJqEaB0W7zzPlh0iIqK/cLl5dsTgzvPsVDubX4w+//cHVB5yHHw7GUoPl+uhJCIicii3m2eH7k6TQB/ofDxhqrDiWI57P0pPRETkSAw7EiGTyfgIOhER0Q0w7EgIV0AnIiKqiWFHQrgCOhERUU0MOxISH6WDTAZkFpQgv8h0+xOIiIgaAIYdCdF4eaJ5sB8AIIOtO0RERAAYdiTH1pWVxXE7REREAMOO5FQPUua4HSIiokoMOxLTsSrs7M/Sw2Jt8PNFEhERMexITfMQP/ipPFBcbsHJvEKxyyEiIhIdw47EKOQyxEdpAbAri4iICGDYkaSEqOpxOxykTERExLAjQZxckIiI6BqGHQnqULVG1sm8IhhKzeIWQ0REJDKGHQkK9FOhcaAPAODABb24xRAREYmMYUeiuAI6ERFRJYYdieIK6ERERJUYdiTq+kHKgsDJBYmIqOFi2JGo1mEaqDzkMJSacTa/WOxyiIiIRMOwI1FKDzniIji5IBEREcOOhHEFdCIiIoYdSeMK6ERERAw7kla9AvqxnEKUlFeIXA0REZE4GHYkLEzrhUZaL1isAg5eMIhdDhERkSgYdiTu2rgdvah1EBERiYVhR+K4AjoRETV0DDsSV92yk87JBYmIqIFi2JG4dhFaeMhluFxoQrahTOxyiIiI6h3DjsR5eSoQG64BwK4sIiJqmOoUdrKysnDhwgXb77t378akSZMwf/58hxVGjsMV0ImIqCGrU9h5/PHHsXnzZgBATk4O7r//fuzevRuvv/46pk2b5tAC6e5dm1yQLTtERNTw1CnsHDp0CImJiQCA77//Hu3atcOOHTuwZMkSLFy40JH1kQNUD1I+dNEIU4VF3GKIiIjqWZ3CjtlshkqlAgBs3LgRDz30EACgdevWuHTpkuOqI4eIDvBBgK8S5RYrjmQbxS6HiIioXtUp7LRt2xbz5s3D1q1bsWHDBjzwwAMAgOzsbAQGBjq0QLp7MpmM43aIiKjBqlPY+fDDD/HVV1+hd+/eeOyxxxAfHw8A+Pnnn23dW+RaOJMyERE1VB51Oal3797Iz8+H0WiEv7+/bfszzzwDHx8fhxVHjtORg5SJiKiBqlPLTmlpKUwmky3onD9/Hp999hmOHz+OkJAQhxZIjtE+SgeZDLhwtRR5hZxckIiIGo46hZ0hQ4bgf//7HwBAr9ejS5cu+PjjjzF06FDMnTvXoQWSY/ipPNAqVA0AyOC4HSIiakDqFHbS09PRo0cPAMDy5csRGhqK8+fP43//+x9mzZrl0ALJcThuh4iIGqI6hZ2SkhKo1ZWtBOvXr8fw4cMhl8vRtWtXnD9/3qEFkuNwBXQiImqI6hR2mjdvjlWrViErKwvr1q1D//79AQB5eXnQaDQOLZAcp7pl58AFAyosVnGLISIiqid1CjtTp07Fv/71LzRp0gSJiYlISkoCUNnKk5CQ4NACyXGaBftBrfJASbkFJ3KLxC6HiIioXtQp7IwcORKZmZnYu3cv1q1bZ9vet29ffPrppw4rjhxLLpehg23cDruyiIioYahT2AGAsLAwJCQkIDs727YCemJiIlq3bu2w4sjxOJMyERE1NHUKO1arFdOmTYNWq0Xjxo3RuHFj6HQ6vPvuu7BaORbElXEFdCIiamjqNIPy66+/jv/+97+YMWMGunXrBgDYtm0b3n77bZSVleH99993aJHkOB2qWnZOXy6GvqQcOh+luAURERE5WZ3CzqJFi/Cf//zHtto5ALRv3x4RERF4/vnnGXZcmL+vEjFBvjibX4yMLD16t+KM10REJG116sYqKCi44dic1q1bo6Cg4K6LIufiuB0iImpI6hR24uPjMXv27BrbZ8+ejfbt2991UeRcCY2rxu1wJmUiImoA6tSNNXPmTAwaNAgbN260zbGTmpqKrKws/Prrrw4tkByvumUnI/MqrFYBcrlM3IKIiIicqE4tO7169cKJEycwbNgw6PV66PV6DB8+HIcPH8bixYsdXSM5WOswNbw85TCWVeBMfrHY5RARETmVTBAEwVFvtn//fnTs2BEWi8VRb1kvjEYjtFotDAZDg1nu4pGvUrH7bAE+GtkeD3eOErscIiKiWrvT7+86TypI7o0roBMRUUPBsNNAXVsBXS9uIURERE7GsNNAVbfsHM8xothUIW4xRERETlSrp7GGDx9+y/16vf5uaqF6FKrxQoTOGxf1pThwwYCkZoFil0REROQUtQo7Wq32tvuffPLJuyqI6k+HaB0u6kuxL+sqww4REUlWrcLOggULnFUHiSAhSodfDlziuB0iIpI0jtlpwK6tgK6HA2cgICIicikMOw1Y23ANPBUy5BeZcOFqqdjlEBEROQXDTgPm5alAbHjlOKz0zKsiV0NEROQcDDsNHFdAJyIiqRM17EyfPh333HMP1Go1QkJCMHToUBw/ftzumLKyMqSkpCAwMBB+fn4YMWIEcnNz7Y7JzMzEoEGD4OPjg5CQELz88suoqODcMXeiI1dAJyIiiRM17GzZsgUpKSnYuXMnNmzYALPZjP79+6O4+NrilC+99BJWr16NH374AVu2bEF2drbdfD8WiwWDBg1CeXk5duzYgUWLFmHhwoWYOnWqGLfkdqpbdo5kG1Bmdq81zYiIiO6EQxcCvVuXL19GSEgItmzZgp49e8JgMCA4OBhLly7FyJEjAQDHjh1DmzZtkJqaiq5du2Lt2rUYPHgwsrOzERoaCgCYN28eXn31VVy+fBlKpfK2122IC4FWEwQB97y/CflFJvz43L3oVNXSQ0RE5OrcciFQg8EAAAgICAAApKWlwWw2o1+/frZjWrdujejoaKSmpgIAUlNTERcXZws6AJCcnAyj0YjDhw/XY/XuSSaTXVsUlIOUiYhIglwm7FitVkyaNAndunVDu3btAAA5OTlQKpXQ6XR2x4aGhiInJ8d2zPVBp3p/9b4bMZlMMBqNdq+GjCugExGRlLlM2ElJScGhQ4fw3XffOf1a06dPh1artb2ioqKcfk1XVr0CegafyCIiIglyibAzYcIErFmzBps3b0ZkZKRte1hYGMrLy2ssMJqbm4uwsDDbMX99Oqv69+pj/mrKlCkwGAy2V1ZWlgPvxv20j9RCLgMu6kuRaywTuxwiIiKHEjXsCIKACRMmYOXKlfj9998RExNjt79Tp07w9PTEpk2bbNuOHz+OzMxMJCUlAQCSkpJw8OBB5OXl2Y7ZsGEDNBoNYmNjb3hdlUoFjUZj92rIfFUeaBVW+Rlwvh0iIpIaUcNOSkoKvvnmGyxduhRqtRo5OTnIyclBaWnl0gVarRbjx4/H5MmTsXnzZqSlpeHpp59GUlISunbtCgDo378/YmNjMWbMGOzfvx/r1q3DG2+8gZSUFKhUKjFvz61cG7fDQcpERCQtooaduXPnwmAwoHfv3mjUqJHttWzZMtsxn376KQYPHowRI0agZ8+eCAsLw4oVK2z7FQoF1qxZA4VCgaSkJDzxxBN48sknMW3aNDFuyW1xJmUiIpIql5pnRywNeZ6daqfyitDvky3w8pTj0NvJ8FC4xHAuIiKim3LLeXZIPE2DfKHx8kCZ2YpjOYVil0NEROQwDDsEAJDLZegQXbVOFicXJCIiCWHYIZuOtpmU9aLWQURE5EgMO2STEM0V0ImISHoYdsimQ6QOAHA2vxhXi8vFLYaIiMhBGHbIRuvjiWbBvgCATcfybnM0ERGRe2DYITtDO0QAAGasPQZDiVnkaoiIiO4eww7ZeaZXUzQP8UN+kQnT1x4VuxwiIqK7xrBDdlQeCkwfHgcA+G5PFnaeuSJyRURERHeHYYdquKdJAB7vEg0A+PfKgygzW0SuiIiIqO4YduiGXn2gNYLVKpy5XIwv/zgtdjlERER1xrBDN6T19sQ7D7UFAMz94xRO5HIJCSIick8MO3RTA9qFoV+bUJgtAqasOAirtcGvGUtERG6IYYduSiaTYdqQtvBVKpB2/iqW7s4UuyQiIqJaY9ihWwrXeePl5FYAgA/XHkOusUzkioiIiGqHYYdua0xSE3SI0qHQVIG3fjosdjlERES1wrBDt6WQyzB9eBw85DL8djgH6w7niF0SERHRHWPYoTvSppEGz/RsCgB466fDKCzjUhJEROQeGHbojk3s2wJNAn2QYyzDR+uOi10OERHRHWHYoTvm5anAB8Mql5JYvPM80s5fFbkiIiKi22PYoVq5t3kQRnaKhCAA/15xEOUVVrFLIiIiuiWGHaq11we2QYCvEsdzC/H11jNil0NERHRLDDtUa/6+SkwdHAsA+HzTSZy5XCRyRURERDfHsEN1MqRDOHq2DEZ5hRX/XnkQgsClJIiIyDUx7FCdyGQyvD+0Hbw85dh5pgA/pF0QuyQiIqIbYtihOosK8MHk+1sCAN7/5Sjyi0wiV0RERFQTww7dlXHdYtA2XANDqRnTVh8RuxwiIqIaGHborngo5JgxvD3kMuDn/dnYfDxP7JKIiIjsMOzQXYuL1GJctxgAwBsrD6GkvELkioiIiK5h2CGHeOn+lojQeeOivhSfrD8hdjlEREQ2DDvkEL4qD7w3rB0A4P9tP4uDFwwiV0RERFSJYYccpk+rEDwUHw6rALy24gAqLFxKgoiIxMewQw715uBYaL09cTjbiAXbz4ldDhEREcMOOVawWoXXB7YBAHyy4QSyCkpEroiIiBo6hh1yuIc7R6Jr0wCUmi14fdUhLiVBRESiYtghh5PJZPhgWByUHnL8eeIyft6fLXZJRETUgDHskFM0DfbDxPuaAwCmrT6Cq8XlIldEREQNFcMOOc0zPZuhVagaV4rL8f6vR8Uuh4iIGiiGHXIapYccHwyPg0wGLE+7gB2n8sUuiYiIGiCGHXKqTo39MaZrYwDAv1ceRJnZInJFRETU0DDskNO9nNwKYRovnLtSglmbTopdDhERNTAMO+R0ai9PvDOkLQBg/p9ncPSSUeSKiIioIWHYoXqR3DYMD7QNQ4VVwJQVB2Gxcu4dIiKqHww7VG/efqgt1CoPZGTp8c3O82KXQ0REDQTDDtWbMK0XXhnQGgAw87djyNaXilwRERE1BAw7VK9GJ0ajU2N/FJdbMPUnLiVBRETOx7BD9Uoul2H68Dh4KmTYeDQPvx3KEbskIiKSOIYdqnctQ9V4rlczAMBbPx+GodQsckVERCRlDDskiuf7NEfTIF/kFZrw4W/HxC6HiIgkjGGHROHlqcAHw+MAAEt3ZWLPuQKRKyIiIqli2CHRdG0aiFH3RAEApqw4CFMFl5IgIiLHY9ghUU0Z0AZBfiqcyivC3D9Oi10OERFJEMMOiUrr44m3HowFAHy5+TRO5RWKXBEREUkNww6JbnD7RrivdQjKLVb8e8UhWLmUBBERORDDDolOJpNh2pC28FEqsPtcAZbtzRK7JCIikhCGHXIJkf4++Gf/VgCAD349ijxjmcgVERGRVDDskMt46t4maB+pRWFZBd5ZfUTscoiISCIYdshlKKqWklDIZfjl4CVsPJIrdklERCQBDDvkUtqGa/G3HjEAgKk/HUKRqULkioiIyN15iF0A0V9N6tsSvx68hKyCUvzfuuN4+6G2YpfkcGcuF2H76SswV1ghABAEAYIACKj+E7BWbUPVfquAGsf89Txr1c+4bn+N8wShap/9ebDtr7r2dcegaptcJkMjnRcaB/qiSaAvmgT6IFitgkwmE+eDJCK6Aww75HK8lQp8MCwOY/67G4tSz2FoQgQ6ROnELuuuXSkyYfX+bKzMyMb+LL3Y5TiMj1JRFX587P8M8kGo2gtyOYMQEYlLJghCg5/UxGg0QqvVwmAwQKPRiF0OVZm8LAMr9l1E6zA1Vr/QHZ4K9+t1LTNbsOFILlbtu4gtJy6jomoOIYVchq5NAxDgq4IMgFxW+Qi+DABkgAyyqm2VP8uqf6465vrt8qpWFfttd/B+qDrmL9uqw0mN94MMFVYBF/UlOH+lBOeuFOPi1VLcaloklYccja8LQU2CKluEGgf6oJHWGwoGISK6C3f6/S1qy86ff/6Jjz76CGlpabh06RJWrlyJoUOH2vYLgoC33noLX3/9NfR6Pbp164a5c+eiRYsWtmMKCgrwwgsvYPXq1ZDL5RgxYgQ+//xz+Pn5iXBH5EivD2qDzcfzcCynEP/ZehbP9W4mdkl3xGoVsPPsFazadxFrD+ag8LpxR3ERWgxLiMCD8eEIVqtErNIxyiusuHD1Wvg5l1+Mc1dKcP5KMbKulsJUYcWJ3CKcyC2qca5SIUdUgHdV+KlsCaoORRE6b3i4YbglItckatgpLi5GfHw8xo0bh+HDh9fYP3PmTMyaNQuLFi1CTEwM3nzzTSQnJ+PIkSPw8vICAIwePRqXLl3Chg0bYDab8fTTT+OZZ57B0qVL6/t2yMEC/VR4Y1As/vnDfny28QQGtAtDkyBfscu6qRO5hViRfhE/ZVzEJcO1eYIidN4YmhCOYQkRaB6iFrFCx1N6yNE02A9Ng2v+48JssSJbX2oLP+fyq/68UoysglKUW6w4fbkYpy8X1zjXQy5DVIAPGgf62FqCqv+M9PeB0oNBiIjunMt0Y8lkMruWHUEQEB4ejn/+85/417/+BQAwGAwIDQ3FwoULMWrUKBw9ehSxsbHYs2cPOnfuDAD47bffMHDgQFy4cAHh4eF3dG12Y7kuQRAw5r+7se1UPro1D8Q347u41GDYPGMZft6fjZX7LuJwttG2Xe3lgUFxjTAsIQL3NAnguJW/sFgFZOtLbS1ClSGoMgydv1ICU4X1pufKZUCEv7ddCGpS1TIU6e8DL09FPd4JEYnJLbqxbuXs2bPIyclBv379bNu0Wi26dOmC1NRUjBo1CqmpqdDpdLagAwD9+vWDXC7Hrl27MGzYMDFKJweSyWR4f1g79P/0T2w/dQUr0i9iRKdIUWsqKa/AusM5WLkvG9tOXraNWfGQy9C7VQiGd4zAfa1D+KV7C4qqlpuoAB90bxFkt89qFZBbWGZrCTp7pRjn86tDUQlKzRZkFZQiq6AUW0/av69MBoRrve3GCTUO9EGgnwoaL0+ovTyg8faEr1LhUqGZiJzLZcNOTk4OACA0NNRue2hoqG1fTk4OQkJC7PZ7eHggICDAdsyNmEwmmEwm2+9Go/Gmx5L4Ggf6YlK/lvjwt2N475cj6N0qGIF+9TvexWIVsP1UPlbtu4jfDuegpNxi25cQrcPwhAgMah+OAF9lvdYlRXK5DI203mik9UZSs0C7fYIg4HKhCedu0CJ0Lr8ERaYKXNSX4qK+FDtOX7n5NWSAxrsq/Hh52gUhjZcnNN4eUHt5QnPdNrWXB7RVP/t5eXBwNZEbcdmw40zTp0/HO++8I3YZVAt/6xGDn/dn4+glI9775Sg+fbSD068pCAKOXDJiZfpF/Lw/G3mF1wJy40AfDO0QgWEJES49jkhqZDIZQjReCNF4ITEmwG6fIAi4Ulz+l/FBJThfUAJDSTkKyypgKDWjwlo595C+xAx9iRlAaZ1q8VN52MKQLTTZ/exRFZKu//laeOK4I6L647JhJywsDACQm5uLRo0a2bbn5uaiQ4cOtmPy8vLszquoqEBBQYHt/BuZMmUKJk+ebPvdaDQiKirKgdWTo3kq5JgxPA5Dv9yOlfsuYlhCBHq2DHbKtS4ZSrFqXzZW7buI47mFtu06H0882D4cQxMi0DFax24QFyOTyRDkp0KQnwqdGgfc8BhBEFBmtsJYZkZhmRmG0oqqnytgLDXDWGaGsbQChWVmGK/bdv3+MnPleKIiUwWKTBXINtRt0VovT7ld69H1P2u9PTGwXSPERWrr/HkQ0TUuG3ZiYmIQFhaGTZs22cKN0WjErl278NxzzwEAkpKSoNfrkZaWhk6dOgEAfv/9d1itVnTp0uWm761SqaBSuf9jvw1NfJQOT93bBAu2n8Prqw5i/aRe8FY6ZlxMYZkZaw/lYNW+i0g9c8U2c7FSIUe/2BAM7RCB3q1C+K9xNyeTyeCtVMBbqUCoxqtO71FeYbULQ4VlFVUh6a/BqOb+wrIK21QEZWYryswmXL6uxfB6X/95Bq880Ap/79GUwZroLokadoqKinDq1Cnb72fPnkVGRgYCAgIQHR2NSZMm4b333kOLFi1sj56Hh4fbnthq06YNHnjgAfz973/HvHnzYDabMWHCBIwaNeqOn8Qi9/LP/q2w7lAOsgpK8dnGE5gysE2d38tssWLryctYuS8b6w/n2D0BlBgTgGEJERgY1whab09HlE4SofSQI9BPVedxYxargKLqAFTVknR9GDKWmXHwggGbjuXhg1+PYffZAvzfw/HQ+XA8GFFdifro+R9//IE+ffrU2D527FgsXLjQNqng/Pnzodfr0b17d3z55Zdo2bKl7diCggJMmDDBblLBWbNm1WpSQT567l42Hc3F+EV7oZDL8FNKN7SLuPOmfkEQcOCCASv3XcTq/dm4Ulxu29cs2BfDO0biofhwRAX4OKN0ojsiCAKW7MrEtDVHUF5hRYTOG7MfT0BCtL/YpRG5lDv9/naZeXbExLDjflKWpuOXA5cQF6HFqpRut30yJqugBKv2XcTKjIs4c90kdkF+SjwYXznhX1yElt0F5FIOXTQgZWk6zl8pgadChtcGtMG4bk3495SoCsNOLTDsuJ+8wjL0/XgLCssq8ObgWIzvHlPjGEOJGb8cvISV+y5gz7mrtu1ennL0jw3DsIQIdG8R5JZrblHDYSwz47UfD+DXg5XTaSS3DcXMkfHsXiUCw06tMOy4p293Z2LKioPwUSqw/qWeiPT3QXmFFZuP52Fl+kX8fiwP5ZbKcTgyGXBvs0AMS4hEcttQqL34RUHuQxAE/C/1PN7/5SjKLVZEBXhjzuMd0T5SJ3ZpRKJi2KkFhh33ZLUKGDV/J3afK0BS00A0DfbFLwcvVc2dUql1mBrDEiIwpEMEwrR1e/qGyFUcuKBHytJ0ZBWUwlMhw+sD22DsvezWooaLYacWGHbc16m8Igz8fKutBQcAQjUqDKma8K9NI/73JGkxlJrxyvL9WHc4FwAwMC4MM0a0h4atldQAMezUAsOOe/tf6jnM/v0UurcIwvCESCQ1C+RU/iRpgiBgwfZzmL72KMwWAY0DfTDn8Y61ejKRSAoYdmqBYYeI3FFGlh4pS9JxUV8KpUKONx+MxRNdotmtRQ3GnX5/8zEUIiI31SFKh18mdke/NiEot1jx5qpDeOHbfSiqmqWZiCox7BARuTGdjxJfP9kZrw9sAw+5DGsOXMKDX2zDkWyj2KURuQyGHSIiNyeTyfD3nk2x7NkkhGu9cDa/GMO+3I5vd2eCIxWIGHaIiCSjU2N//DKxB/q0CoapwoopKw7ipWUZKGa3FjVwDDtERBLi76vEf8feg1cfaA2FXIZVGdl4aPY2HM8pFLs0ItEw7BARSYxcLsNzvZvhu2e6IkzjhdOXizFkzjZ8vzdL7NKIRMGwQ0QkUfc0CcAvE7ujZ8tglJmteGX5Afzz+/0oKWe3FjUsDDtERBIW6KfCwqfuwb/6t4RcBvyYfgFDZm/HyVx2a1HDwbBDRCRxcrkME+5rgaV/74oQtQon84rw0OztWJF+QezSiOoFww4RUQPRtWkgfpnYA92bB6HUbMHk7/fjleX7UVpuEbs0Iqdi2CEiakCC1SosGpeIl/q1hEwGfL/3AobO2Y7Tl4vELo3IaRh2iIgaGIVchhf7tcCS8V0Q5KfC8dxCPPjFNvyUcVHs0oicgmGHiKiBurd5EH59sTuSmgaipNyCF7/LwJQVB1FmZrcWSQvDDhFRAxai9sI3f+uCifc1h0wGfLs7E8O+3IGz+cVil0bkMAw7REQNnEIuw+T+rbDo6UQE+ipx9JIRD36xDWsOZItdGpFDMOwQEREAoGfLYPz6Yg8kxgSgyFSBCUv34c1Vh9itRW6PYYeIiGxCNV5Y+rcueL53MwDA4p3nMXLeDpy/wm4tcl8MO0REZMdDIccrD7TGgqfvgb+PJw5dNGLwrG1Ye/CS2KUR1QnDDhER3VCfViH49cUe6NzYH4WmCjy3JB1v/3wYpgp2a5F7YdghIqKbaqT1xrfPdMWzvZoCABbuOIdH5qUiq6BE5MqI7hzDDhER3ZKnQo4pA9rgv2M7Q+vtif0XDBg0ayvWH84RuzSiO8KwQ0REd6Rvm1D8+mIPJETrYCyrwDOL0/DumiMor7CKXRrRLTHsEBHRHYvQeWPZM0n4W/cYAMB/t53FI1+l4sJVdmuR62LYISKiWlF6yPHG4FjMH9MJGi8PZGTpMWjWNizcfhbHcwphtQpil0hkRyYIQoP/W2k0GqHVamEwGKDRaMQuh4jIbWQVlGDC0nTsv2CwbdN4eaBTY390bhKATo390SFKBy9PhYhVklTd6fc3ww4YdoiI7kZ5hRULd5zFnyfykZ55FSXl9o+meypkaBuuxT1N/NGpcQA6N/FHkJ9KpGpJShh2aoFhh4jIMSosVhzLKcSecwXYe/4q9p4rQK7RVOO4mCBfdG7sj85NKluAmgb5QiaTiVAxuTOGnVpg2CEicg5BEHDhain2ni/A3nNXsffcVZzIK8Rfv3kCfJWVXV9V3V/tIjRQebDri26NYacWGHaIiOqPocSM9Myr2Hu+AHvOXcX+LD1Mf3l8XekhR3ykFp2bBKBzY390auwPnY9SpIrJVTHs1ALDDhGReMorrDiUbUDauavYc64Aaeev4kpxeY3jWoT42cLPPU0CEBXgza6vBo5hpxYYdoiIXIcgCDibX2wb87P3/FWcuVxz1fVgtco26PmeJv6IbaSBh4IzqjQkDDu1wLBDROTarhSZkHb+KtLOV7b+HLxogNli//Xl7alAQrTONu4nIVoHtZenSBVTfWDYqQWGHSIi91JmtuDABYNt4HPa+aswlJrtjpHLgNZhGtsTX50b+yNc5y1SxeQMDDu1wLBDROTerFYBpy4XVT3xVdn1lXmDldkjdN5VEx76o3PjALQKU0Mh57gfd8WwUwsMO0RE0pNnLMPe89cGPR/ONsLyl6UstN6e6N48CN1bBKFHiyBE+vuIVC3VBcNOLTDsEBFJX7GpAvuz9NhzrvKx932ZehSZKuyOaRrkix4tgtC9RTC6Ng3gmB8Xx7BTCww7REQNT4XFiv0XDNh2Mh9bT17Gviy9XcuPh1yGjtH+tlaf9pE6dnm5GIadWmDYISIiY5kZO09fwdaq8HPuiv2YH623J7o1D0SPFsHo3jwIUQHs8hIbw04tMOwQEdFfZRWU2ILP9lP5MJbZd3nFVHd5NQ9CUrNAdnmJgGGnFhh2iIjoViosVhy4eK3LKz3TvstLIZehY7SustWnRRDaR2g5wWE9YNipBYYdIiKqjcIyM1JPX8G2U/nYejIfZ/PtZ3jWeHmgW/Mg9GgRjB4t2OXlLAw7tcCwQ0REdyOroKQq+FzGtpM1u7yaBPrYgg+7vByHYacWGHaIiMhRLFYBBy7oq7q88pGeeRUVf+nySoiq7PLq0ZJdXneDYacWGHaIiMhZCsvM2HmmwNbqc+YvXV5qLw90axaEHi2D0KN5MKID2eV1pxh2aoFhh4iI6kt1l9e2k/nYdiq/xppejQN90KNF5XifpGaB0LDL66YYdmqBYYeIiMRgsQo4eNGArScuY+upfKSfr9nl1SFKZws/8ZHs8roew04tMOwQEZErKDJVVE1sWBl+zlyu2eXVJSYAHaJ06BDlj/ZR2gbd8sOwUwsMO0RE5IouXC2xDXTefjof+hJzjWOaBfuiQ5Q/OkTrkBClQ6swNTwbSOsPw04tMOwQEZGrs1gFHLpowN7zV5GRpUdG1lVkFZTWOE7lIUe7CG1V60/lK9LfGzKZ9Nb1YtipBYYdIiJyR1eKTNh/QY+MTD32ZemxP0tfY44fAAjyUyI+sir8ROvQPlIHrbf7d38x7NQCww4REUmB1Srg7JVi7M/SV7X+6HH0khFmS82v+mbBvoiPquz66hDlj9aN3K/7i2GnFhh2iIhIqsrMFhzONtoFoMyCkhrHVXd/xUfqbON/XL37i2GnFhh2iIioIbm++yvjggH7s/Q15vsBgEBfJTpE6RBfNfYnPsq1ur8YdmqBYYeIiBoyQRBwNr/Y1vKzP0uPIzfp/moa7IsOVa0/HaJ0aB2mgdJDnO4vhp1aYNghIiKyV2a24MglY2Xrzy26v5QecrQL19hafxKi/BEVUD/dXww7tcCwQ0REdHsFxeXYn1X55Fd1C9CNur8Cqru/qluAInXQ+ji++6vBhZ05c+bgo48+Qk5ODuLj4/HFF18gMTHxjs5l2CEiIqo9QRBw7koJMrKu2lqAbtb99cM/knBPkwCHXv9Ov789HHpVkSxbtgyTJ0/GvHnz0KVLF3z22WdITk7G8ePHERISInZ5REREkiSTyRAT5IuYIF8MS4gEcK376/qnv7IKStA6TC1enVJo2enSpQvuuecezJ49GwBgtVoRFRWFF154Aa+99tptz2fLDhERkfMYSsyidmO51+xBN1BeXo60tDT069fPtk0ul6Nfv35ITU0VsTIiIiIC4JSgUxtu342Vn58Pi8WC0NBQu+2hoaE4duzYDc8xmUwwmUy2341Go1NrJCIiIvG4fctOXUyfPh1ardb2ioqKErskIiIichK3DztBQUFQKBTIzc21256bm4uwsLAbnjNlyhQYDAbbKysrqz5KJSIiIhG4fdhRKpXo1KkTNm3aZNtmtVqxadMmJCUl3fAclUoFjUZj9yIiIiJpcvsxOwAwefJkjB07Fp07d0ZiYiI+++wzFBcX4+mnnxa7NCIiIhKZJMLOo48+isuXL2Pq1KnIyclBhw4d8Ntvv9UYtExEREQNjyTm2blbnGeHiIjI/TSYeXaIiIiIboVhh4iIiCSNYYeIiIgkjWGHiIiIJI1hh4iIiCSNYYeIiIgkTRLz7Nyt6qfvuSAoERGR+6j+3r7dLDoMOwAKCwsBgAuCEhERuaHCwkJotdqb7uekgqhcSys7OxtqtRoymcxh72s0GhEVFYWsrCxOVuhE/JzrDz/r+sHPuX7wc64fzvycBUFAYWEhwsPDIZfffGQOW3YAyOVyREZGOu39udho/eDnXH/4WdcPfs71g59z/XDW53yrFp1qHKBMREREksawQ0RERJLGsONEKpUKb731FlQqldilSBo/5/rDz7p+8HOuH/yc64crfM4coExERESSxpYdIiIikjSGHSIiIpI0hh0iIiKSNIYdIiIikjSGHSeaM2cOmjRpAi8vL3Tp0gW7d+8WuyRJmT59Ou655x6o1WqEhIRg6NChOH78uNhlSd6MGTMgk8kwadIksUuRnIsXL+KJJ55AYGAgvL29ERcXh71794pdlqRYLBa8+eabiImJgbe3N5o1a4Z33333tmsr0e39+eefePDBBxEeHg6ZTIZVq1bZ7RcEAVOnTkWjRo3g7e2Nfv364eTJk/VSG8OOkyxbtgyTJ0/GW2+9hfT0dMTHxyM5ORl5eXlilyYZW7ZsQUpKCnbu3IkNGzbAbDajf//+KC4uFrs0ydqzZw+++uortG/fXuxSJOfq1avo1q0bPD09sXbtWhw5cgQff/wx/P39xS5NUj788EPMnTsXs2fPxtGjR/Hhhx9i5syZ+OKLL8Quze0VFxcjPj4ec+bMueH+mTNnYtasWZg3bx527doFX19fJCcno6yszPnFCeQUiYmJQkpKiu13i8UihIeHC9OnTxexKmnLy8sTAAhbtmwRuxRJKiwsFFq0aCFs2LBB6NWrl/Diiy+KXZKkvPrqq0L37t3FLkPyBg0aJIwbN85u2/Dhw4XRo0eLVJE0ARBWrlxp+91qtQphYWHCRx99ZNum1+sFlUolfPvtt06vhy07TlBeXo60tDT069fPtk0ul6Nfv35ITU0VsTJpMxgMAICAgACRK5GmlJQUDBo0yO7vNTnOzz//jM6dO+Phhx9GSEgIEhIS8PXXX4tdluTce++92LRpE06cOAEA2L9/P7Zt24YBAwaIXJm0nT17Fjk5OXb//6HVatGlS5d6+V7kQqBOkJ+fD4vFgtDQULvtoaGhOHbsmEhVSZvVasWkSZPQrVs3tGvXTuxyJOe7775Deno69uzZI3YpknXmzBnMnTsXkydPxr///W/s2bMHEydOhFKpxNixY8UuTzJee+01GI1GtG7dGgqFAhaLBe+//z5Gjx4tdmmSlpOTAwA3/F6s3udMDDskCSkpKTh06BC2bdsmdimSk5WVhRdffBEbNmyAl5eX2OVIltVqRefOnfHBBx8AABISEnDo0CHMmzePYceBvv/+eyxZsgRLly5F27ZtkZGRgUmTJiE8PJyfs4SxG8sJgoKCoFAokJuba7c9NzcXYWFhIlUlXRMmTMCaNWuwefNmREZGil2O5KSlpSEvLw8dO3aEh4cHPDw8sGXLFsyaNQseHh6wWCxilygJjRo1QmxsrN22Nm3aIDMzU6SKpOnll1/Ga6+9hlGjRiEuLg5jxozBSy+9hOnTp4tdmqRVf/eJ9b3IsOMESqUSnTp1wqZNm2zbrFYrNm3ahKSkJBErkxZBEDBhwgSsXLkSv//+O2JiYsQuSZL69u2LgwcPIiMjw/bq3LkzRo8ejYyMDCgUCrFLlIRu3brVmDrhxIkTaNy4sUgVSVNJSQnkcvuvPoVCAavVKlJFDUNMTAzCwsLsvheNRiN27dpVL9+L7MZyksmTJ2Ps2LHo3LkzEhMT8dlnn6G4uBhPP/202KVJRkpKCpYuXYqffvoJarXa1u+r1Wrh7e0tcnXSoVara4yD8vX1RWBgIMdHOdBLL72Ee++9Fx988AEeeeQR7N69G/Pnz8f8+fPFLk1SHnzwQbz//vuIjo5G27ZtsW/fPnzyyScYN26c2KW5vaKiIpw6dcr2+9mzZ5GRkYGAgABER0dj0qRJeO+999CiRQvExMTgzTffRHh4OIYOHer84pz+vFcD9sUXXwjR0dGCUqkUEhMThZ07d4pdkqQAuOFrwYIFYpcmeXz03DlWr14ttGvXTlCpVELr1q2F+fPni12S5BiNRuHFF18UoqOjBS8vL6Fp06bC66+/LphMJrFLc3ubN2++4f8njx07VhCEysfP33zzTSE0NFRQqVRC3759hePHj9dLbTJB4LSRREREJF0cs0NERESSxrBDREREksawQ0RERJLGsENERESSxrBDREREksawQ0RERJLGsENERESSxrBDREREksawQ0Qu66mnnqqfqeSJSNIYdoiI7lB5ebnYJRBRHTDsEJFb+uSTTxAXFwdfX19ERUXh+eefR1FREQCguLgYGo0Gy5cvtztn1apV8PX1RWFhIQAgKysLjzzyCHQ6HQICAjBkyBCcO3fOdnx1y9L777+P8PBwtGrVqt7uj4gch2GHiNySXC7HrFmzcPjwYSxatAi///47XnnlFQCVq7KPGjUKCxYssDtnwYIFGDlyJNRqNcxmM5KTk6FWq7F161Zs374dfn5+eOCBB+xacDZt2oTjx49jw4YNWLNmTb3eIxE5BhcCJSKX9dRTT0Gv12PVqlW3PXb58uX4xz/+gfz8fADA7t27ce+99yIrKwuNGjVCXl4eIiIisHHjRvTq1QvffPMN3nvvPRw9ehQymQxAZTeVTqfDqlWr0L9/fzz11FP47bffkJmZCaVS6cxbJSInYssOEbmljRs3om/fvoiIiIBarcaYMWNw5coVlJSUAAASExPRtm1bLFq0CADwzTffoHHjxujZsycAYP/+/Th16hTUajX8/Pzg5+eHgIAAlJWV4fTp07brxMXFMegQuTmGHSJyO+fOncPgwYPRvn17/Pjjj0hLS8OcOXMA2A8i/tvf/oaFCxcCqOzCevrpp22tOEVFRejUqRMyMjLsXidOnMDjjz9uew9fX9/6uzEicgoPsQsgIqqttLQ0WK1WfPzxx5DLK//N9v3339c47oknnsArr7yCWbNm4ciRIxg7dqxtX8eOHbFs2TKEhIRAo9HUW+1EVP/YskNELs1gMNRofQkKCoLZbMYXX3yBM2fOYPHixZg3b16Nc/39/TF8+HC8/PLL6N+/PyIjI237Ro8ejaCgIAwZMgRbt27F2bNn8ccff2DixIm4cOFCfd4iETkZww4RubQ//vgDCQkJdq/Fixfjk08+wYcffoh27dphyZIlmD59+g3PHz9+PMrLyzFu3Di77T4+Pvjzzz8RHR2N4cOHo02bNhg/fjzKysrY0kMkMXwai4gkbfHixXjppZeQnZ3NgcZEDRTH7BCRJJWUlODSpUuYMWMGnn32WQYdogaM3VhEJEkzZ85E69atERYWhilTpohdDhGJiN1YREREJGls2SEiIiJJY9ghIiIiSWPYISIiIklj2CEiIiJJY9ghIiIiSWPYISIiIklj2CEiIiJJY9ghIiIiSWPYISIiIkn7/y8jR2laiJmiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_losses.reverse()\n",
    "plt.plot(best_losses)\n",
    "\n",
    "plt.title(\"Best Loss over Layers\")\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(X_test):\n",
    "    df = X_test\n",
    "\n",
    "    for i in range(11):\n",
    "        inputs = df_to_tensor(df)\n",
    "        pred = models[i](inputs)\n",
    "        df[f'layer {11-i} predictions'] = pd.DataFrame(pred.detach().numpy())\n",
    "\n",
    "    return df.loc[:, 'layer 11 predictions':'layer 1 predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer 11 predictions</th>\n",
       "      <th>layer 10 predictions</th>\n",
       "      <th>layer 9 predictions</th>\n",
       "      <th>layer 8 predictions</th>\n",
       "      <th>layer 7 predictions</th>\n",
       "      <th>layer 6 predictions</th>\n",
       "      <th>layer 5 predictions</th>\n",
       "      <th>layer 4 predictions</th>\n",
       "      <th>layer 3 predictions</th>\n",
       "      <th>layer 2 predictions</th>\n",
       "      <th>layer 1 predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>283.455261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>290.525543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      layer 11 predictions  layer 10 predictions  layer 9 predictions  \\\n",
       "1124                   NaN                   NaN                  NaN   \n",
       "235             283.455261                   NaN                  NaN   \n",
       "585             290.525543                   NaN                  NaN   \n",
       "1469                   NaN                   NaN                  NaN   \n",
       "2066                   NaN                   NaN                  NaN   \n",
       "...                    ...                   ...                  ...   \n",
       "1593                   NaN                   NaN                  NaN   \n",
       "1831                   NaN                   NaN                  NaN   \n",
       "737                    NaN                   NaN                  NaN   \n",
       "2098                   NaN                   NaN                  NaN   \n",
       "1928                   NaN                   NaN                  NaN   \n",
       "\n",
       "      layer 8 predictions  layer 7 predictions  layer 6 predictions  \\\n",
       "1124                  NaN                  NaN                  NaN   \n",
       "235                   NaN                  NaN                  NaN   \n",
       "585                   NaN                  NaN                  NaN   \n",
       "1469                  NaN                  NaN                  NaN   \n",
       "2066                  NaN                  NaN                  NaN   \n",
       "...                   ...                  ...                  ...   \n",
       "1593                  NaN                  NaN                  NaN   \n",
       "1831                  NaN                  NaN                  NaN   \n",
       "737                   NaN                  NaN                  NaN   \n",
       "2098                  NaN                  NaN                  NaN   \n",
       "1928                  NaN                  NaN                  NaN   \n",
       "\n",
       "      layer 5 predictions  layer 4 predictions  layer 3 predictions  \\\n",
       "1124                  NaN                  NaN                  NaN   \n",
       "235                   NaN                  NaN                  NaN   \n",
       "585                   NaN                  NaN                  NaN   \n",
       "1469                  NaN                  NaN                  NaN   \n",
       "2066                  NaN                  NaN                  NaN   \n",
       "...                   ...                  ...                  ...   \n",
       "1593                  NaN                  NaN                  NaN   \n",
       "1831                  NaN                  NaN                  NaN   \n",
       "737                   NaN                  NaN                  NaN   \n",
       "2098                  NaN                  NaN                  NaN   \n",
       "1928                  NaN                  NaN                  NaN   \n",
       "\n",
       "      layer 2 predictions  layer 1 predictions  \n",
       "1124                  NaN                  NaN  \n",
       "235                   NaN                  NaN  \n",
       "585                   NaN                  NaN  \n",
       "1469                  NaN                  NaN  \n",
       "2066                  NaN                  NaN  \n",
       "...                   ...                  ...  \n",
       "1593                  NaN                  NaN  \n",
       "1831                  NaN                  NaN  \n",
       "737                   NaN                  NaN  \n",
       "2098                  NaN                  NaN  \n",
       "1928                  NaN                  NaN  \n",
       "\n",
       "[660 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
