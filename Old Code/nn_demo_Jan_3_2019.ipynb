{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]INFO:root:Train Epoch: 1 [0/1295 (0%)]\tLoss: 406713.156250\n",
      "INFO:root:Train Epoch: 1 [100/1295 (8%)]\tLoss: 387606.125000\n",
      "INFO:root:Train Epoch: 1 [200/1295 (15%)]\tLoss: 392749.843750\n",
      "INFO:root:Train Epoch: 1 [300/1295 (23%)]\tLoss: 396660.593750\n",
      "INFO:root:Train Epoch: 1 [400/1295 (31%)]\tLoss: 401099.312500\n",
      "INFO:root:Train Epoch: 1 [500/1295 (38%)]\tLoss: 339711.125000\n",
      "INFO:root:Train Epoch: 1 [600/1295 (46%)]\tLoss: 393590.875000\n",
      "INFO:root:Train Epoch: 1 [700/1295 (54%)]\tLoss: 521200.062500\n",
      "INFO:root:Train Epoch: 1 [800/1295 (62%)]\tLoss: 409492.406250\n",
      "INFO:root:Train Epoch: 1 [900/1295 (69%)]\tLoss: 406882.468750\n",
      "INFO:root:Train Epoch: 1 [1000/1295 (77%)]\tLoss: 400323.468750\n",
      "INFO:root:Train Epoch: 1 [1100/1295 (85%)]\tLoss: 400491.093750\n",
      "INFO:root:Train Epoch: 1 [1140/1295 (92%)]\tLoss: 400060.000000\n",
      "13it [00:00, 147.71it/s]\n",
      "0it [00:00, ?it/s]INFO:root:Train Epoch: 2 [0/1295 (0%)]\tLoss: 402170.500000\n",
      "INFO:root:Train Epoch: 2 [100/1295 (8%)]\tLoss: 389156.187500\n",
      "INFO:root:Train Epoch: 2 [200/1295 (15%)]\tLoss: 356773.812500\n",
      "INFO:root:Train Epoch: 2 [300/1295 (23%)]\tLoss: 295589.781250\n",
      "INFO:root:Train Epoch: 2 [400/1295 (31%)]\tLoss: 158374.000000\n",
      "INFO:root:Train Epoch: 2 [500/1295 (38%)]\tLoss: 3563.071045\n",
      "INFO:root:Train Epoch: 2 [600/1295 (46%)]\tLoss: 230438.671875\n",
      "INFO:root:Train Epoch: 2 [700/1295 (54%)]\tLoss: 139536.765625\n",
      "INFO:root:Train Epoch: 2 [800/1295 (62%)]\tLoss: 9859.716797\n",
      "INFO:root:Train Epoch: 2 [900/1295 (69%)]\tLoss: 123449.250000\n",
      "INFO:root:Train Epoch: 2 [1000/1295 (77%)]\tLoss: 179602.921875\n",
      "INFO:root:Train Epoch: 2 [1100/1295 (85%)]\tLoss: 147909.375000\n",
      "INFO:root:Train Epoch: 2 [1140/1295 (92%)]\tLoss: 44977.722656\n",
      "13it [00:00, 154.72it/s]\n",
      "0it [00:00, ?it/s]INFO:root:Train Epoch: 3 [0/1295 (0%)]\tLoss: 18650.792969\n",
      "INFO:root:Train Epoch: 3 [100/1295 (8%)]\tLoss: 135237.734375\n",
      "INFO:root:Train Epoch: 3 [200/1295 (15%)]\tLoss: 31757.441406\n",
      "INFO:root:Train Epoch: 3 [300/1295 (23%)]\tLoss: 14008.649414\n",
      "INFO:root:Train Epoch: 3 [400/1295 (31%)]\tLoss: 74067.960938\n",
      "INFO:root:Train Epoch: 3 [500/1295 (38%)]\tLoss: 87800.718750\n",
      "INFO:root:Train Epoch: 3 [600/1295 (46%)]\tLoss: 31557.958984\n",
      "INFO:root:Train Epoch: 3 [700/1295 (54%)]\tLoss: 6198.723145\n",
      "INFO:root:Train Epoch: 3 [800/1295 (62%)]\tLoss: 61527.441406\n",
      "INFO:root:Train Epoch: 3 [900/1295 (69%)]\tLoss: 34955.617188\n",
      "INFO:root:Train Epoch: 3 [1000/1295 (77%)]\tLoss: 4537.650391\n",
      "INFO:root:Train Epoch: 3 [1100/1295 (85%)]\tLoss: 34112.367188\n",
      "INFO:root:Train Epoch: 3 [1140/1295 (92%)]\tLoss: 44248.890625\n",
      "13it [00:00, 152.90it/s]\n",
      "0it [00:00, ?it/s]INFO:root:Train Epoch: 4 [0/1295 (0%)]\tLoss: 17696.041016\n",
      "INFO:root:Train Epoch: 4 [100/1295 (8%)]\tLoss: 4061.998535\n",
      "INFO:root:Train Epoch: 4 [200/1295 (15%)]\tLoss: 30584.830078\n",
      "INFO:root:Train Epoch: 4 [300/1295 (23%)]\tLoss: 20307.123047\n",
      "INFO:root:Train Epoch: 4 [400/1295 (31%)]\tLoss: 2958.417236\n",
      "INFO:root:Train Epoch: 4 [500/1295 (38%)]\tLoss: 17392.365234\n",
      "INFO:root:Train Epoch: 4 [600/1295 (46%)]\tLoss: 22757.570312\n",
      "INFO:root:Train Epoch: 4 [700/1295 (54%)]\tLoss: 11518.886719\n",
      "INFO:root:Train Epoch: 4 [800/1295 (62%)]\tLoss: 4384.560547\n",
      "INFO:root:Train Epoch: 4 [900/1295 (69%)]\tLoss: 19687.304688\n",
      "INFO:root:Train Epoch: 4 [1000/1295 (77%)]\tLoss: 11701.730469\n",
      "INFO:root:Train Epoch: 4 [1100/1295 (85%)]\tLoss: 2824.863525\n",
      "INFO:root:Train Epoch: 4 [1140/1295 (92%)]\tLoss: 13169.611328\n",
      "13it [00:00, 154.72it/s]\n",
      "0it [00:00, ?it/s]INFO:root:Train Epoch: 5 [0/1295 (0%)]\tLoss: 11373.098633\n",
      "INFO:root:Train Epoch: 5 [100/1295 (8%)]\tLoss: 3489.391846\n",
      "INFO:root:Train Epoch: 5 [200/1295 (15%)]\tLoss: 5174.224609\n",
      "INFO:root:Train Epoch: 5 [300/1295 (23%)]\tLoss: 9605.000977\n",
      "INFO:root:Train Epoch: 5 [400/1295 (31%)]\tLoss: 4760.770020\n",
      "INFO:root:Train Epoch: 5 [500/1295 (38%)]\tLoss: 3482.988037\n",
      "INFO:root:Train Epoch: 5 [600/1295 (46%)]\tLoss: 6092.176270\n",
      "INFO:root:Train Epoch: 5 [700/1295 (54%)]\tLoss: 6841.551270\n",
      "INFO:root:Train Epoch: 5 [800/1295 (62%)]\tLoss: 3398.714600\n",
      "INFO:root:Train Epoch: 5 [900/1295 (69%)]\tLoss: 4408.609375\n",
      "INFO:root:Train Epoch: 5 [1000/1295 (77%)]\tLoss: 5879.941895\n",
      "INFO:root:Train Epoch: 5 [1100/1295 (85%)]\tLoss: 3632.112549\n",
      "INFO:root:Train Epoch: 5 [1140/1295 (92%)]\tLoss: 3536.413818\n",
      "13it [00:00, 154.72it/s]\n",
      "0it [00:00, ?it/s]INFO:root:Train Epoch: 6 [0/1295 (0%)]\tLoss: 4112.855469\n",
      "INFO:root:Train Epoch: 6 [100/1295 (8%)]\tLoss: 4316.569336\n",
      "INFO:root:Train Epoch: 6 [200/1295 (15%)]\tLoss: 2951.905518\n",
      "INFO:root:Train Epoch: 6 [300/1295 (23%)]\tLoss: 3517.949707\n",
      "INFO:root:Train Epoch: 6 [400/1295 (31%)]\tLoss: 3309.679932\n",
      "INFO:root:Train Epoch: 6 [500/1295 (38%)]\tLoss: 3481.579834\n",
      "INFO:root:Train Epoch: 6 [600/1295 (46%)]\tLoss: 3177.421875\n",
      "INFO:root:Train Epoch: 6 [700/1295 (54%)]\tLoss: 3630.133789\n",
      "INFO:root:Train Epoch: 6 [800/1295 (62%)]\tLoss: 3403.493652\n",
      "INFO:root:Train Epoch: 6 [900/1295 (69%)]\tLoss: 2734.909180\n",
      "INFO:root:Train Epoch: 6 [1000/1295 (77%)]\tLoss: 2987.106201\n",
      "INFO:root:Train Epoch: 6 [1100/1295 (85%)]\tLoss: 4218.110352\n",
      "INFO:root:Train Epoch: 6 [1140/1295 (92%)]\tLoss: 3007.629639\n",
      "13it [00:00, 156.58it/s]\n",
      "0it [00:00, ?it/s]INFO:root:Train Epoch: 7 [0/1295 (0%)]\tLoss: 3339.125000\n",
      "INFO:root:Train Epoch: 7 [100/1295 (8%)]\tLoss: 3374.284668\n",
      "INFO:root:Train Epoch: 7 [200/1295 (15%)]\tLoss: 3320.035889\n",
      "INFO:root:Train Epoch: 7 [300/1295 (23%)]\tLoss: 3220.266113\n",
      "INFO:root:Train Epoch: 7 [400/1295 (31%)]\tLoss: 3986.499268\n",
      "INFO:root:Train Epoch: 7 [500/1295 (38%)]\tLoss: 3829.922607\n",
      "INFO:root:Train Epoch: 7 [600/1295 (46%)]\tLoss: 2843.162842\n",
      "INFO:root:Train Epoch: 7 [700/1295 (54%)]\tLoss: 3140.450684\n",
      "INFO:root:Train Epoch: 7 [800/1295 (62%)]\tLoss: 3057.922363\n",
      "INFO:root:Train Epoch: 7 [900/1295 (69%)]\tLoss: 3171.478271\n",
      "INFO:root:Train Epoch: 7 [1000/1295 (77%)]\tLoss: 2898.002441\n",
      "INFO:root:Train Epoch: 7 [1100/1295 (85%)]\tLoss: 2911.754883\n",
      "INFO:root:Train Epoch: 7 [1140/1295 (92%)]\tLoss: 2958.991455\n",
      "13it [00:00, 154.72it/s]\n",
      "0it [00:00, ?it/s]INFO:root:Train Epoch: 8 [0/1295 (0%)]\tLoss: 2901.269531\n",
      "INFO:root:Train Epoch: 8 [100/1295 (8%)]\tLoss: 2869.646973\n",
      "INFO:root:Train Epoch: 8 [200/1295 (15%)]\tLoss: 3030.785400\n",
      "INFO:root:Train Epoch: 8 [300/1295 (23%)]\tLoss: 3057.480225\n",
      "INFO:root:Train Epoch: 8 [400/1295 (31%)]\tLoss: 3114.366943\n",
      "INFO:root:Train Epoch: 8 [500/1295 (38%)]\tLoss: 3543.032959\n",
      "INFO:root:Train Epoch: 8 [600/1295 (46%)]\tLoss: 2885.427490\n",
      "INFO:root:Train Epoch: 8 [700/1295 (54%)]\tLoss: 2913.928711\n",
      "INFO:root:Train Epoch: 8 [800/1295 (62%)]\tLoss: 3158.070312\n",
      "INFO:root:Train Epoch: 8 [900/1295 (69%)]\tLoss: 3137.894043\n",
      "INFO:root:Train Epoch: 8 [1000/1295 (77%)]\tLoss: 2982.685547\n",
      "INFO:root:Train Epoch: 8 [1100/1295 (85%)]\tLoss: 2981.884521\n",
      "INFO:root:Train Epoch: 8 [1140/1295 (92%)]\tLoss: 3529.646484\n",
      "13it [00:00, 149.38it/s]\n",
      "0it [00:00, ?it/s]INFO:root:Train Epoch: 9 [0/1295 (0%)]\tLoss: 3064.253906\n",
      "INFO:root:Train Epoch: 9 [100/1295 (8%)]\tLoss: 2856.681396\n",
      "INFO:root:Train Epoch: 9 [200/1295 (15%)]\tLoss: 3323.671875\n",
      "INFO:root:Train Epoch: 9 [300/1295 (23%)]\tLoss: 3648.571777\n",
      "INFO:root:Train Epoch: 9 [400/1295 (31%)]\tLoss: 2824.644043\n",
      "INFO:root:Train Epoch: 9 [500/1295 (38%)]\tLoss: 3079.160889\n",
      "INFO:root:Train Epoch: 9 [600/1295 (46%)]\tLoss: 3393.580078\n",
      "INFO:root:Train Epoch: 9 [700/1295 (54%)]\tLoss: 3216.603760\n",
      "INFO:root:Train Epoch: 9 [800/1295 (62%)]\tLoss: 3047.707031\n",
      "INFO:root:Train Epoch: 9 [900/1295 (69%)]\tLoss: 3225.989746\n",
      "INFO:root:Train Epoch: 9 [1000/1295 (77%)]\tLoss: 3677.397705\n",
      "INFO:root:Train Epoch: 9 [1100/1295 (85%)]\tLoss: 3394.066406\n",
      "INFO:root:Train Epoch: 9 [1140/1295 (92%)]\tLoss: 2824.310303\n",
      "13it [00:00, 156.58it/s]\n",
      "0it [00:00, ?it/s]INFO:root:Train Epoch: 10 [0/1295 (0%)]\tLoss: 3271.635986\n",
      "INFO:root:Train Epoch: 10 [100/1295 (8%)]\tLoss: 3513.334717\n",
      "INFO:root:Train Epoch: 10 [200/1295 (15%)]\tLoss: 2929.244873\n",
      "INFO:root:Train Epoch: 10 [300/1295 (23%)]\tLoss: 3430.938721\n",
      "INFO:root:Train Epoch: 10 [400/1295 (31%)]\tLoss: 3924.700439\n",
      "INFO:root:Train Epoch: 10 [500/1295 (38%)]\tLoss: 3368.799561\n",
      "INFO:root:Train Epoch: 10 [600/1295 (46%)]\tLoss: 3141.947754\n",
      "INFO:root:Train Epoch: 10 [700/1295 (54%)]\tLoss: 2722.254150\n",
      "INFO:root:Train Epoch: 10 [800/1295 (62%)]\tLoss: 3549.119385\n",
      "INFO:root:Train Epoch: 10 [900/1295 (69%)]\tLoss: 2560.662598\n",
      "INFO:root:Train Epoch: 10 [1000/1295 (77%)]\tLoss: 3613.321777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Epoch: 10 [1100/1295 (85%)]\tLoss: 3398.846680\n",
      "INFO:root:Train Epoch: 10 [1140/1295 (92%)]\tLoss: 3644.958252\n",
      "13it [00:00, 158.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "################################################ data dimensions\n",
    "_num_tuples = 15552 \n",
    "_num_features = 45\n",
    "_label_dims = 11\n",
    "\n",
    "################################################ load data\n",
    "data = pd.read_excel('spectrum_more_sets.xlsx').values\n",
    "labels = pd.read_excel('temperature_more_sets.xlsx').values\n",
    "\n",
    "#data = pd.read_excel('spectrum_norm.xlsx').values\n",
    "#labels = pd.read_excel('temperature_norm.xlsx').values\n",
    "\n",
    "\n",
    "################################################ Define dataset function\n",
    "class Dataset(object):\n",
    "    def __init__(self, data):\n",
    "        # m, n denote number of tuples and features respectively\n",
    "        self._m = data[0].shape[0]\n",
    "        self._n = data[0].shape[1]\n",
    "        self._training_data = data[0]\n",
    "        self._training_labels = data[1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._m\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return  self._training_data[idx,:], self._training_labels[idx,:] \n",
    "\n",
    "    def fetch_col(self, col_index):\n",
    "        return self._training_data[:, col_index]\n",
    "\n",
    "    def shuffle(self, seed=None):\n",
    "        if seed:\n",
    "            np.random.seed(seed=seed)\n",
    "        shuffled_indices = np.arange(self._m)\n",
    "        np.random.shuffle(shuffled_indices)\n",
    "        self._training_data = np.take(self._training_data, shuffled_indices, axis=0)\n",
    "        self._training_labels = np.take(self._training_labels, shuffled_indices)\n",
    "\n",
    "    @property\n",
    "    def num_tuples(self):\n",
    "        return self._m\n",
    "\n",
    "    @property\n",
    "    def num_features(self):\n",
    "        return self._n\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._training_labels\n",
    "\n",
    "    @property\n",
    "    def data_table(self):\n",
    "        return self._training_data\n",
    "       \n",
    "dataset = Dataset((data, labels))\n",
    "\n",
    "################################################ Define model\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# model definition\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(45, 200)\n",
    "        self.fc2 = nn.Linear(200, 200)\n",
    "        self.fc3 = nn.Linear(200, 11)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        #x = self.sigmoid(x)\n",
    "        return x\n",
    "    def name(self):\n",
    "        return 'nn'\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "args = {'lr':1e-3, \n",
    "        'max_steps':100,\n",
    "        'batch_size':100,\n",
    "        'epoch':10,\n",
    "        'enable_gpu':None}\n",
    "train_loader = DataLoader(dataset, batch_size=args['batch_size'], shuffle=True)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = NN().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=0.9)\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in tqdm(enumerate(train_loader)):\n",
    "        data, target = data.float().to(device), target.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.mse_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        logger.info('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.mse_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    logger.info('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "################################################ Run the training set \n",
    "for epoch in range(1, args['epoch'] + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    #test(args, model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
