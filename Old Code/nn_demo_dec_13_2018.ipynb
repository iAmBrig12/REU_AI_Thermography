{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameters for loading data\n",
    "_num_tuples = 1296\n",
    "_num_features = 45\n",
    "_label_dims = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(files, num_tuples, num_features, label_dims):\n",
    "    data_file, label_file = files\n",
    "    print(data_file, label_file)\n",
    "    data = np.zeros((num_tuples, num_features))\n",
    "    labels = np.zeros((num_tuples, label_dims))\n",
    "    \n",
    "    with open(data_file, 'rb') as f:\n",
    "        for i,line in enumerate(f.readlines()):\n",
    "            ##################[ISSUE! @YUZHE]HARD CODED, PLEASE CHECK THE DATA FORMAT ########################\n",
    "            #processed = line.rstrip('\\n').rstrip('\\r').rstrip(',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,').split(',')\n",
    "            processed = line.rstrip('\\n').split(',')\n",
    "            ###################################################################################################\n",
    "            #logger.info(processed)\n",
    "            try:\n",
    "                assert num_features == len(processed)\n",
    "                data[i,:] = processed\n",
    "            except AssertionError as err:\n",
    "                logger.info(\"Wrong Feature Number claimed !, {}, {}\".format(num_features, len(processed)))\n",
    "                \n",
    "    with open(label_file, 'rb') as f:\n",
    "        for i,line in enumerate(f.readlines()):\n",
    "            #processed = line.rstrip('\\n').split(',')\n",
    "            processed = line.rstrip('\\n').rstrip('\\r').rstrip(',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,').split(',')\n",
    "            #print(len(processed), label_dims)\n",
    "            try:\n",
    "                assert label_dims == len(processed)\n",
    "                \n",
    "                labels[i,:] = processed\n",
    "            except AssertionError as err:\n",
    "                logger.info(\"Wrong Label Dimensions claimed !\")\n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('spectrum.csv', 'temperature.csv')\n"
     ]
    }
   ],
   "source": [
    "data, labels = load_data(('spectrum.csv', 'temperature.csv'), _num_tuples, _num_features, _label_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, data):\n",
    "        # m, n denote number of tuples and features respectively\n",
    "        self._m = data[0].shape[0]\n",
    "        self._n = data[0].shape[1]\n",
    "        self._training_data = data[0]\n",
    "        self._training_labels = data[1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._m\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return  self._training_data[idx,:], self._training_labels[idx,:] \n",
    "\n",
    "    def fetch_col(self, col_index):\n",
    "        return self._training_data[:, col_index]\n",
    "\n",
    "    def shuffle(self, seed=None):\n",
    "        if seed:\n",
    "            np.random.seed(seed=seed)\n",
    "        shuffled_indices = np.arange(self._m)\n",
    "        np.random.shuffle(shuffled_indices)\n",
    "        self._training_data = np.take(self._training_data, shuffled_indices, axis=0)\n",
    "        self._training_labels = np.take(self._training_labels, shuffled_indices)\n",
    "\n",
    "    @property\n",
    "    def num_tuples(self):\n",
    "        return self._m\n",
    "\n",
    "    @property\n",
    "    def num_features(self):\n",
    "        return self._n\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._training_labels\n",
    "\n",
    "    @property\n",
    "    def data_table(self):\n",
    "        return self._training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset((data, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# model definition\n",
    "# notes from Yuzhe: Here are the parameters for the neural network,total of 3 layers of network\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(45, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 11)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        ## notes from Yuzhe: Following are the activate function for network\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        #x = self.relu(x)\n",
    "        return x\n",
    "    def name(self):\n",
    "        return 'nn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "## notes from Yuzhe, following are parameters that can be changed to modify the training code\n",
    "args = {'lr':0.001, ## learning rate\n",
    "        'max_steps':10,   ## maximum numbers of iteration\n",
    "        'batch_size':100,   \n",
    "        'epoch':30,\n",
    "        'enable_gpu':None}\n",
    "train_loader = DataLoader(dataset, batch_size=args['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = NN().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.float().to(device), target.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.mse_loss(output, target)\n",
    "        if epoch >= 499:\n",
    "            print(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        logger.info('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.mse_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    logger.info('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Epoch: 1 [0/1296 (0%)]\tLoss: 406806.562500\n",
      "INFO:root:Train Epoch: 1 [100/1296 (8%)]\tLoss: 399810.687500\n",
      "INFO:root:Train Epoch: 1 [200/1296 (15%)]\tLoss: 400475.468750\n",
      "INFO:root:Train Epoch: 1 [300/1296 (23%)]\tLoss: 405205.437500\n",
      "INFO:root:Train Epoch: 1 [400/1296 (31%)]\tLoss: 395530.843750\n",
      "INFO:root:Train Epoch: 1 [500/1296 (38%)]\tLoss: 380604.437500\n",
      "INFO:root:Train Epoch: 1 [600/1296 (46%)]\tLoss: 304379.093750\n",
      "INFO:root:Train Epoch: 1 [700/1296 (54%)]\tLoss: 6551596.000000\n",
      "INFO:root:Train Epoch: 1 [800/1296 (62%)]\tLoss: 404725.531250\n",
      "INFO:root:Train Epoch: 1 [900/1296 (69%)]\tLoss: 398363.593750\n",
      "INFO:root:Train Epoch: 1 [1000/1296 (77%)]\tLoss: 396047.968750\n",
      "INFO:root:Train Epoch: 1 [1100/1296 (85%)]\tLoss: 399431.531250\n",
      "INFO:root:Train Epoch: 1 [1152/1296 (92%)]\tLoss: 398835.468750\n",
      "INFO:root:Train Epoch: 2 [0/1296 (0%)]\tLoss: 385013.656250\n",
      "INFO:root:Train Epoch: 2 [100/1296 (8%)]\tLoss: 381360.718750\n",
      "INFO:root:Train Epoch: 2 [200/1296 (15%)]\tLoss: 366773.093750\n",
      "INFO:root:Train Epoch: 2 [300/1296 (23%)]\tLoss: 319318.750000\n",
      "INFO:root:Train Epoch: 2 [400/1296 (31%)]\tLoss: 181400.968750\n",
      "INFO:root:Train Epoch: 2 [500/1296 (38%)]\tLoss: 8353.368164\n",
      "INFO:root:Train Epoch: 2 [600/1296 (46%)]\tLoss: 207055.140625\n",
      "INFO:root:Train Epoch: 2 [700/1296 (54%)]\tLoss: 170586.031250\n",
      "INFO:root:Train Epoch: 2 [800/1296 (62%)]\tLoss: 6556.052734\n",
      "INFO:root:Train Epoch: 2 [900/1296 (69%)]\tLoss: 117655.640625\n",
      "INFO:root:Train Epoch: 2 [1000/1296 (77%)]\tLoss: 178042.390625\n",
      "INFO:root:Train Epoch: 2 [1100/1296 (85%)]\tLoss: 152664.671875\n",
      "INFO:root:Train Epoch: 2 [1152/1296 (92%)]\tLoss: 48979.035156\n",
      "INFO:root:Train Epoch: 3 [0/1296 (0%)]\tLoss: 10541.557617\n",
      "INFO:root:Train Epoch: 3 [100/1296 (8%)]\tLoss: 135099.187500\n",
      "INFO:root:Train Epoch: 3 [200/1296 (15%)]\tLoss: 47720.578125\n",
      "INFO:root:Train Epoch: 3 [300/1296 (23%)]\tLoss: 13427.725586\n",
      "INFO:root:Train Epoch: 3 [400/1296 (31%)]\tLoss: 77610.968750\n",
      "INFO:root:Train Epoch: 3 [500/1296 (38%)]\tLoss: 93736.406250\n",
      "INFO:root:Train Epoch: 3 [600/1296 (46%)]\tLoss: 41182.292969\n",
      "INFO:root:Train Epoch: 3 [700/1296 (54%)]\tLoss: 3692.640137\n",
      "INFO:root:Train Epoch: 3 [800/1296 (62%)]\tLoss: 65524.367188\n",
      "INFO:root:Train Epoch: 3 [900/1296 (69%)]\tLoss: 47005.277344\n",
      "INFO:root:Train Epoch: 3 [1000/1296 (77%)]\tLoss: 4153.608887\n",
      "INFO:root:Train Epoch: 3 [1100/1296 (85%)]\tLoss: 38568.117188\n",
      "INFO:root:Train Epoch: 3 [1152/1296 (92%)]\tLoss: 51272.882812\n",
      "INFO:root:Train Epoch: 4 [0/1296 (0%)]\tLoss: 21349.435547\n",
      "INFO:root:Train Epoch: 4 [100/1296 (8%)]\tLoss: 4224.818359\n",
      "INFO:root:Train Epoch: 4 [200/1296 (15%)]\tLoss: 27807.585938\n",
      "INFO:root:Train Epoch: 4 [300/1296 (23%)]\tLoss: 26694.664062\n",
      "INFO:root:Train Epoch: 4 [400/1296 (31%)]\tLoss: 3060.653564\n",
      "INFO:root:Train Epoch: 4 [500/1296 (38%)]\tLoss: 17084.890625\n",
      "INFO:root:Train Epoch: 4 [600/1296 (46%)]\tLoss: 22926.101562\n",
      "INFO:root:Train Epoch: 4 [700/1296 (54%)]\tLoss: 10056.029297\n",
      "INFO:root:Train Epoch: 4 [800/1296 (62%)]\tLoss: 3944.256836\n",
      "INFO:root:Train Epoch: 4 [900/1296 (69%)]\tLoss: 17092.492188\n",
      "INFO:root:Train Epoch: 4 [1000/1296 (77%)]\tLoss: 9919.906250\n",
      "INFO:root:Train Epoch: 4 [1100/1296 (85%)]\tLoss: 2973.135254\n",
      "INFO:root:Train Epoch: 4 [1152/1296 (92%)]\tLoss: 8066.748047\n",
      "INFO:root:Train Epoch: 5 [0/1296 (0%)]\tLoss: 10955.775391\n",
      "INFO:root:Train Epoch: 5 [100/1296 (8%)]\tLoss: 5703.979980\n",
      "INFO:root:Train Epoch: 5 [200/1296 (15%)]\tLoss: 3301.120361\n",
      "INFO:root:Train Epoch: 5 [300/1296 (23%)]\tLoss: 9614.578125\n",
      "INFO:root:Train Epoch: 5 [400/1296 (31%)]\tLoss: 7222.382812\n",
      "INFO:root:Train Epoch: 5 [500/1296 (38%)]\tLoss: 2632.098633\n",
      "INFO:root:Train Epoch: 5 [600/1296 (46%)]\tLoss: 6679.633301\n",
      "INFO:root:Train Epoch: 5 [700/1296 (54%)]\tLoss: 7242.699707\n",
      "INFO:root:Train Epoch: 5 [800/1296 (62%)]\tLoss: 5229.597656\n",
      "INFO:root:Train Epoch: 5 [900/1296 (69%)]\tLoss: 3754.156738\n",
      "INFO:root:Train Epoch: 5 [1000/1296 (77%)]\tLoss: 7370.775391\n",
      "INFO:root:Train Epoch: 5 [1100/1296 (85%)]\tLoss: 5160.531250\n",
      "INFO:root:Train Epoch: 5 [1152/1296 (92%)]\tLoss: 3143.240479\n",
      "INFO:root:Train Epoch: 6 [0/1296 (0%)]\tLoss: 4595.722168\n",
      "INFO:root:Train Epoch: 6 [100/1296 (8%)]\tLoss: 5331.483398\n",
      "INFO:root:Train Epoch: 6 [200/1296 (15%)]\tLoss: 4099.482422\n",
      "INFO:root:Train Epoch: 6 [300/1296 (23%)]\tLoss: 3073.009521\n",
      "INFO:root:Train Epoch: 6 [400/1296 (31%)]\tLoss: 4830.979004\n",
      "INFO:root:Train Epoch: 6 [500/1296 (38%)]\tLoss: 4751.132812\n",
      "INFO:root:Train Epoch: 6 [600/1296 (46%)]\tLoss: 3037.531494\n",
      "INFO:root:Train Epoch: 6 [700/1296 (54%)]\tLoss: 3924.070557\n",
      "INFO:root:Train Epoch: 6 [800/1296 (62%)]\tLoss: 4110.481934\n",
      "INFO:root:Train Epoch: 6 [900/1296 (69%)]\tLoss: 3254.370605\n",
      "INFO:root:Train Epoch: 6 [1000/1296 (77%)]\tLoss: 3025.744385\n",
      "INFO:root:Train Epoch: 6 [1100/1296 (85%)]\tLoss: 3320.388672\n",
      "INFO:root:Train Epoch: 6 [1152/1296 (92%)]\tLoss: 3870.418457\n",
      "INFO:root:Train Epoch: 7 [0/1296 (0%)]\tLoss: 3007.860596\n",
      "INFO:root:Train Epoch: 7 [100/1296 (8%)]\tLoss: 3553.991699\n",
      "INFO:root:Train Epoch: 7 [200/1296 (15%)]\tLoss: 4015.285156\n",
      "INFO:root:Train Epoch: 7 [300/1296 (23%)]\tLoss: 3351.079102\n",
      "INFO:root:Train Epoch: 7 [400/1296 (31%)]\tLoss: 3475.532959\n",
      "INFO:root:Train Epoch: 7 [500/1296 (38%)]\tLoss: 4183.200684\n",
      "INFO:root:Train Epoch: 7 [600/1296 (46%)]\tLoss: 3333.244873\n",
      "INFO:root:Train Epoch: 7 [700/1296 (54%)]\tLoss: 3209.242188\n",
      "INFO:root:Train Epoch: 7 [800/1296 (62%)]\tLoss: 3697.500244\n",
      "INFO:root:Train Epoch: 7 [900/1296 (69%)]\tLoss: 3440.539795\n",
      "INFO:root:Train Epoch: 7 [1000/1296 (77%)]\tLoss: 2980.365479\n",
      "INFO:root:Train Epoch: 7 [1100/1296 (85%)]\tLoss: 3187.548096\n",
      "INFO:root:Train Epoch: 7 [1152/1296 (92%)]\tLoss: 3221.747070\n",
      "INFO:root:Train Epoch: 8 [0/1296 (0%)]\tLoss: 2975.523193\n",
      "INFO:root:Train Epoch: 8 [100/1296 (8%)]\tLoss: 3330.427246\n",
      "INFO:root:Train Epoch: 8 [200/1296 (15%)]\tLoss: 3389.226562\n",
      "INFO:root:Train Epoch: 8 [300/1296 (23%)]\tLoss: 3541.748535\n",
      "INFO:root:Train Epoch: 8 [400/1296 (31%)]\tLoss: 3126.218994\n",
      "INFO:root:Train Epoch: 8 [500/1296 (38%)]\tLoss: 3101.434570\n",
      "INFO:root:Train Epoch: 8 [600/1296 (46%)]\tLoss: 3972.258301\n",
      "INFO:root:Train Epoch: 8 [700/1296 (54%)]\tLoss: 3006.569824\n",
      "INFO:root:Train Epoch: 8 [800/1296 (62%)]\tLoss: 2920.826660\n",
      "INFO:root:Train Epoch: 8 [900/1296 (69%)]\tLoss: 3808.149902\n",
      "INFO:root:Train Epoch: 8 [1000/1296 (77%)]\tLoss: 2741.717041\n",
      "INFO:root:Train Epoch: 8 [1100/1296 (85%)]\tLoss: 2976.199219\n",
      "INFO:root:Train Epoch: 8 [1152/1296 (92%)]\tLoss: 3179.530518\n",
      "INFO:root:Train Epoch: 9 [0/1296 (0%)]\tLoss: 3322.621826\n",
      "INFO:root:Train Epoch: 9 [100/1296 (8%)]\tLoss: 2892.535645\n",
      "INFO:root:Train Epoch: 9 [200/1296 (15%)]\tLoss: 3456.240967\n",
      "INFO:root:Train Epoch: 9 [300/1296 (23%)]\tLoss: 3748.174561\n",
      "INFO:root:Train Epoch: 9 [400/1296 (31%)]\tLoss: 2875.163086\n",
      "INFO:root:Train Epoch: 9 [500/1296 (38%)]\tLoss: 3113.001465\n",
      "INFO:root:Train Epoch: 9 [600/1296 (46%)]\tLoss: 3025.854004\n",
      "INFO:root:Train Epoch: 9 [700/1296 (54%)]\tLoss: 3203.731201\n",
      "INFO:root:Train Epoch: 9 [800/1296 (62%)]\tLoss: 3433.522705\n",
      "INFO:root:Train Epoch: 9 [900/1296 (69%)]\tLoss: 2907.736572\n",
      "INFO:root:Train Epoch: 9 [1000/1296 (77%)]\tLoss: 3837.481201\n",
      "INFO:root:Train Epoch: 9 [1100/1296 (85%)]\tLoss: 3736.010254\n",
      "INFO:root:Train Epoch: 9 [1152/1296 (92%)]\tLoss: 3035.820068\n",
      "INFO:root:Train Epoch: 10 [0/1296 (0%)]\tLoss: 3673.850098\n",
      "INFO:root:Train Epoch: 10 [100/1296 (8%)]\tLoss: 3850.279541\n",
      "INFO:root:Train Epoch: 10 [200/1296 (15%)]\tLoss: 3247.357910\n",
      "INFO:root:Train Epoch: 10 [300/1296 (23%)]\tLoss: 2972.726562\n",
      "INFO:root:Train Epoch: 10 [400/1296 (31%)]\tLoss: 3557.202393\n",
      "INFO:root:Train Epoch: 10 [500/1296 (38%)]\tLoss: 3243.550293\n",
      "INFO:root:Train Epoch: 10 [600/1296 (46%)]\tLoss: 2961.453613\n",
      "INFO:root:Train Epoch: 10 [700/1296 (54%)]\tLoss: 3517.523438\n",
      "INFO:root:Train Epoch: 10 [800/1296 (62%)]\tLoss: 3643.752930\n",
      "INFO:root:Train Epoch: 10 [900/1296 (69%)]\tLoss: 2952.714355\n",
      "INFO:root:Train Epoch: 10 [1000/1296 (77%)]\tLoss: 3129.316895\n",
      "INFO:root:Train Epoch: 10 [1100/1296 (85%)]\tLoss: 3705.789307\n",
      "INFO:root:Train Epoch: 10 [1152/1296 (92%)]\tLoss: 3581.134766\n",
      "INFO:root:Train Epoch: 11 [0/1296 (0%)]\tLoss: 3062.855469\n",
      "INFO:root:Train Epoch: 11 [100/1296 (8%)]\tLoss: 3546.095459\n",
      "INFO:root:Train Epoch: 11 [200/1296 (15%)]\tLoss: 3760.525635\n",
      "INFO:root:Train Epoch: 11 [300/1296 (23%)]\tLoss: 3377.002441\n",
      "INFO:root:Train Epoch: 11 [400/1296 (31%)]\tLoss: 3116.791748\n",
      "INFO:root:Train Epoch: 11 [500/1296 (38%)]\tLoss: 3898.285889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Epoch: 11 [600/1296 (46%)]\tLoss: 3895.736816\n",
      "INFO:root:Train Epoch: 11 [700/1296 (54%)]\tLoss: 2741.863525\n",
      "INFO:root:Train Epoch: 11 [800/1296 (62%)]\tLoss: 2995.912109\n",
      "INFO:root:Train Epoch: 11 [900/1296 (69%)]\tLoss: 3453.706787\n",
      "INFO:root:Train Epoch: 11 [1000/1296 (77%)]\tLoss: 3405.600098\n",
      "INFO:root:Train Epoch: 11 [1100/1296 (85%)]\tLoss: 2868.036621\n",
      "INFO:root:Train Epoch: 11 [1152/1296 (92%)]\tLoss: 3323.678711\n",
      "INFO:root:Train Epoch: 12 [0/1296 (0%)]\tLoss: 3726.866211\n",
      "INFO:root:Train Epoch: 12 [100/1296 (8%)]\tLoss: 2769.741943\n",
      "INFO:root:Train Epoch: 12 [200/1296 (15%)]\tLoss: 3299.605713\n",
      "INFO:root:Train Epoch: 12 [300/1296 (23%)]\tLoss: 3401.320312\n",
      "INFO:root:Train Epoch: 12 [400/1296 (31%)]\tLoss: 2912.167236\n",
      "INFO:root:Train Epoch: 12 [500/1296 (38%)]\tLoss: 2871.958740\n",
      "INFO:root:Train Epoch: 12 [600/1296 (46%)]\tLoss: 3188.794678\n",
      "INFO:root:Train Epoch: 12 [700/1296 (54%)]\tLoss: 2934.572021\n",
      "INFO:root:Train Epoch: 12 [800/1296 (62%)]\tLoss: 2976.453125\n",
      "INFO:root:Train Epoch: 12 [900/1296 (69%)]\tLoss: 3396.780518\n",
      "INFO:root:Train Epoch: 12 [1000/1296 (77%)]\tLoss: 3073.857666\n",
      "INFO:root:Train Epoch: 12 [1100/1296 (85%)]\tLoss: 3308.636719\n",
      "INFO:root:Train Epoch: 12 [1152/1296 (92%)]\tLoss: 3361.312988\n",
      "INFO:root:Train Epoch: 13 [0/1296 (0%)]\tLoss: 3063.250732\n",
      "INFO:root:Train Epoch: 13 [100/1296 (8%)]\tLoss: 3522.954834\n",
      "INFO:root:Train Epoch: 13 [200/1296 (15%)]\tLoss: 2859.684814\n",
      "INFO:root:Train Epoch: 13 [300/1296 (23%)]\tLoss: 3270.883301\n",
      "INFO:root:Train Epoch: 13 [400/1296 (31%)]\tLoss: 3920.667236\n",
      "INFO:root:Train Epoch: 13 [500/1296 (38%)]\tLoss: 2908.817627\n",
      "INFO:root:Train Epoch: 13 [600/1296 (46%)]\tLoss: 3207.917236\n",
      "INFO:root:Train Epoch: 13 [700/1296 (54%)]\tLoss: 3683.698486\n",
      "INFO:root:Train Epoch: 13 [800/1296 (62%)]\tLoss: 3241.711182\n",
      "INFO:root:Train Epoch: 13 [900/1296 (69%)]\tLoss: 3028.011230\n",
      "INFO:root:Train Epoch: 13 [1000/1296 (77%)]\tLoss: 4926.887207\n",
      "INFO:root:Train Epoch: 13 [1100/1296 (85%)]\tLoss: 3346.243164\n",
      "INFO:root:Train Epoch: 13 [1152/1296 (92%)]\tLoss: 2976.244629\n",
      "INFO:root:Train Epoch: 14 [0/1296 (0%)]\tLoss: 3790.027832\n",
      "INFO:root:Train Epoch: 14 [100/1296 (8%)]\tLoss: 3959.416748\n",
      "INFO:root:Train Epoch: 14 [200/1296 (15%)]\tLoss: 3027.216064\n",
      "INFO:root:Train Epoch: 14 [300/1296 (23%)]\tLoss: 3171.697510\n",
      "INFO:root:Train Epoch: 14 [400/1296 (31%)]\tLoss: 2686.131348\n",
      "INFO:root:Train Epoch: 14 [500/1296 (38%)]\tLoss: 3550.108154\n",
      "INFO:root:Train Epoch: 14 [600/1296 (46%)]\tLoss: 3328.256104\n",
      "INFO:root:Train Epoch: 14 [700/1296 (54%)]\tLoss: 3079.808594\n",
      "INFO:root:Train Epoch: 14 [800/1296 (62%)]\tLoss: 2736.403076\n",
      "INFO:root:Train Epoch: 14 [900/1296 (69%)]\tLoss: 3732.748291\n",
      "INFO:root:Train Epoch: 14 [1000/1296 (77%)]\tLoss: 3323.017822\n",
      "INFO:root:Train Epoch: 14 [1100/1296 (85%)]\tLoss: 3267.086914\n",
      "INFO:root:Train Epoch: 14 [1152/1296 (92%)]\tLoss: 3521.651367\n",
      "INFO:root:Train Epoch: 15 [0/1296 (0%)]\tLoss: 2700.095947\n",
      "INFO:root:Train Epoch: 15 [100/1296 (8%)]\tLoss: 2850.250732\n",
      "INFO:root:Train Epoch: 15 [200/1296 (15%)]\tLoss: 3128.224121\n",
      "INFO:root:Train Epoch: 15 [300/1296 (23%)]\tLoss: 3054.398438\n",
      "INFO:root:Train Epoch: 15 [400/1296 (31%)]\tLoss: 3123.123291\n",
      "INFO:root:Train Epoch: 15 [500/1296 (38%)]\tLoss: 2783.366699\n",
      "INFO:root:Train Epoch: 15 [600/1296 (46%)]\tLoss: 3039.010010\n",
      "INFO:root:Train Epoch: 15 [700/1296 (54%)]\tLoss: 3362.075195\n",
      "INFO:root:Train Epoch: 15 [800/1296 (62%)]\tLoss: 2972.437988\n",
      "INFO:root:Train Epoch: 15 [900/1296 (69%)]\tLoss: 2988.471680\n",
      "INFO:root:Train Epoch: 15 [1000/1296 (77%)]\tLoss: 3201.663086\n",
      "INFO:root:Train Epoch: 15 [1100/1296 (85%)]\tLoss: 2527.444092\n",
      "INFO:root:Train Epoch: 15 [1152/1296 (92%)]\tLoss: 2992.572510\n",
      "INFO:root:Train Epoch: 16 [0/1296 (0%)]\tLoss: 2967.619385\n",
      "INFO:root:Train Epoch: 16 [100/1296 (8%)]\tLoss: 2768.759766\n",
      "INFO:root:Train Epoch: 16 [200/1296 (15%)]\tLoss: 3111.240723\n",
      "INFO:root:Train Epoch: 16 [300/1296 (23%)]\tLoss: 3066.655518\n",
      "INFO:root:Train Epoch: 16 [400/1296 (31%)]\tLoss: 3079.380127\n",
      "INFO:root:Train Epoch: 16 [500/1296 (38%)]\tLoss: 3130.974609\n",
      "INFO:root:Train Epoch: 16 [600/1296 (46%)]\tLoss: 2882.876465\n",
      "INFO:root:Train Epoch: 16 [700/1296 (54%)]\tLoss: 3129.680908\n",
      "INFO:root:Train Epoch: 16 [800/1296 (62%)]\tLoss: 2849.760254\n",
      "INFO:root:Train Epoch: 16 [900/1296 (69%)]\tLoss: 3327.457031\n",
      "INFO:root:Train Epoch: 16 [1000/1296 (77%)]\tLoss: 3352.963867\n",
      "INFO:root:Train Epoch: 16 [1100/1296 (85%)]\tLoss: 2969.003662\n",
      "INFO:root:Train Epoch: 16 [1152/1296 (92%)]\tLoss: 3539.733643\n",
      "INFO:root:Train Epoch: 17 [0/1296 (0%)]\tLoss: 3102.768311\n",
      "INFO:root:Train Epoch: 17 [100/1296 (8%)]\tLoss: 2932.959229\n",
      "INFO:root:Train Epoch: 17 [200/1296 (15%)]\tLoss: 2763.112549\n",
      "INFO:root:Train Epoch: 17 [300/1296 (23%)]\tLoss: 3169.049805\n",
      "INFO:root:Train Epoch: 17 [400/1296 (31%)]\tLoss: 3062.550537\n",
      "INFO:root:Train Epoch: 17 [500/1296 (38%)]\tLoss: 2926.137939\n",
      "INFO:root:Train Epoch: 17 [600/1296 (46%)]\tLoss: 2976.397949\n",
      "INFO:root:Train Epoch: 17 [700/1296 (54%)]\tLoss: 3038.746094\n",
      "INFO:root:Train Epoch: 17 [800/1296 (62%)]\tLoss: 3243.662598\n",
      "INFO:root:Train Epoch: 17 [900/1296 (69%)]\tLoss: 3256.905273\n",
      "INFO:root:Train Epoch: 17 [1000/1296 (77%)]\tLoss: 2905.309082\n",
      "INFO:root:Train Epoch: 17 [1100/1296 (85%)]\tLoss: 2970.617676\n",
      "INFO:root:Train Epoch: 17 [1152/1296 (92%)]\tLoss: 3232.956787\n",
      "INFO:root:Train Epoch: 18 [0/1296 (0%)]\tLoss: 3263.273438\n",
      "INFO:root:Train Epoch: 18 [100/1296 (8%)]\tLoss: 3421.862305\n",
      "INFO:root:Train Epoch: 18 [200/1296 (15%)]\tLoss: 2989.841797\n",
      "INFO:root:Train Epoch: 18 [300/1296 (23%)]\tLoss: 2780.540771\n",
      "INFO:root:Train Epoch: 18 [400/1296 (31%)]\tLoss: 3380.471191\n",
      "INFO:root:Train Epoch: 18 [500/1296 (38%)]\tLoss: 2939.097900\n",
      "INFO:root:Train Epoch: 18 [600/1296 (46%)]\tLoss: 2880.206787\n",
      "INFO:root:Train Epoch: 18 [700/1296 (54%)]\tLoss: 2932.614746\n",
      "INFO:root:Train Epoch: 18 [800/1296 (62%)]\tLoss: 3363.336426\n",
      "INFO:root:Train Epoch: 18 [900/1296 (69%)]\tLoss: 3056.705566\n",
      "INFO:root:Train Epoch: 18 [1000/1296 (77%)]\tLoss: 2984.047119\n",
      "INFO:root:Train Epoch: 18 [1100/1296 (85%)]\tLoss: 2655.634033\n",
      "INFO:root:Train Epoch: 18 [1152/1296 (92%)]\tLoss: 2935.721436\n",
      "INFO:root:Train Epoch: 19 [0/1296 (0%)]\tLoss: 3083.627686\n",
      "INFO:root:Train Epoch: 19 [100/1296 (8%)]\tLoss: 3091.190918\n",
      "INFO:root:Train Epoch: 19 [200/1296 (15%)]\tLoss: 2966.064453\n",
      "INFO:root:Train Epoch: 19 [300/1296 (23%)]\tLoss: 3176.302979\n",
      "INFO:root:Train Epoch: 19 [400/1296 (31%)]\tLoss: 3052.487061\n",
      "INFO:root:Train Epoch: 19 [500/1296 (38%)]\tLoss: 3270.710449\n",
      "INFO:root:Train Epoch: 19 [600/1296 (46%)]\tLoss: 2706.990234\n",
      "INFO:root:Train Epoch: 19 [700/1296 (54%)]\tLoss: 2998.758545\n",
      "INFO:root:Train Epoch: 19 [800/1296 (62%)]\tLoss: 3339.983154\n",
      "INFO:root:Train Epoch: 19 [900/1296 (69%)]\tLoss: 3159.490967\n",
      "INFO:root:Train Epoch: 19 [1000/1296 (77%)]\tLoss: 3178.560303\n",
      "INFO:root:Train Epoch: 19 [1100/1296 (85%)]\tLoss: 3001.689453\n",
      "INFO:root:Train Epoch: 19 [1152/1296 (92%)]\tLoss: 2925.169678\n",
      "INFO:root:Train Epoch: 20 [0/1296 (0%)]\tLoss: 2941.435303\n",
      "INFO:root:Train Epoch: 20 [100/1296 (8%)]\tLoss: 3221.866699\n",
      "INFO:root:Train Epoch: 20 [200/1296 (15%)]\tLoss: 2846.424805\n",
      "INFO:root:Train Epoch: 20 [300/1296 (23%)]\tLoss: 3177.677734\n",
      "INFO:root:Train Epoch: 20 [400/1296 (31%)]\tLoss: 3136.442627\n",
      "INFO:root:Train Epoch: 20 [500/1296 (38%)]\tLoss: 3220.594727\n",
      "INFO:root:Train Epoch: 20 [600/1296 (46%)]\tLoss: 3183.686768\n",
      "INFO:root:Train Epoch: 20 [700/1296 (54%)]\tLoss: 2817.707764\n",
      "INFO:root:Train Epoch: 20 [800/1296 (62%)]\tLoss: 3014.063721\n",
      "INFO:root:Train Epoch: 20 [900/1296 (69%)]\tLoss: 2918.935059\n",
      "INFO:root:Train Epoch: 20 [1000/1296 (77%)]\tLoss: 2899.415771\n",
      "INFO:root:Train Epoch: 20 [1100/1296 (85%)]\tLoss: 2732.976074\n",
      "INFO:root:Train Epoch: 20 [1152/1296 (92%)]\tLoss: 2998.912598\n",
      "INFO:root:Train Epoch: 21 [0/1296 (0%)]\tLoss: 3754.597656\n",
      "INFO:root:Train Epoch: 21 [100/1296 (8%)]\tLoss: 3066.555420\n",
      "INFO:root:Train Epoch: 21 [200/1296 (15%)]\tLoss: 3090.078125\n",
      "INFO:root:Train Epoch: 21 [300/1296 (23%)]\tLoss: 3566.572998\n",
      "INFO:root:Train Epoch: 21 [400/1296 (31%)]\tLoss: 2961.401367\n",
      "INFO:root:Train Epoch: 21 [500/1296 (38%)]\tLoss: 3135.224365\n",
      "INFO:root:Train Epoch: 21 [600/1296 (46%)]\tLoss: 3284.263184\n",
      "INFO:root:Train Epoch: 21 [700/1296 (54%)]\tLoss: 2960.000244\n",
      "INFO:root:Train Epoch: 21 [800/1296 (62%)]\tLoss: 2832.491699\n",
      "INFO:root:Train Epoch: 21 [900/1296 (69%)]\tLoss: 3197.589844\n",
      "INFO:root:Train Epoch: 21 [1000/1296 (77%)]\tLoss: 3047.328857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Epoch: 21 [1100/1296 (85%)]\tLoss: 2753.583740\n",
      "INFO:root:Train Epoch: 21 [1152/1296 (92%)]\tLoss: 3260.686035\n",
      "INFO:root:Train Epoch: 22 [0/1296 (0%)]\tLoss: 3060.831299\n",
      "INFO:root:Train Epoch: 22 [100/1296 (8%)]\tLoss: 3295.530273\n",
      "INFO:root:Train Epoch: 22 [200/1296 (15%)]\tLoss: 3594.310303\n",
      "INFO:root:Train Epoch: 22 [300/1296 (23%)]\tLoss: 2934.298828\n",
      "INFO:root:Train Epoch: 22 [400/1296 (31%)]\tLoss: 2884.571533\n",
      "INFO:root:Train Epoch: 22 [500/1296 (38%)]\tLoss: 3035.305420\n",
      "INFO:root:Train Epoch: 22 [600/1296 (46%)]\tLoss: 2870.808350\n",
      "INFO:root:Train Epoch: 22 [700/1296 (54%)]\tLoss: 3092.178223\n",
      "INFO:root:Train Epoch: 22 [800/1296 (62%)]\tLoss: 2983.266113\n",
      "INFO:root:Train Epoch: 22 [900/1296 (69%)]\tLoss: 2920.132324\n",
      "INFO:root:Train Epoch: 22 [1000/1296 (77%)]\tLoss: 3114.683105\n",
      "INFO:root:Train Epoch: 22 [1100/1296 (85%)]\tLoss: 2972.305664\n",
      "INFO:root:Train Epoch: 22 [1152/1296 (92%)]\tLoss: 2899.571045\n",
      "INFO:root:Train Epoch: 23 [0/1296 (0%)]\tLoss: 2962.298828\n",
      "INFO:root:Train Epoch: 23 [100/1296 (8%)]\tLoss: 2854.000244\n",
      "INFO:root:Train Epoch: 23 [200/1296 (15%)]\tLoss: 3290.207520\n",
      "INFO:root:Train Epoch: 23 [300/1296 (23%)]\tLoss: 3131.349854\n",
      "INFO:root:Train Epoch: 23 [400/1296 (31%)]\tLoss: 3000.485596\n",
      "INFO:root:Train Epoch: 23 [500/1296 (38%)]\tLoss: 2848.216309\n",
      "INFO:root:Train Epoch: 23 [600/1296 (46%)]\tLoss: 3012.194580\n",
      "INFO:root:Train Epoch: 23 [700/1296 (54%)]\tLoss: 3369.354980\n",
      "INFO:root:Train Epoch: 23 [800/1296 (62%)]\tLoss: 2978.962402\n",
      "INFO:root:Train Epoch: 23 [900/1296 (69%)]\tLoss: 3220.716309\n",
      "INFO:root:Train Epoch: 23 [1000/1296 (77%)]\tLoss: 3301.700684\n",
      "INFO:root:Train Epoch: 23 [1100/1296 (85%)]\tLoss: 2977.021240\n",
      "INFO:root:Train Epoch: 23 [1152/1296 (92%)]\tLoss: 3030.329346\n",
      "INFO:root:Train Epoch: 24 [0/1296 (0%)]\tLoss: 3038.838135\n",
      "INFO:root:Train Epoch: 24 [100/1296 (8%)]\tLoss: 3039.094971\n",
      "INFO:root:Train Epoch: 24 [200/1296 (15%)]\tLoss: 2954.652832\n",
      "INFO:root:Train Epoch: 24 [300/1296 (23%)]\tLoss: 3268.299316\n",
      "INFO:root:Train Epoch: 24 [400/1296 (31%)]\tLoss: 3544.752930\n",
      "INFO:root:Train Epoch: 24 [500/1296 (38%)]\tLoss: 3080.549805\n",
      "INFO:root:Train Epoch: 24 [600/1296 (46%)]\tLoss: 2865.765869\n",
      "INFO:root:Train Epoch: 24 [700/1296 (54%)]\tLoss: 3248.629639\n",
      "INFO:root:Train Epoch: 24 [800/1296 (62%)]\tLoss: 3173.553223\n",
      "INFO:root:Train Epoch: 24 [900/1296 (69%)]\tLoss: 3054.399902\n",
      "INFO:root:Train Epoch: 24 [1000/1296 (77%)]\tLoss: 2850.049072\n",
      "INFO:root:Train Epoch: 24 [1100/1296 (85%)]\tLoss: 3250.386230\n",
      "INFO:root:Train Epoch: 24 [1152/1296 (92%)]\tLoss: 2806.417480\n",
      "INFO:root:Train Epoch: 25 [0/1296 (0%)]\tLoss: 3196.536133\n",
      "INFO:root:Train Epoch: 25 [100/1296 (8%)]\tLoss: 3089.308350\n",
      "INFO:root:Train Epoch: 25 [200/1296 (15%)]\tLoss: 2897.765381\n",
      "INFO:root:Train Epoch: 25 [300/1296 (23%)]\tLoss: 2816.261963\n",
      "INFO:root:Train Epoch: 25 [400/1296 (31%)]\tLoss: 3143.833008\n",
      "INFO:root:Train Epoch: 25 [500/1296 (38%)]\tLoss: 3100.910400\n",
      "INFO:root:Train Epoch: 25 [600/1296 (46%)]\tLoss: 2803.392090\n",
      "INFO:root:Train Epoch: 25 [700/1296 (54%)]\tLoss: 3191.809570\n",
      "INFO:root:Train Epoch: 25 [800/1296 (62%)]\tLoss: 3374.515137\n",
      "INFO:root:Train Epoch: 25 [900/1296 (69%)]\tLoss: 3075.496338\n",
      "INFO:root:Train Epoch: 25 [1000/1296 (77%)]\tLoss: 3161.398682\n",
      "INFO:root:Train Epoch: 25 [1100/1296 (85%)]\tLoss: 3237.909180\n",
      "INFO:root:Train Epoch: 25 [1152/1296 (92%)]\tLoss: 2957.722412\n",
      "INFO:root:Train Epoch: 26 [0/1296 (0%)]\tLoss: 2969.865479\n",
      "INFO:root:Train Epoch: 26 [100/1296 (8%)]\tLoss: 2731.775635\n",
      "INFO:root:Train Epoch: 26 [200/1296 (15%)]\tLoss: 3391.290771\n",
      "INFO:root:Train Epoch: 26 [300/1296 (23%)]\tLoss: 3157.813965\n",
      "INFO:root:Train Epoch: 26 [400/1296 (31%)]\tLoss: 2851.020020\n",
      "INFO:root:Train Epoch: 26 [500/1296 (38%)]\tLoss: 3698.886475\n",
      "INFO:root:Train Epoch: 26 [600/1296 (46%)]\tLoss: 3883.033447\n",
      "INFO:root:Train Epoch: 26 [700/1296 (54%)]\tLoss: 2893.629150\n",
      "INFO:root:Train Epoch: 26 [800/1296 (62%)]\tLoss: 3049.052734\n",
      "INFO:root:Train Epoch: 26 [900/1296 (69%)]\tLoss: 2937.638428\n",
      "INFO:root:Train Epoch: 26 [1000/1296 (77%)]\tLoss: 3130.897217\n",
      "INFO:root:Train Epoch: 26 [1100/1296 (85%)]\tLoss: 2943.755615\n",
      "INFO:root:Train Epoch: 26 [1152/1296 (92%)]\tLoss: 2952.402100\n",
      "INFO:root:Train Epoch: 27 [0/1296 (0%)]\tLoss: 3393.457520\n",
      "INFO:root:Train Epoch: 27 [100/1296 (8%)]\tLoss: 3172.545166\n",
      "INFO:root:Train Epoch: 27 [200/1296 (15%)]\tLoss: 3231.972900\n",
      "INFO:root:Train Epoch: 27 [300/1296 (23%)]\tLoss: 3468.944336\n",
      "INFO:root:Train Epoch: 27 [400/1296 (31%)]\tLoss: 3535.349365\n",
      "INFO:root:Train Epoch: 27 [500/1296 (38%)]\tLoss: 3311.932373\n",
      "INFO:root:Train Epoch: 27 [600/1296 (46%)]\tLoss: 3844.273682\n",
      "INFO:root:Train Epoch: 27 [700/1296 (54%)]\tLoss: 3278.389648\n",
      "INFO:root:Train Epoch: 27 [800/1296 (62%)]\tLoss: 2862.119629\n",
      "INFO:root:Train Epoch: 27 [900/1296 (69%)]\tLoss: 3675.561768\n",
      "INFO:root:Train Epoch: 27 [1000/1296 (77%)]\tLoss: 3980.887939\n",
      "INFO:root:Train Epoch: 27 [1100/1296 (85%)]\tLoss: 2976.387451\n",
      "INFO:root:Train Epoch: 27 [1152/1296 (92%)]\tLoss: 3974.245117\n",
      "INFO:root:Train Epoch: 28 [0/1296 (0%)]\tLoss: 4175.372070\n",
      "INFO:root:Train Epoch: 28 [100/1296 (8%)]\tLoss: 2846.359375\n",
      "INFO:root:Train Epoch: 28 [200/1296 (15%)]\tLoss: 4033.971191\n",
      "INFO:root:Train Epoch: 28 [300/1296 (23%)]\tLoss: 4390.571777\n",
      "INFO:root:Train Epoch: 28 [400/1296 (31%)]\tLoss: 3106.080322\n",
      "INFO:root:Train Epoch: 28 [500/1296 (38%)]\tLoss: 3665.322510\n",
      "INFO:root:Train Epoch: 28 [600/1296 (46%)]\tLoss: 3396.032471\n",
      "INFO:root:Train Epoch: 28 [700/1296 (54%)]\tLoss: 3155.854980\n",
      "INFO:root:Train Epoch: 28 [800/1296 (62%)]\tLoss: 3180.494873\n",
      "INFO:root:Train Epoch: 28 [900/1296 (69%)]\tLoss: 3138.386230\n",
      "INFO:root:Train Epoch: 28 [1000/1296 (77%)]\tLoss: 3055.680664\n",
      "INFO:root:Train Epoch: 28 [1100/1296 (85%)]\tLoss: 3195.567139\n",
      "INFO:root:Train Epoch: 28 [1152/1296 (92%)]\tLoss: 2845.456055\n",
      "INFO:root:Train Epoch: 29 [0/1296 (0%)]\tLoss: 3519.992188\n",
      "INFO:root:Train Epoch: 29 [100/1296 (8%)]\tLoss: 3238.132568\n",
      "INFO:root:Train Epoch: 29 [200/1296 (15%)]\tLoss: 3150.172363\n",
      "INFO:root:Train Epoch: 29 [300/1296 (23%)]\tLoss: 3045.626953\n",
      "INFO:root:Train Epoch: 29 [400/1296 (31%)]\tLoss: 3334.141113\n",
      "INFO:root:Train Epoch: 29 [500/1296 (38%)]\tLoss: 3130.075684\n",
      "INFO:root:Train Epoch: 29 [600/1296 (46%)]\tLoss: 3350.154053\n",
      "INFO:root:Train Epoch: 29 [700/1296 (54%)]\tLoss: 2784.093262\n",
      "INFO:root:Train Epoch: 29 [800/1296 (62%)]\tLoss: 3028.325439\n",
      "INFO:root:Train Epoch: 29 [900/1296 (69%)]\tLoss: 3520.618164\n",
      "INFO:root:Train Epoch: 29 [1000/1296 (77%)]\tLoss: 3083.489502\n",
      "INFO:root:Train Epoch: 29 [1100/1296 (85%)]\tLoss: 3053.194824\n",
      "INFO:root:Train Epoch: 29 [1152/1296 (92%)]\tLoss: 2910.708252\n",
      "INFO:root:Train Epoch: 30 [0/1296 (0%)]\tLoss: 2866.638428\n",
      "INFO:root:Train Epoch: 30 [100/1296 (8%)]\tLoss: 2919.725586\n",
      "INFO:root:Train Epoch: 30 [200/1296 (15%)]\tLoss: 3056.850830\n",
      "INFO:root:Train Epoch: 30 [300/1296 (23%)]\tLoss: 2888.425293\n",
      "INFO:root:Train Epoch: 30 [400/1296 (31%)]\tLoss: 3246.031494\n",
      "INFO:root:Train Epoch: 30 [500/1296 (38%)]\tLoss: 3172.608887\n",
      "INFO:root:Train Epoch: 30 [600/1296 (46%)]\tLoss: 3064.374756\n",
      "INFO:root:Train Epoch: 30 [700/1296 (54%)]\tLoss: 2934.256836\n",
      "INFO:root:Train Epoch: 30 [800/1296 (62%)]\tLoss: 3030.802246\n",
      "INFO:root:Train Epoch: 30 [900/1296 (69%)]\tLoss: 3617.698486\n",
      "INFO:root:Train Epoch: 30 [1000/1296 (77%)]\tLoss: 3213.211914\n",
      "INFO:root:Train Epoch: 30 [1100/1296 (85%)]\tLoss: 3133.079590\n",
      "INFO:root:Train Epoch: 30 [1152/1296 (92%)]\tLoss: 3213.135254\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args['epoch'] + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    #test(args, model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0071, -0.1287,  0.1259,  ...,  0.1253, -0.0517,  0.0411],\n",
      "        [-0.1447, -0.1280, -0.0043,  ..., -0.1127, -0.0791, -0.0833],\n",
      "        [-0.0141, -0.0029,  0.1197,  ..., -0.0019,  0.0951,  0.0563],\n",
      "        ...,\n",
      "        [-0.0902, -0.0325, -0.0210,  ..., -0.0407, -0.0002,  0.1448],\n",
      "        [ 0.0771,  0.1247,  0.0349,  ...,  0.0376,  0.0866,  0.0797],\n",
      "        [ 0.1361,  0.0082, -0.0669,  ..., -0.0285,  0.1064, -0.1164]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-8.5227e+02, -9.3861e-02, -5.5554e-02, -4.0435e-01, -4.3156e-02,\n",
      "        -7.7015e-02, -1.0699e+04, -4.7856e+03, -6.8719e-02, -2.5835e-02,\n",
      "        -6.5731e-02, -2.0890e+04, -6.6544e-03, -6.2132e-03, -7.8425e-02,\n",
      "        -3.8066e+03, -1.5754e+04, -1.2599e+04, -5.2499e+03, -1.8008e+04,\n",
      "        -4.2330e-03, -1.4033e-01, -2.2787e+04, -1.4855e-01, -1.4133e-01,\n",
      "        -2.0877e+03, -1.0252e-01, -8.6479e+03, -7.9017e-02, -1.7272e+04,\n",
      "        -5.5592e-01, -9.5456e-02, -5.3845e-02, -3.0728e+03, -1.1291e-01,\n",
      "        -1.5339e+04, -3.0782e-01, -1.3412e+04, -5.6820e-02, -8.4890e-02,\n",
      "        -1.2293e-01, -2.0415e+04, -4.0731e-02, -6.9655e+03, -8.1405e-02,\n",
      "        -1.2877e+04, -8.9728e-02, -2.8381e-02, -1.8626e+04, -1.4824e-01,\n",
      "        -1.4946e+04, -5.4900e-04, -3.5615e-02, -1.0496e+03, -9.9750e-02,\n",
      "        -5.9307e-02, -3.2717e-01, -1.3563e-02, -1.5210e+04, -8.6997e-02,\n",
      "        -3.6171e-02, -1.0542e+03, -1.1272e-01, -2.8143e+04, -8.4165e+03,\n",
      "        -1.1083e-01, -9.6542e+03, -4.2217e-02, -4.1416e-02, -5.4373e-02,\n",
      "        -2.0118e+04, -7.2238e+03, -2.5411e-01, -5.0105e+03, -1.1418e-01,\n",
      "        -3.6957e-02, -1.3777e-01, -1.1701e-01, -3.8463e+03, -1.7790e+04,\n",
      "        -1.1239e+04, -7.3113e-02, -1.0950e-01, -4.0537e-02, -1.5406e+04,\n",
      "        -1.4353e+04, -6.0242e+03, -1.4254e+04, -1.1837e-01, -4.6841e+03,\n",
      "        -1.4917e+04, -1.5766e+03, -6.1496e+03, -6.8619e-02, -4.9380e+03,\n",
      "        -7.7503e+03, -3.5850e-02, -4.2717e+03, -7.4760e-02, -6.9531e+03],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-9.4654e+01,  7.3755e-02, -1.3753e-02,  ..., -4.4281e+02,\n",
      "          4.7848e-02, -7.1454e+02],\n",
      "        [ 4.8255e-03,  9.4553e-02,  7.0859e-02,  ..., -3.2771e-02,\n",
      "          5.7743e-02, -5.3250e-02],\n",
      "        [ 4.1461e-02, -6.1751e-02,  2.0106e-03,  ..., -1.1378e-02,\n",
      "         -8.8564e-02, -3.7639e-02],\n",
      "        ...,\n",
      "        [ 4.0032e-02, -7.5048e-02,  4.0028e-02,  ...,  3.7768e-03,\n",
      "         -6.5962e-02, -6.4167e-02],\n",
      "        [ 5.6175e-02, -6.7201e-03,  2.9824e-02,  ..., -3.5296e-02,\n",
      "          7.3644e-02, -7.3447e-02],\n",
      "        [ 8.0671e-03, -6.3474e-03,  8.9707e-02,  ..., -2.4035e-02,\n",
      "         -8.4037e-02,  3.2776e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-2.4643e+02, -3.1066e-02, -3.4373e-02, -2.4373e-02, -1.8014e+02,\n",
      "        -6.3430e+02, -3.8672e+02, -1.9808e+01, -9.9192e+01, -2.9559e+02,\n",
      "        -2.0139e+02, -8.5077e+01, -3.6970e-01, -1.9398e+02, -3.1790e-01,\n",
      "        -2.7411e-01, -1.5800e-01, -5.4931e+01, -5.6614e+01, -2.7791e-01,\n",
      "        -1.3876e+02, -4.8995e-01, -2.1001e+02, -9.3786e+00, -3.0864e-01,\n",
      "        -4.8620e+02,  3.0559e+01, -1.0256e+01, -1.2148e+01, -2.5814e-01,\n",
      "        -4.7374e+02, -6.7211e-02, -7.6795e-02, -4.8118e+01, -6.0435e-02,\n",
      "        -7.5861e+02, -3.3038e-02, -4.4757e-01, -9.3456e-02, -1.4807e+01,\n",
      "        -3.3172e+02, -3.0775e+02, -2.8553e+02, -4.4549e+00, -5.5859e-02,\n",
      "        -2.3255e+02, -2.7848e-01, -9.2645e-02, -1.1121e+01, -3.2260e+00,\n",
      "        -6.6241e-02,  2.7306e+01, -1.7944e+02, -1.5200e+02, -4.5975e+02,\n",
      "        -3.7260e+02, -2.5944e+01, -3.0545e-01, -1.2148e-01,  1.7483e+01,\n",
      "        -3.1592e+00, -1.1941e+01, -1.9465e+00, -6.3496e-01, -4.6984e+02,\n",
      "        -7.0809e-02, -8.9643e-02, -9.6678e+00, -9.7453e-02, -8.2206e+01,\n",
      "        -1.5746e-01, -3.3924e+02, -5.7838e+02, -5.6913e+02, -8.1695e-02,\n",
      "        -2.9227e-01, -2.8634e-01, -8.6322e-02, -1.6445e+02, -3.8548e+02,\n",
      "        -5.1887e+01, -4.5242e+02, -9.3904e-02, -3.9739e-01, -4.9506e+02,\n",
      "        -8.7173e-02,  9.6260e-01, -5.7869e-02, -3.6471e+02, -3.1644e+02,\n",
      "         7.2315e+00, -1.8003e-01, -6.3384e-02, -2.3727e-01, -5.0993e+02,\n",
      "        -3.4529e-01, -9.9097e+02, -8.9471e-02, -3.7559e-01,  4.7435e+00],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-2.6948e+03,  8.5218e-03, -4.8591e-02,  ..., -1.1106e-02,\n",
      "          2.2565e-01,  1.4840e+00],\n",
      "        [-2.6881e+03, -1.8400e-02, -1.7031e-02,  ..., -1.5294e-02,\n",
      "          2.1727e-01,  1.4685e+00],\n",
      "        [-2.6753e+03,  3.9479e-02,  3.3809e-02,  ..., -3.5882e-02,\n",
      "          1.3549e-01,  1.4686e+00],\n",
      "        ...,\n",
      "        [-2.7202e+03, -8.3487e-02,  7.9663e-02,  ..., -3.6382e-02,\n",
      "          1.3482e-01,  1.4945e+00],\n",
      "        [-2.6744e+03, -1.9373e-02,  1.5079e-02,  ...,  2.8792e-02,\n",
      "          8.0116e-02,  1.4600e+00],\n",
      "        [-2.6531e+03,  5.4192e-02, -6.8543e-02,  ..., -4.6888e-02,\n",
      "          4.6930e-02,  1.4440e+00]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.8591, -0.8565, -0.6977, -0.7962, -0.8106, -0.6853, -0.8273, -0.6693,\n",
      "        -1.0962, -0.6937, -0.6868], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
