{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_num_tuples = 1296\n",
    "_num_features = 45\n",
    "_label_dims = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(files, num_tuples, num_features, label_dims):\n",
    "    data_file, label_file = files\n",
    "    print(data_file, label_file)\n",
    "    data = np.zeros((num_tuples, num_features))\n",
    "    labels = np.zeros((num_tuples, label_dims))\n",
    "    \n",
    "    with open(data_file, 'rb') as f:\n",
    "        for i,line in enumerate(f.readlines()):\n",
    "            ##################[ISSUE! @YUZHE]HARD CODED, PLEASE CHECK THE DATA FORMAT ########################\n",
    "            #processed = line.rstrip('\\n').rstrip('\\r').rstrip(',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,').split(',')\n",
    "            processed = line.rstrip('\\n').split(',')\n",
    "            ###################################################################################################\n",
    "            #logger.info(processed)\n",
    "            try:\n",
    "                assert num_features == len(processed)\n",
    "                data[i,:] = processed\n",
    "            except AssertionError as err:\n",
    "                logger.info(\"Wrong Feature Number claimed !, {}, {}\".format(num_features, len(processed)))\n",
    "                \n",
    "    with open(label_file, 'rb') as f:\n",
    "        for i,line in enumerate(f.readlines()):\n",
    "            #processed = line.rstrip('\\n').split(',')\n",
    "            processed = line.rstrip('\\n').rstrip('\\r').rstrip(',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,').split(',')\n",
    "            #print(len(processed), label_dims)\n",
    "            try:\n",
    "                assert label_dims == len(processed)\n",
    "                \n",
    "                labels[i,:] = processed\n",
    "            except AssertionError as err:\n",
    "                logger.info(\"Wrong Label Dimensions claimed !\")\n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('spectrum.csv', 'temperature.csv')\n"
     ]
    }
   ],
   "source": [
    "data, labels = load_data(('spectrum.csv', 'temperature.csv'), _num_tuples, _num_features, _label_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, data):\n",
    "        # m, n denote number of tuples and features respectively\n",
    "        self._m = data[0].shape[0]\n",
    "        self._n = data[0].shape[1]\n",
    "        self._training_data = data[0]\n",
    "        self._training_labels = data[1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._m\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return  self._training_data[idx,:], self._training_labels[idx,:] \n",
    "\n",
    "    def fetch_col(self, col_index):\n",
    "        return self._training_data[:, col_index]\n",
    "\n",
    "    def shuffle(self, seed=None):\n",
    "        if seed:\n",
    "            np.random.seed(seed=seed)\n",
    "        shuffled_indices = np.arange(self._m)\n",
    "        np.random.shuffle(shuffled_indices)\n",
    "        self._training_data = np.take(self._training_data, shuffled_indices, axis=0)\n",
    "        self._training_labels = np.take(self._training_labels, shuffled_indices)\n",
    "\n",
    "    @property\n",
    "    def num_tuples(self):\n",
    "        return self._m\n",
    "\n",
    "    @property\n",
    "    def num_features(self):\n",
    "        return self._n\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._training_labels\n",
    "\n",
    "    @property\n",
    "    def data_table(self):\n",
    "        return self._training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset((data, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# model definition\n",
    "# notes from Yuzhe: Here are the parameters for the neural network,total of 3 layers of network\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(45, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 11)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        ## notes from Yuzhe: Following are the activate function for network\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        #x = self.relu(x)\n",
    "        return x\n",
    "    def name(self):\n",
    "        return 'nn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "## notes from Yuzhe, following are parameters that can be changed to modify the training code\n",
    "args = {'lr':0.001, ## learning rate\n",
    "        'max_steps':30,   ## maximum numbers of iteration\n",
    "        'batch_size':100,   \n",
    "        'epoch':30,\n",
    "        'enable_gpu':None}\n",
    "train_loader = DataLoader(dataset, batch_size=args['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = NN().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.float().to(device), target.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.mse_loss(output, target)\n",
    "        if epoch >= 499:\n",
    "            print(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        logger.info('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.mse_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    logger.info('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Epoch: 1 [0/1296 (0%)]\tLoss: 393816.250000\n",
      "INFO:root:Train Epoch: 1 [100/1296 (8%)]\tLoss: 397791.875000\n",
      "INFO:root:Train Epoch: 1 [200/1296 (15%)]\tLoss: 399383.562500\n",
      "INFO:root:Train Epoch: 1 [300/1296 (23%)]\tLoss: 403071.250000\n",
      "INFO:root:Train Epoch: 1 [400/1296 (31%)]\tLoss: 302302.968750\n",
      "INFO:root:Train Epoch: 1 [500/1296 (38%)]\tLoss: 13862247.000000\n",
      "INFO:root:Train Epoch: 1 [600/1296 (46%)]\tLoss: 390826.156250\n",
      "INFO:root:Train Epoch: 1 [700/1296 (54%)]\tLoss: 398823.937500\n",
      "INFO:root:Train Epoch: 1 [800/1296 (62%)]\tLoss: 407833.062500\n",
      "INFO:root:Train Epoch: 1 [900/1296 (69%)]\tLoss: 389083.531250\n",
      "INFO:root:Train Epoch: 1 [1000/1296 (77%)]\tLoss: 400359.781250\n",
      "INFO:root:Train Epoch: 1 [1100/1296 (85%)]\tLoss: 398740.718750\n",
      "INFO:root:Train Epoch: 1 [1152/1296 (92%)]\tLoss: 390604.781250\n",
      "INFO:root:Train Epoch: 2 [0/1296 (0%)]\tLoss: 374498.093750\n",
      "INFO:root:Train Epoch: 2 [100/1296 (8%)]\tLoss: 348997.656250\n",
      "INFO:root:Train Epoch: 2 [200/1296 (15%)]\tLoss: 271107.250000\n",
      "INFO:root:Train Epoch: 2 [300/1296 (23%)]\tLoss: 104146.851562\n",
      "INFO:root:Train Epoch: 2 [400/1296 (31%)]\tLoss: 19075.142578\n",
      "INFO:root:Train Epoch: 2 [500/1296 (38%)]\tLoss: 302755.812500\n",
      "INFO:root:Train Epoch: 2 [600/1296 (46%)]\tLoss: 49242.855469\n",
      "INFO:root:Train Epoch: 2 [700/1296 (54%)]\tLoss: 45356.000000\n",
      "INFO:root:Train Epoch: 2 [800/1296 (62%)]\tLoss: 142300.546875\n",
      "INFO:root:Train Epoch: 2 [900/1296 (69%)]\tLoss: 176968.406250\n",
      "INFO:root:Train Epoch: 2 [1000/1296 (77%)]\tLoss: 113427.179688\n",
      "INFO:root:Train Epoch: 2 [1100/1296 (85%)]\tLoss: 12228.110352\n",
      "INFO:root:Train Epoch: 2 [1152/1296 (92%)]\tLoss: 72482.273438\n",
      "INFO:root:Train Epoch: 3 [0/1296 (0%)]\tLoss: 121794.890625\n",
      "INFO:root:Train Epoch: 3 [100/1296 (8%)]\tLoss: 3465.963379\n",
      "INFO:root:Train Epoch: 3 [200/1296 (15%)]\tLoss: 42978.140625\n",
      "INFO:root:Train Epoch: 3 [300/1296 (23%)]\tLoss: 76389.875000\n",
      "INFO:root:Train Epoch: 3 [400/1296 (31%)]\tLoss: 63636.140625\n",
      "INFO:root:Train Epoch: 3 [500/1296 (38%)]\tLoss: 10217.739258\n",
      "INFO:root:Train Epoch: 3 [600/1296 (46%)]\tLoss: 27677.349609\n",
      "INFO:root:Train Epoch: 3 [700/1296 (54%)]\tLoss: 70005.570312\n",
      "INFO:root:Train Epoch: 3 [800/1296 (62%)]\tLoss: 8338.824219\n",
      "INFO:root:Train Epoch: 3 [900/1296 (69%)]\tLoss: 16539.001953\n",
      "INFO:root:Train Epoch: 3 [1000/1296 (77%)]\tLoss: 48823.972656\n",
      "INFO:root:Train Epoch: 3 [1100/1296 (85%)]\tLoss: 38481.718750\n",
      "INFO:root:Train Epoch: 3 [1152/1296 (92%)]\tLoss: 6168.481445\n",
      "INFO:root:Train Epoch: 4 [0/1296 (0%)]\tLoss: 21574.140625\n",
      "INFO:root:Train Epoch: 4 [100/1296 (8%)]\tLoss: 35466.679688\n",
      "INFO:root:Train Epoch: 4 [200/1296 (15%)]\tLoss: 5618.351074\n",
      "INFO:root:Train Epoch: 4 [300/1296 (23%)]\tLoss: 8670.100586\n",
      "INFO:root:Train Epoch: 4 [400/1296 (31%)]\tLoss: 26588.484375\n",
      "INFO:root:Train Epoch: 4 [500/1296 (38%)]\tLoss: 16998.884766\n",
      "INFO:root:Train Epoch: 4 [600/1296 (46%)]\tLoss: 3259.960449\n",
      "INFO:root:Train Epoch: 4 [700/1296 (54%)]\tLoss: 14546.805664\n",
      "INFO:root:Train Epoch: 4 [800/1296 (62%)]\tLoss: 18282.802734\n",
      "INFO:root:Train Epoch: 4 [900/1296 (69%)]\tLoss: 4028.384033\n",
      "INFO:root:Train Epoch: 4 [1000/1296 (77%)]\tLoss: 8379.590820\n",
      "INFO:root:Train Epoch: 4 [1100/1296 (85%)]\tLoss: 11936.886719\n",
      "INFO:root:Train Epoch: 4 [1152/1296 (92%)]\tLoss: 7638.426270\n",
      "INFO:root:Train Epoch: 5 [0/1296 (0%)]\tLoss: 2933.826416\n",
      "INFO:root:Train Epoch: 5 [100/1296 (8%)]\tLoss: 8373.582031\n",
      "INFO:root:Train Epoch: 5 [200/1296 (15%)]\tLoss: 9522.912109\n",
      "INFO:root:Train Epoch: 5 [300/1296 (23%)]\tLoss: 3367.499756\n",
      "INFO:root:Train Epoch: 5 [400/1296 (31%)]\tLoss: 4262.415039\n",
      "INFO:root:Train Epoch: 5 [500/1296 (38%)]\tLoss: 8305.729492\n",
      "INFO:root:Train Epoch: 5 [600/1296 (46%)]\tLoss: 6680.169922\n",
      "INFO:root:Train Epoch: 5 [700/1296 (54%)]\tLoss: 3126.721191\n",
      "INFO:root:Train Epoch: 5 [800/1296 (62%)]\tLoss: 5920.074707\n",
      "INFO:root:Train Epoch: 5 [900/1296 (69%)]\tLoss: 7464.201660\n",
      "INFO:root:Train Epoch: 5 [1000/1296 (77%)]\tLoss: 3130.517578\n",
      "INFO:root:Train Epoch: 5 [1100/1296 (85%)]\tLoss: 4765.141113\n",
      "INFO:root:Train Epoch: 5 [1152/1296 (92%)]\tLoss: 7364.622070\n",
      "INFO:root:Train Epoch: 6 [0/1296 (0%)]\tLoss: 4088.382568\n",
      "INFO:root:Train Epoch: 6 [100/1296 (8%)]\tLoss: 3167.944824\n",
      "INFO:root:Train Epoch: 6 [200/1296 (15%)]\tLoss: 4187.288574\n",
      "INFO:root:Train Epoch: 6 [300/1296 (23%)]\tLoss: 4433.703613\n",
      "INFO:root:Train Epoch: 6 [400/1296 (31%)]\tLoss: 3194.912354\n",
      "INFO:root:Train Epoch: 6 [500/1296 (38%)]\tLoss: 3837.675293\n",
      "INFO:root:Train Epoch: 6 [600/1296 (46%)]\tLoss: 5557.883301\n",
      "INFO:root:Train Epoch: 6 [700/1296 (54%)]\tLoss: 3869.762451\n",
      "INFO:root:Train Epoch: 6 [800/1296 (62%)]\tLoss: 3712.861816\n",
      "INFO:root:Train Epoch: 6 [900/1296 (69%)]\tLoss: 5270.446777\n",
      "INFO:root:Train Epoch: 6 [1000/1296 (77%)]\tLoss: 3357.382324\n",
      "INFO:root:Train Epoch: 6 [1100/1296 (85%)]\tLoss: 3313.971924\n",
      "INFO:root:Train Epoch: 6 [1152/1296 (92%)]\tLoss: 3005.305420\n",
      "INFO:root:Train Epoch: 7 [0/1296 (0%)]\tLoss: 4337.589355\n",
      "INFO:root:Train Epoch: 7 [100/1296 (8%)]\tLoss: 2959.833984\n",
      "INFO:root:Train Epoch: 7 [200/1296 (15%)]\tLoss: 3138.877930\n",
      "INFO:root:Train Epoch: 7 [300/1296 (23%)]\tLoss: 3658.814209\n",
      "INFO:root:Train Epoch: 7 [400/1296 (31%)]\tLoss: 3437.990234\n",
      "INFO:root:Train Epoch: 7 [500/1296 (38%)]\tLoss: 2861.046875\n",
      "INFO:root:Train Epoch: 7 [600/1296 (46%)]\tLoss: 3624.319092\n",
      "INFO:root:Train Epoch: 7 [700/1296 (54%)]\tLoss: 3065.791016\n",
      "INFO:root:Train Epoch: 7 [800/1296 (62%)]\tLoss: 3061.240967\n",
      "INFO:root:Train Epoch: 7 [900/1296 (69%)]\tLoss: 2920.209961\n",
      "INFO:root:Train Epoch: 7 [1000/1296 (77%)]\tLoss: 3648.395508\n",
      "INFO:root:Train Epoch: 7 [1100/1296 (85%)]\tLoss: 3154.839600\n",
      "INFO:root:Train Epoch: 7 [1152/1296 (92%)]\tLoss: 3067.039307\n",
      "INFO:root:Train Epoch: 8 [0/1296 (0%)]\tLoss: 3065.937988\n",
      "INFO:root:Train Epoch: 8 [100/1296 (8%)]\tLoss: 2866.972412\n",
      "INFO:root:Train Epoch: 8 [200/1296 (15%)]\tLoss: 3113.056152\n",
      "INFO:root:Train Epoch: 8 [300/1296 (23%)]\tLoss: 3057.812256\n",
      "INFO:root:Train Epoch: 8 [400/1296 (31%)]\tLoss: 2869.523193\n",
      "INFO:root:Train Epoch: 8 [500/1296 (38%)]\tLoss: 3296.885986\n",
      "INFO:root:Train Epoch: 8 [600/1296 (46%)]\tLoss: 3004.029785\n",
      "INFO:root:Train Epoch: 8 [700/1296 (54%)]\tLoss: 2909.185303\n",
      "INFO:root:Train Epoch: 8 [800/1296 (62%)]\tLoss: 2942.312988\n",
      "INFO:root:Train Epoch: 8 [900/1296 (69%)]\tLoss: 3090.629150\n",
      "INFO:root:Train Epoch: 8 [1000/1296 (77%)]\tLoss: 3022.451172\n",
      "INFO:root:Train Epoch: 8 [1100/1296 (85%)]\tLoss: 2793.134521\n",
      "INFO:root:Train Epoch: 8 [1152/1296 (92%)]\tLoss: 2902.844727\n",
      "INFO:root:Train Epoch: 9 [0/1296 (0%)]\tLoss: 3039.346680\n",
      "INFO:root:Train Epoch: 9 [100/1296 (8%)]\tLoss: 3069.697266\n",
      "INFO:root:Train Epoch: 9 [200/1296 (15%)]\tLoss: 2827.375000\n",
      "INFO:root:Train Epoch: 9 [300/1296 (23%)]\tLoss: 3020.493164\n",
      "INFO:root:Train Epoch: 9 [400/1296 (31%)]\tLoss: 2983.273438\n",
      "INFO:root:Train Epoch: 9 [500/1296 (38%)]\tLoss: 2873.414062\n",
      "INFO:root:Train Epoch: 9 [600/1296 (46%)]\tLoss: 3039.288086\n",
      "INFO:root:Train Epoch: 9 [700/1296 (54%)]\tLoss: 3519.197510\n",
      "INFO:root:Train Epoch: 9 [800/1296 (62%)]\tLoss: 2814.196289\n",
      "INFO:root:Train Epoch: 9 [900/1296 (69%)]\tLoss: 3311.447266\n",
      "INFO:root:Train Epoch: 9 [1000/1296 (77%)]\tLoss: 3243.741699\n",
      "INFO:root:Train Epoch: 9 [1100/1296 (85%)]\tLoss: 3128.684326\n",
      "INFO:root:Train Epoch: 9 [1152/1296 (92%)]\tLoss: 2853.484863\n",
      "INFO:root:Train Epoch: 10 [0/1296 (0%)]\tLoss: 3048.263184\n",
      "INFO:root:Train Epoch: 10 [100/1296 (8%)]\tLoss: 2997.922119\n",
      "INFO:root:Train Epoch: 10 [200/1296 (15%)]\tLoss: 3158.491943\n",
      "INFO:root:Train Epoch: 10 [300/1296 (23%)]\tLoss: 2558.287842\n",
      "INFO:root:Train Epoch: 10 [400/1296 (31%)]\tLoss: 3031.162354\n",
      "INFO:root:Train Epoch: 10 [500/1296 (38%)]\tLoss: 2895.540283\n",
      "INFO:root:Train Epoch: 10 [600/1296 (46%)]\tLoss: 3112.631348\n",
      "INFO:root:Train Epoch: 10 [700/1296 (54%)]\tLoss: 2965.366455\n",
      "INFO:root:Train Epoch: 10 [800/1296 (62%)]\tLoss: 2942.469238\n",
      "INFO:root:Train Epoch: 10 [900/1296 (69%)]\tLoss: 2897.106689\n",
      "INFO:root:Train Epoch: 10 [1000/1296 (77%)]\tLoss: 3013.564209\n",
      "INFO:root:Train Epoch: 10 [1100/1296 (85%)]\tLoss: 3299.215332\n",
      "INFO:root:Train Epoch: 10 [1152/1296 (92%)]\tLoss: 3435.302490\n",
      "INFO:root:Train Epoch: 11 [0/1296 (0%)]\tLoss: 3082.104492\n",
      "INFO:root:Train Epoch: 11 [100/1296 (8%)]\tLoss: 3115.916260\n",
      "INFO:root:Train Epoch: 11 [200/1296 (15%)]\tLoss: 2818.754883\n",
      "INFO:root:Train Epoch: 11 [300/1296 (23%)]\tLoss: 3173.224365\n",
      "INFO:root:Train Epoch: 11 [400/1296 (31%)]\tLoss: 2889.041992\n",
      "INFO:root:Train Epoch: 11 [500/1296 (38%)]\tLoss: 3067.488770\n",
      "INFO:root:Train Epoch: 11 [600/1296 (46%)]\tLoss: 2784.351074\n",
      "INFO:root:Train Epoch: 11 [700/1296 (54%)]\tLoss: 3071.873291\n",
      "INFO:root:Train Epoch: 11 [800/1296 (62%)]\tLoss: 3186.151855\n",
      "INFO:root:Train Epoch: 11 [900/1296 (69%)]\tLoss: 2907.128662\n",
      "INFO:root:Train Epoch: 11 [1000/1296 (77%)]\tLoss: 3005.345703\n",
      "INFO:root:Train Epoch: 11 [1100/1296 (85%)]\tLoss: 3248.810547\n",
      "INFO:root:Train Epoch: 11 [1152/1296 (92%)]\tLoss: 2915.034912\n",
      "INFO:root:Train Epoch: 12 [0/1296 (0%)]\tLoss: 3010.171143\n",
      "INFO:root:Train Epoch: 12 [100/1296 (8%)]\tLoss: 3115.236084\n",
      "INFO:root:Train Epoch: 12 [200/1296 (15%)]\tLoss: 3416.306396\n",
      "INFO:root:Train Epoch: 12 [300/1296 (23%)]\tLoss: 3384.505615\n",
      "INFO:root:Train Epoch: 12 [400/1296 (31%)]\tLoss: 2774.374268\n",
      "INFO:root:Train Epoch: 12 [500/1296 (38%)]\tLoss: 2957.078125\n",
      "INFO:root:Train Epoch: 12 [600/1296 (46%)]\tLoss: 3445.048096\n",
      "INFO:root:Train Epoch: 12 [700/1296 (54%)]\tLoss: 3000.637207\n",
      "INFO:root:Train Epoch: 12 [800/1296 (62%)]\tLoss: 3520.591309\n",
      "INFO:root:Train Epoch: 12 [900/1296 (69%)]\tLoss: 3045.701416\n",
      "INFO:root:Train Epoch: 12 [1000/1296 (77%)]\tLoss: 3166.297607\n",
      "INFO:root:Train Epoch: 12 [1100/1296 (85%)]\tLoss: 3078.968018\n",
      "INFO:root:Train Epoch: 12 [1152/1296 (92%)]\tLoss: 2727.722656\n",
      "INFO:root:Train Epoch: 13 [0/1296 (0%)]\tLoss: 3328.671387\n",
      "INFO:root:Train Epoch: 13 [100/1296 (8%)]\tLoss: 3008.368896\n",
      "INFO:root:Train Epoch: 13 [200/1296 (15%)]\tLoss: 2874.714600\n",
      "INFO:root:Train Epoch: 13 [300/1296 (23%)]\tLoss: 3025.340820\n",
      "INFO:root:Train Epoch: 13 [400/1296 (31%)]\tLoss: 2876.059082\n",
      "INFO:root:Train Epoch: 13 [500/1296 (38%)]\tLoss: 3661.888184\n",
      "INFO:root:Train Epoch: 13 [600/1296 (46%)]\tLoss: 2942.454102\n",
      "INFO:root:Train Epoch: 13 [700/1296 (54%)]\tLoss: 2966.039551\n",
      "INFO:root:Train Epoch: 13 [800/1296 (62%)]\tLoss: 3278.821777\n",
      "INFO:root:Train Epoch: 13 [900/1296 (69%)]\tLoss: 2823.112549\n",
      "INFO:root:Train Epoch: 13 [1000/1296 (77%)]\tLoss: 2896.403809\n",
      "INFO:root:Train Epoch: 13 [1100/1296 (85%)]\tLoss: 2789.485596\n",
      "INFO:root:Train Epoch: 13 [1152/1296 (92%)]\tLoss: 3128.575928\n",
      "INFO:root:Train Epoch: 14 [0/1296 (0%)]\tLoss: 3073.679199\n",
      "INFO:root:Train Epoch: 14 [100/1296 (8%)]\tLoss: 3033.354736\n",
      "INFO:root:Train Epoch: 14 [200/1296 (15%)]\tLoss: 2982.508301\n",
      "INFO:root:Train Epoch: 14 [300/1296 (23%)]\tLoss: 3052.652588\n",
      "INFO:root:Train Epoch: 14 [400/1296 (31%)]\tLoss: 3098.228516\n",
      "INFO:root:Train Epoch: 14 [500/1296 (38%)]\tLoss: 2639.917480\n",
      "INFO:root:Train Epoch: 14 [600/1296 (46%)]\tLoss: 3014.488037\n",
      "INFO:root:Train Epoch: 14 [700/1296 (54%)]\tLoss: 2870.620361\n",
      "INFO:root:Train Epoch: 14 [800/1296 (62%)]\tLoss: 3231.055176\n",
      "INFO:root:Train Epoch: 14 [900/1296 (69%)]\tLoss: 3508.732666\n",
      "INFO:root:Train Epoch: 14 [1000/1296 (77%)]\tLoss: 3101.942627\n",
      "INFO:root:Train Epoch: 14 [1100/1296 (85%)]\tLoss: 3216.391846\n",
      "INFO:root:Train Epoch: 14 [1152/1296 (92%)]\tLoss: 3080.912842\n",
      "INFO:root:Train Epoch: 15 [0/1296 (0%)]\tLoss: 3045.643066\n",
      "INFO:root:Train Epoch: 15 [100/1296 (8%)]\tLoss: 2957.622314\n",
      "INFO:root:Train Epoch: 15 [200/1296 (15%)]\tLoss: 2809.766846\n",
      "INFO:root:Train Epoch: 15 [300/1296 (23%)]\tLoss: 3498.122803\n",
      "INFO:root:Train Epoch: 15 [400/1296 (31%)]\tLoss: 3160.886475\n",
      "INFO:root:Train Epoch: 15 [500/1296 (38%)]\tLoss: 3079.299316\n",
      "INFO:root:Train Epoch: 15 [600/1296 (46%)]\tLoss: 2776.078613\n",
      "INFO:root:Train Epoch: 15 [700/1296 (54%)]\tLoss: 3256.830811\n",
      "INFO:root:Train Epoch: 15 [800/1296 (62%)]\tLoss: 3314.111084\n",
      "INFO:root:Train Epoch: 15 [900/1296 (69%)]\tLoss: 2955.536133\n",
      "INFO:root:Train Epoch: 15 [1000/1296 (77%)]\tLoss: 3398.543213\n",
      "INFO:root:Train Epoch: 15 [1100/1296 (85%)]\tLoss: 2741.242188\n",
      "INFO:root:Train Epoch: 15 [1152/1296 (92%)]\tLoss: 2716.392822\n",
      "INFO:root:Train Epoch: 16 [0/1296 (0%)]\tLoss: 2794.219727\n",
      "INFO:root:Train Epoch: 16 [100/1296 (8%)]\tLoss: 3249.474609\n",
      "INFO:root:Train Epoch: 16 [200/1296 (15%)]\tLoss: 2909.221680\n",
      "INFO:root:Train Epoch: 16 [300/1296 (23%)]\tLoss: 2912.631836\n",
      "INFO:root:Train Epoch: 16 [400/1296 (31%)]\tLoss: 2833.759277\n",
      "INFO:root:Train Epoch: 16 [500/1296 (38%)]\tLoss: 3276.238281\n",
      "INFO:root:Train Epoch: 16 [600/1296 (46%)]\tLoss: 3074.509277\n",
      "INFO:root:Train Epoch: 16 [700/1296 (54%)]\tLoss: 2587.852539\n",
      "INFO:root:Train Epoch: 16 [800/1296 (62%)]\tLoss: 3067.769531\n",
      "INFO:root:Train Epoch: 16 [900/1296 (69%)]\tLoss: 3129.446777\n",
      "INFO:root:Train Epoch: 16 [1000/1296 (77%)]\tLoss: 2817.740234\n",
      "INFO:root:Train Epoch: 16 [1100/1296 (85%)]\tLoss: 3325.336670\n",
      "INFO:root:Train Epoch: 16 [1152/1296 (92%)]\tLoss: 2968.830078\n",
      "INFO:root:Train Epoch: 17 [0/1296 (0%)]\tLoss: 3077.616699\n",
      "INFO:root:Train Epoch: 17 [100/1296 (8%)]\tLoss: 3323.015381\n",
      "INFO:root:Train Epoch: 17 [200/1296 (15%)]\tLoss: 2846.470947\n",
      "INFO:root:Train Epoch: 17 [300/1296 (23%)]\tLoss: 2939.113770\n",
      "INFO:root:Train Epoch: 17 [400/1296 (31%)]\tLoss: 2912.574463\n",
      "INFO:root:Train Epoch: 17 [500/1296 (38%)]\tLoss: 2906.916992\n",
      "INFO:root:Train Epoch: 17 [600/1296 (46%)]\tLoss: 3049.273926\n",
      "INFO:root:Train Epoch: 17 [700/1296 (54%)]\tLoss: 2860.429932\n",
      "INFO:root:Train Epoch: 17 [800/1296 (62%)]\tLoss: 3417.825195\n",
      "INFO:root:Train Epoch: 17 [900/1296 (69%)]\tLoss: 3000.560303\n",
      "INFO:root:Train Epoch: 17 [1000/1296 (77%)]\tLoss: 3215.360352\n",
      "INFO:root:Train Epoch: 17 [1100/1296 (85%)]\tLoss: 3083.245361\n",
      "INFO:root:Train Epoch: 17 [1152/1296 (92%)]\tLoss: 3304.170898\n",
      "INFO:root:Train Epoch: 18 [0/1296 (0%)]\tLoss: 3084.631836\n",
      "INFO:root:Train Epoch: 18 [100/1296 (8%)]\tLoss: 3035.326904\n",
      "INFO:root:Train Epoch: 18 [200/1296 (15%)]\tLoss: 3494.635742\n",
      "INFO:root:Train Epoch: 18 [300/1296 (23%)]\tLoss: 3360.016357\n",
      "INFO:root:Train Epoch: 18 [400/1296 (31%)]\tLoss: 2650.238525\n",
      "INFO:root:Train Epoch: 18 [500/1296 (38%)]\tLoss: 3561.045410\n",
      "INFO:root:Train Epoch: 18 [600/1296 (46%)]\tLoss: 3575.569580\n",
      "INFO:root:Train Epoch: 18 [700/1296 (54%)]\tLoss: 3173.514648\n",
      "INFO:root:Train Epoch: 18 [800/1296 (62%)]\tLoss: 2947.683838\n",
      "INFO:root:Train Epoch: 18 [900/1296 (69%)]\tLoss: 3360.824951\n",
      "INFO:root:Train Epoch: 18 [1000/1296 (77%)]\tLoss: 3317.133545\n",
      "INFO:root:Train Epoch: 18 [1100/1296 (85%)]\tLoss: 3012.177979\n",
      "INFO:root:Train Epoch: 18 [1152/1296 (92%)]\tLoss: 3225.195068\n",
      "INFO:root:Train Epoch: 19 [0/1296 (0%)]\tLoss: 3965.643311\n",
      "INFO:root:Train Epoch: 19 [100/1296 (8%)]\tLoss: 2940.872314\n",
      "INFO:root:Train Epoch: 19 [200/1296 (15%)]\tLoss: 3571.880859\n",
      "INFO:root:Train Epoch: 19 [300/1296 (23%)]\tLoss: 3141.219482\n",
      "INFO:root:Train Epoch: 19 [400/1296 (31%)]\tLoss: 2910.444336\n",
      "INFO:root:Train Epoch: 19 [500/1296 (38%)]\tLoss: 2738.987061\n",
      "INFO:root:Train Epoch: 19 [600/1296 (46%)]\tLoss: 4112.467285\n",
      "INFO:root:Train Epoch: 19 [700/1296 (54%)]\tLoss: 3136.484375\n",
      "INFO:root:Train Epoch: 19 [800/1296 (62%)]\tLoss: 3115.442871\n",
      "INFO:root:Train Epoch: 19 [900/1296 (69%)]\tLoss: 3061.374756\n",
      "INFO:root:Train Epoch: 19 [1000/1296 (77%)]\tLoss: 3302.708496\n",
      "INFO:root:Train Epoch: 19 [1100/1296 (85%)]\tLoss: 3363.493164\n",
      "INFO:root:Train Epoch: 19 [1152/1296 (92%)]\tLoss: 3507.835938\n",
      "INFO:root:Train Epoch: 20 [0/1296 (0%)]\tLoss: 3304.111084\n",
      "INFO:root:Train Epoch: 20 [100/1296 (8%)]\tLoss: 2616.879639\n",
      "INFO:root:Train Epoch: 20 [200/1296 (15%)]\tLoss: 2936.441162\n",
      "INFO:root:Train Epoch: 20 [300/1296 (23%)]\tLoss: 3207.389160\n",
      "INFO:root:Train Epoch: 20 [400/1296 (31%)]\tLoss: 3194.825195\n",
      "INFO:root:Train Epoch: 20 [500/1296 (38%)]\tLoss: 2395.211182\n",
      "INFO:root:Train Epoch: 20 [600/1296 (46%)]\tLoss: 3142.332764\n",
      "INFO:root:Train Epoch: 20 [700/1296 (54%)]\tLoss: 3021.000977\n",
      "INFO:root:Train Epoch: 20 [800/1296 (62%)]\tLoss: 2975.909912\n",
      "INFO:root:Train Epoch: 20 [900/1296 (69%)]\tLoss: 3038.610352\n",
      "INFO:root:Train Epoch: 20 [1000/1296 (77%)]\tLoss: 3324.920898\n",
      "INFO:root:Train Epoch: 20 [1100/1296 (85%)]\tLoss: 3065.820801\n",
      "INFO:root:Train Epoch: 20 [1152/1296 (92%)]\tLoss: 2987.529541\n",
      "INFO:root:Train Epoch: 21 [0/1296 (0%)]\tLoss: 3139.458252\n",
      "INFO:root:Train Epoch: 21 [100/1296 (8%)]\tLoss: 3084.965820\n",
      "INFO:root:Train Epoch: 21 [200/1296 (15%)]\tLoss: 2803.515869\n",
      "INFO:root:Train Epoch: 21 [300/1296 (23%)]\tLoss: 3173.989990\n",
      "INFO:root:Train Epoch: 21 [400/1296 (31%)]\tLoss: 3001.181885\n",
      "INFO:root:Train Epoch: 21 [500/1296 (38%)]\tLoss: 3342.075684\n",
      "INFO:root:Train Epoch: 21 [600/1296 (46%)]\tLoss: 3027.763428\n",
      "INFO:root:Train Epoch: 21 [700/1296 (54%)]\tLoss: 2935.705566\n",
      "INFO:root:Train Epoch: 21 [800/1296 (62%)]\tLoss: 3079.305664\n",
      "INFO:root:Train Epoch: 21 [900/1296 (69%)]\tLoss: 3036.888916\n",
      "INFO:root:Train Epoch: 21 [1000/1296 (77%)]\tLoss: 3188.669189\n",
      "INFO:root:Train Epoch: 21 [1100/1296 (85%)]\tLoss: 2848.650391\n",
      "INFO:root:Train Epoch: 21 [1152/1296 (92%)]\tLoss: 2997.997070\n",
      "INFO:root:Train Epoch: 22 [0/1296 (0%)]\tLoss: 3160.799561\n",
      "INFO:root:Train Epoch: 22 [100/1296 (8%)]\tLoss: 3111.670410\n",
      "INFO:root:Train Epoch: 22 [200/1296 (15%)]\tLoss: 3129.065430\n",
      "INFO:root:Train Epoch: 22 [300/1296 (23%)]\tLoss: 2777.662354\n",
      "INFO:root:Train Epoch: 22 [400/1296 (31%)]\tLoss: 2955.685303\n",
      "INFO:root:Train Epoch: 22 [500/1296 (38%)]\tLoss: 3181.929199\n",
      "INFO:root:Train Epoch: 22 [600/1296 (46%)]\tLoss: 2813.882812\n",
      "INFO:root:Train Epoch: 22 [700/1296 (54%)]\tLoss: 3196.953369\n",
      "INFO:root:Train Epoch: 22 [800/1296 (62%)]\tLoss: 3027.150391\n",
      "INFO:root:Train Epoch: 22 [900/1296 (69%)]\tLoss: 2954.097168\n",
      "INFO:root:Train Epoch: 22 [1000/1296 (77%)]\tLoss: 2900.611816\n",
      "INFO:root:Train Epoch: 22 [1100/1296 (85%)]\tLoss: 3593.053223\n",
      "INFO:root:Train Epoch: 22 [1152/1296 (92%)]\tLoss: 2766.839844\n",
      "INFO:root:Train Epoch: 23 [0/1296 (0%)]\tLoss: 2982.548584\n",
      "INFO:root:Train Epoch: 23 [100/1296 (8%)]\tLoss: 2827.497803\n",
      "INFO:root:Train Epoch: 23 [200/1296 (15%)]\tLoss: 2799.458496\n",
      "INFO:root:Train Epoch: 23 [300/1296 (23%)]\tLoss: 3264.188477\n",
      "INFO:root:Train Epoch: 23 [400/1296 (31%)]\tLoss: 3026.427490\n",
      "INFO:root:Train Epoch: 23 [500/1296 (38%)]\tLoss: 3101.686035\n",
      "INFO:root:Train Epoch: 23 [600/1296 (46%)]\tLoss: 2960.708252\n",
      "INFO:root:Train Epoch: 23 [700/1296 (54%)]\tLoss: 3486.368164\n",
      "INFO:root:Train Epoch: 23 [800/1296 (62%)]\tLoss: 3089.245117\n",
      "INFO:root:Train Epoch: 23 [900/1296 (69%)]\tLoss: 3019.472168\n",
      "INFO:root:Train Epoch: 23 [1000/1296 (77%)]\tLoss: 3038.282715\n",
      "INFO:root:Train Epoch: 23 [1100/1296 (85%)]\tLoss: 3174.593506\n",
      "INFO:root:Train Epoch: 23 [1152/1296 (92%)]\tLoss: 2823.856445\n",
      "INFO:root:Train Epoch: 24 [0/1296 (0%)]\tLoss: 2843.143555\n",
      "INFO:root:Train Epoch: 24 [100/1296 (8%)]\tLoss: 2955.469727\n",
      "INFO:root:Train Epoch: 24 [200/1296 (15%)]\tLoss: 3285.646973\n",
      "INFO:root:Train Epoch: 24 [300/1296 (23%)]\tLoss: 2823.219238\n",
      "INFO:root:Train Epoch: 24 [400/1296 (31%)]\tLoss: 3070.453125\n",
      "INFO:root:Train Epoch: 24 [500/1296 (38%)]\tLoss: 3113.756104\n",
      "INFO:root:Train Epoch: 24 [600/1296 (46%)]\tLoss: 2959.592529\n",
      "INFO:root:Train Epoch: 24 [700/1296 (54%)]\tLoss: 3487.108154\n",
      "INFO:root:Train Epoch: 24 [800/1296 (62%)]\tLoss: 2988.011719\n",
      "INFO:root:Train Epoch: 24 [900/1296 (69%)]\tLoss: 3165.212402\n",
      "INFO:root:Train Epoch: 24 [1000/1296 (77%)]\tLoss: 2970.654053\n",
      "INFO:root:Train Epoch: 24 [1100/1296 (85%)]\tLoss: 3163.475342\n",
      "INFO:root:Train Epoch: 24 [1152/1296 (92%)]\tLoss: 3179.315674\n",
      "INFO:root:Train Epoch: 25 [0/1296 (0%)]\tLoss: 3294.690430\n",
      "INFO:root:Train Epoch: 25 [100/1296 (8%)]\tLoss: 2946.067139\n",
      "INFO:root:Train Epoch: 25 [200/1296 (15%)]\tLoss: 3050.373535\n",
      "INFO:root:Train Epoch: 25 [300/1296 (23%)]\tLoss: 3107.351807\n",
      "INFO:root:Train Epoch: 25 [400/1296 (31%)]\tLoss: 3025.752686\n",
      "INFO:root:Train Epoch: 25 [500/1296 (38%)]\tLoss: 3437.491211\n",
      "INFO:root:Train Epoch: 25 [600/1296 (46%)]\tLoss: 2701.507324\n",
      "INFO:root:Train Epoch: 25 [700/1296 (54%)]\tLoss: 2786.868652\n",
      "INFO:root:Train Epoch: 25 [800/1296 (62%)]\tLoss: 3101.280518\n",
      "INFO:root:Train Epoch: 25 [900/1296 (69%)]\tLoss: 3136.395508\n",
      "INFO:root:Train Epoch: 25 [1000/1296 (77%)]\tLoss: 3117.896484\n",
      "INFO:root:Train Epoch: 25 [1100/1296 (85%)]\tLoss: 3219.194336\n",
      "INFO:root:Train Epoch: 25 [1152/1296 (92%)]\tLoss: 3418.772461\n",
      "INFO:root:Train Epoch: 26 [0/1296 (0%)]\tLoss: 3225.987061\n",
      "INFO:root:Train Epoch: 26 [100/1296 (8%)]\tLoss: 2828.079834\n",
      "INFO:root:Train Epoch: 26 [200/1296 (15%)]\tLoss: 2965.852051\n",
      "INFO:root:Train Epoch: 26 [300/1296 (23%)]\tLoss: 3201.993408\n",
      "INFO:root:Train Epoch: 26 [400/1296 (31%)]\tLoss: 3155.112549\n",
      "INFO:root:Train Epoch: 26 [500/1296 (38%)]\tLoss: 3130.734863\n",
      "INFO:root:Train Epoch: 26 [600/1296 (46%)]\tLoss: 3171.148438\n",
      "INFO:root:Train Epoch: 26 [700/1296 (54%)]\tLoss: 2992.489014\n",
      "INFO:root:Train Epoch: 26 [800/1296 (62%)]\tLoss: 4120.523438\n",
      "INFO:root:Train Epoch: 26 [900/1296 (69%)]\tLoss: 3239.155273\n",
      "INFO:root:Train Epoch: 26 [1000/1296 (77%)]\tLoss: 3258.000244\n",
      "INFO:root:Train Epoch: 26 [1100/1296 (85%)]\tLoss: 3613.211182\n",
      "INFO:root:Train Epoch: 26 [1152/1296 (92%)]\tLoss: 3039.010986\n",
      "INFO:root:Train Epoch: 27 [0/1296 (0%)]\tLoss: 3285.495605\n",
      "INFO:root:Train Epoch: 27 [100/1296 (8%)]\tLoss: 3277.773682\n",
      "INFO:root:Train Epoch: 27 [200/1296 (15%)]\tLoss: 2945.126465\n",
      "INFO:root:Train Epoch: 27 [300/1296 (23%)]\tLoss: 2734.665283\n",
      "INFO:root:Train Epoch: 27 [400/1296 (31%)]\tLoss: 3154.378662\n",
      "INFO:root:Train Epoch: 27 [500/1296 (38%)]\tLoss: 3128.798096\n",
      "INFO:root:Train Epoch: 27 [600/1296 (46%)]\tLoss: 2992.319824\n",
      "INFO:root:Train Epoch: 27 [700/1296 (54%)]\tLoss: 2986.125732\n",
      "INFO:root:Train Epoch: 27 [800/1296 (62%)]\tLoss: 2899.159424\n",
      "INFO:root:Train Epoch: 27 [900/1296 (69%)]\tLoss: 2960.889893\n",
      "INFO:root:Train Epoch: 27 [1000/1296 (77%)]\tLoss: 3330.392090\n",
      "INFO:root:Train Epoch: 27 [1100/1296 (85%)]\tLoss: 3012.800537\n",
      "INFO:root:Train Epoch: 27 [1152/1296 (92%)]\tLoss: 3134.917725\n",
      "INFO:root:Train Epoch: 28 [0/1296 (0%)]\tLoss: 3331.648193\n",
      "INFO:root:Train Epoch: 28 [100/1296 (8%)]\tLoss: 3391.888428\n",
      "INFO:root:Train Epoch: 28 [200/1296 (15%)]\tLoss: 2754.102783\n",
      "INFO:root:Train Epoch: 28 [300/1296 (23%)]\tLoss: 3538.760254\n",
      "INFO:root:Train Epoch: 28 [400/1296 (31%)]\tLoss: 3091.920410\n",
      "INFO:root:Train Epoch: 28 [500/1296 (38%)]\tLoss: 2878.306152\n",
      "INFO:root:Train Epoch: 28 [600/1296 (46%)]\tLoss: 3019.556396\n",
      "INFO:root:Train Epoch: 28 [700/1296 (54%)]\tLoss: 3338.972412\n",
      "INFO:root:Train Epoch: 28 [800/1296 (62%)]\tLoss: 3420.890625\n",
      "INFO:root:Train Epoch: 28 [900/1296 (69%)]\tLoss: 3086.994385\n",
      "INFO:root:Train Epoch: 28 [1000/1296 (77%)]\tLoss: 2829.009521\n",
      "INFO:root:Train Epoch: 28 [1100/1296 (85%)]\tLoss: 2999.946533\n",
      "INFO:root:Train Epoch: 28 [1152/1296 (92%)]\tLoss: 2903.221924\n",
      "INFO:root:Train Epoch: 29 [0/1296 (0%)]\tLoss: 3358.099365\n",
      "INFO:root:Train Epoch: 29 [100/1296 (8%)]\tLoss: 3214.576172\n",
      "INFO:root:Train Epoch: 29 [200/1296 (15%)]\tLoss: 2900.825684\n",
      "INFO:root:Train Epoch: 29 [300/1296 (23%)]\tLoss: 3151.392334\n",
      "INFO:root:Train Epoch: 29 [400/1296 (31%)]\tLoss: 3080.029785\n",
      "INFO:root:Train Epoch: 29 [500/1296 (38%)]\tLoss: 2872.996338\n",
      "INFO:root:Train Epoch: 29 [600/1296 (46%)]\tLoss: 3350.695312\n",
      "INFO:root:Train Epoch: 29 [700/1296 (54%)]\tLoss: 2951.375244\n",
      "INFO:root:Train Epoch: 29 [800/1296 (62%)]\tLoss: 2906.363037\n",
      "INFO:root:Train Epoch: 29 [900/1296 (69%)]\tLoss: 2776.393066\n",
      "INFO:root:Train Epoch: 29 [1000/1296 (77%)]\tLoss: 3620.552002\n",
      "INFO:root:Train Epoch: 29 [1100/1296 (85%)]\tLoss: 3029.114014\n",
      "INFO:root:Train Epoch: 29 [1152/1296 (92%)]\tLoss: 2992.422363\n",
      "INFO:root:Train Epoch: 30 [0/1296 (0%)]\tLoss: 3348.923828\n",
      "INFO:root:Train Epoch: 30 [100/1296 (8%)]\tLoss: 3007.041260\n",
      "INFO:root:Train Epoch: 30 [200/1296 (15%)]\tLoss: 3030.395752\n",
      "INFO:root:Train Epoch: 30 [300/1296 (23%)]\tLoss: 2952.936768\n",
      "INFO:root:Train Epoch: 30 [400/1296 (31%)]\tLoss: 3246.515381\n",
      "INFO:root:Train Epoch: 30 [500/1296 (38%)]\tLoss: 3115.658447\n",
      "INFO:root:Train Epoch: 30 [600/1296 (46%)]\tLoss: 3220.199219\n",
      "INFO:root:Train Epoch: 30 [700/1296 (54%)]\tLoss: 3375.242676\n",
      "INFO:root:Train Epoch: 30 [800/1296 (62%)]\tLoss: 2767.361816\n",
      "INFO:root:Train Epoch: 30 [900/1296 (69%)]\tLoss: 2930.372803\n",
      "INFO:root:Train Epoch: 30 [1000/1296 (77%)]\tLoss: 2953.042480\n",
      "INFO:root:Train Epoch: 30 [1100/1296 (85%)]\tLoss: 3005.250244\n",
      "INFO:root:Train Epoch: 30 [1152/1296 (92%)]\tLoss: 3046.650879\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args['epoch'] + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    #test(args, model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1476, -0.0560, -0.0207,  ..., -0.0674,  0.0529, -0.1030],\n",
      "        [ 0.0413, -0.0575,  0.1053,  ...,  0.0275, -0.1328,  0.1284],\n",
      "        [ 0.0140,  0.0808, -0.1295,  ...,  0.1422, -0.1231, -0.0791],\n",
      "        ...,\n",
      "        [ 0.0741,  0.1353,  0.0581,  ...,  0.0571,  0.0771,  0.1452],\n",
      "        [ 0.1198, -0.0315, -0.0971,  ..., -0.1323, -0.0671,  0.0049],\n",
      "        [-0.1429, -0.0325, -0.0471,  ..., -0.1018, -0.0338, -0.0587]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-5.3841e-03, -5.0519e-02, -1.0950e+03, -9.3156e-02, -1.2654e-01,\n",
      "        -1.0156e+03, -5.8675e+02, -3.7298e-02, -6.9028e-02, -2.5147e-02,\n",
      "        -6.4043e+02, -3.5268e-03, -4.3736e+02, -1.3637e-01, -1.8476e+02,\n",
      "        -5.4530e-02, -4.7857e+01, -3.8251e-02, -8.8616e+01, -4.9167e+02,\n",
      "        -1.0506e-01, -9.7962e+02, -9.2888e-02, -9.2696e+02, -1.3983e-01,\n",
      "        -1.2593e-01, -5.4261e-02, -1.2491e-01, -2.3559e-03, -1.0906e-01,\n",
      "        -2.8878e+02, -8.8779e+02, -7.7823e-02, -3.0977e-02, -1.3583e-02,\n",
      "        -8.7729e-02, -8.1617e+02, -6.0232e+02, -6.2948e-02, -5.4280e+02,\n",
      "        -7.9196e-02, -4.8755e-02, -1.2629e-01, -1.4509e-01, -9.2856e+01,\n",
      "        -8.7555e+02, -9.7567e+02, -7.6999e+02, -9.7873e-02, -4.9655e+02,\n",
      "        -8.8951e+02, -2.1124e-02, -2.9303e-02, -2.9912e+02, -1.2099e-01,\n",
      "        -3.9716e+02, -3.9499e-02, -6.6893e-02, -1.3346e-02, -8.1187e+02,\n",
      "        -5.0389e+02, -3.6356e-02, -9.6010e+02, -8.8956e+02, -8.8288e-02,\n",
      "        -1.6387e+02, -9.1501e+02, -1.2887e-01, -7.3775e+02, -7.5202e-03,\n",
      "        -1.4477e-01, -1.3734e-01, -8.4554e+02, -1.3506e+02, -1.0316e-01,\n",
      "        -7.8693e+02, -1.4139e-01, -1.3377e+02, -9.6166e-02, -9.9623e+01,\n",
      "        -9.1564e+02, -6.8588e+02, -1.2156e+02, -4.5902e+02, -2.5319e-02,\n",
      "        -8.5983e+01, -1.1431e+02, -1.0858e-01, -1.2490e-01, -5.1251e+02,\n",
      "        -7.8821e-02, -5.1964e+02, -1.0307e+02, -7.6861e-03, -4.9349e+02,\n",
      "        -3.3926e+02, -8.5393e-02, -9.5857e+02, -3.5609e+02, -2.7721e+02,\n",
      "        -1.1889e-01, -1.0768e+02, -7.3919e-02, -9.6682e+02, -3.2534e+02,\n",
      "        -5.6029e-02, -6.6196e-02, -5.9186e+02, -3.5858e+02, -5.2194e-02,\n",
      "        -3.2523e-02, -5.8288e+02, -5.4132e-02, -8.7356e-02, -1.2279e+02,\n",
      "        -3.2445e-02, -1.1844e-01, -9.2339e+02, -5.6161e+02, -5.4257e+02,\n",
      "        -6.0020e-02, -2.3013e+02, -8.7441e+02, -1.0427e-01, -1.4422e-01,\n",
      "        -2.3309e+02, -3.2305e-03, -2.8027e+02, -6.1679e+02, -8.7576e+01,\n",
      "        -1.3433e-01, -3.1490e-03, -4.5850e-02, -2.8431e+02, -5.9714e+02,\n",
      "        -9.1772e-02, -1.9772e-02, -5.5620e+02, -1.0639e-01, -3.3400e+02,\n",
      "        -7.7364e+02, -7.0214e+02, -1.1695e-01, -5.3233e-03, -9.6401e-02,\n",
      "        -4.4906e-02, -1.4258e-02, -1.9013e+02, -8.9639e+02, -2.1300e+02,\n",
      "        -1.3683e-03, -7.5218e+01, -1.2545e-01, -6.5645e-02, -7.4753e-02,\n",
      "        -5.8639e-02, -1.0507e+03, -4.5276e-02, -1.2256e-01, -4.4262e+02,\n",
      "        -1.4657e-01, -8.6713e-02, -1.3297e-01, -2.5799e-02, -1.1495e-01,\n",
      "        -8.6911e+02, -1.0577e-01, -1.4657e+02, -1.2201e-01, -8.4022e-02,\n",
      "        -3.7879e+02, -6.1648e+02, -1.4028e+02, -1.0801e-02, -3.1825e-03,\n",
      "        -5.4576e-02, -2.5745e+02, -3.1617e+02, -1.4581e+02, -3.3763e+02,\n",
      "        -9.7601e+02, -7.6856e-02, -1.2796e-01, -1.3591e+02, -1.6020e+02,\n",
      "        -3.2909e-02, -5.8307e+02, -5.7376e+02, -7.2547e+02, -9.2933e+02,\n",
      "        -9.4446e+01, -1.2960e-01, -7.2381e-02, -1.2011e-01, -1.7446e+02,\n",
      "        -5.2490e+02, -3.7539e-02, -3.8559e+02, -5.7330e+02, -4.0862e+02,\n",
      "        -2.4565e+02, -3.9086e+02, -4.2307e+02, -7.2150e-02, -7.0456e+02,\n",
      "        -8.8571e-03, -4.7023e+02, -1.4033e-01, -3.0103e+02, -1.5163e-02,\n",
      "        -1.4539e-01, -7.9044e+02, -5.1930e-03, -2.2001e-02, -1.4109e+02,\n",
      "        -3.6306e-02, -2.3490e+02, -2.2433e+02, -3.2576e-02, -8.7963e+02,\n",
      "        -4.4491e+02, -3.1779e-02, -6.6796e+02, -5.3576e+02, -1.3834e-01,\n",
      "        -5.6311e-02, -1.1021e-01, -5.2796e-02, -6.5799e+02, -6.5448e-02,\n",
      "        -1.3761e-01, -1.2749e-01, -4.0691e+02, -6.1691e-02, -7.3176e+02,\n",
      "        -5.0931e+02, -1.1317e-01, -9.3334e-02, -2.8578e+02, -1.2797e-01,\n",
      "        -3.3019e+02, -5.0541e+02, -5.7900e-02, -2.6518e-02, -3.6920e-02,\n",
      "        -8.6273e-02, -6.6326e+01, -9.1009e-02, -8.0069e-02, -3.3375e-02,\n",
      "        -3.7725e+02, -1.4160e+02, -1.1783e-01, -5.4871e-02, -1.5251e-01,\n",
      "        -1.6451e-03, -8.2727e-02, -2.4716e-03, -6.0959e+02, -9.5255e-02,\n",
      "        -6.8493e+02, -1.2219e-01, -3.8534e+02, -1.7078e-01, -1.9254e-02,\n",
      "        -2.8167e+01, -1.0661e+03, -8.4347e+02, -3.0899e+02, -8.2406e-02,\n",
      "        -7.9606e+02, -1.0468e-01, -1.4093e-01, -9.5824e-03, -7.4917e-02,\n",
      "        -1.1713e+03, -5.0472e+02, -1.2396e+02, -5.9999e-02, -3.4946e+02,\n",
      "        -4.8898e+02, -4.5884e-02, -5.3347e+02, -1.1292e-01, -1.2902e-01,\n",
      "        -2.4791e+02, -4.9857e+02, -1.3277e-01, -1.1740e+02, -5.5460e+02,\n",
      "        -5.6739e+02, -8.0629e+02, -1.3029e-02, -1.0469e-01, -1.9869e+02,\n",
      "        -1.0765e+03, -4.5465e+02, -3.8010e+02, -6.8140e-02, -1.4039e-01,\n",
      "        -2.6870e-02, -6.2805e-03, -1.2469e-01, -6.1581e-02, -1.0433e-01,\n",
      "        -1.0294e-01, -1.7586e+02, -1.3494e-01, -7.7357e-02, -1.5639e-01,\n",
      "        -6.5654e-02, -1.0996e+03, -7.7994e+02, -1.2427e-01, -1.7399e+02,\n",
      "        -4.3895e-02, -7.4171e+02, -1.3846e-01, -6.1596e+02, -8.0700e-02,\n",
      "        -8.3907e-02, -3.1260e-02, -1.1090e+03, -4.7376e+02, -3.9351e-02,\n",
      "        -3.6124e-02, -2.8218e+02, -9.8821e+02, -4.1466e+02, -1.9782e+02,\n",
      "        -8.4723e-02, -1.6282e+02, -5.1023e-02, -8.5955e-03, -7.1917e+02,\n",
      "        -4.8403e+02, -7.9477e+02, -9.6104e-02, -5.2012e-02, -1.4035e-01,\n",
      "        -1.2211e-01, -7.7208e+02, -1.9379e+02, -3.9297e+02, -5.8114e+02,\n",
      "        -1.2450e-01, -8.3625e+01, -5.9787e+02, -2.3201e+02, -7.4047e+02,\n",
      "        -2.5364e-02, -3.6775e+02, -8.0714e-02, -1.0613e-01, -8.6105e+02,\n",
      "        -1.9521e+01, -1.1975e-01, -4.5097e+02, -4.7786e-02, -3.2647e+02,\n",
      "        -2.9523e+02, -5.0087e+02, -3.4759e+02, -1.1756e-01, -2.6911e-02,\n",
      "        -3.7067e+02, -8.3975e-02, -2.0568e+02, -8.0930e-02, -3.1500e-02,\n",
      "        -6.3329e+02, -1.3060e-01, -4.0495e+02, -1.5870e+02, -1.3214e-02,\n",
      "        -1.3579e-01, -2.5397e-02, -9.2415e-02, -7.7678e+02, -6.4681e+02,\n",
      "        -3.3898e-02, -5.3982e+02, -1.2011e+03, -2.1839e+02, -1.2622e-01,\n",
      "        -7.0818e+02, -1.1185e-01, -1.4697e-01, -5.0879e+02, -1.0491e-01,\n",
      "        -1.8421e+02, -4.1490e-02, -9.1553e+02, -9.4969e-02, -9.3178e+02,\n",
      "        -6.3319e+02, -1.2206e-01, -1.1470e-01, -1.2747e-01, -3.7466e-02,\n",
      "        -1.0248e-01, -2.8206e+02, -1.3370e-02, -1.4025e-01, -1.2328e-01,\n",
      "        -4.2666e+02, -8.5665e-02, -1.2465e-01, -1.4094e-01, -9.3966e+02,\n",
      "        -8.7248e+02, -1.0842e+03, -4.9348e+02, -4.8191e-02, -8.2673e-02,\n",
      "        -6.3372e-02, -7.0886e+02, -1.0001e-01, -2.0605e+02, -5.6564e+02,\n",
      "        -2.3743e+02, -6.7363e-02, -1.3486e-01, -7.4409e+02, -2.9518e-02,\n",
      "        -1.3733e-01, -9.6388e-02, -9.2837e+02, -3.7947e-02, -5.5180e-02,\n",
      "        -5.3689e+02, -1.6012e+02, -4.2973e-02, -3.8178e-02, -1.1416e-01,\n",
      "        -9.7631e+02, -9.9469e-02, -1.2396e+02, -2.9197e-02, -8.0036e+02,\n",
      "        -6.8743e+02, -6.7913e+02, -6.1254e+02, -5.9865e+02, -4.1687e+02,\n",
      "        -1.4660e+02, -7.2161e-03, -3.8201e+02, -4.7756e+02, -7.9874e-02,\n",
      "        -5.5015e+02, -4.4150e+02, -6.0568e+02, -4.3528e-02, -1.4010e-01,\n",
      "        -1.3377e-01, -6.0301e-02, -3.0397e-02, -1.2831e-01, -6.4901e-02,\n",
      "        -3.4431e+02, -1.0680e-01, -6.4460e+02, -1.0956e+02, -5.4477e+02,\n",
      "        -2.1769e+02, -5.4680e-02, -6.5436e+02, -1.3899e-01, -9.2993e+02,\n",
      "        -4.7228e-02, -5.5358e-02, -4.2938e+02, -9.0588e-02, -1.7642e+01,\n",
      "        -5.4134e-02, -4.8233e+02, -4.2327e+02, -1.3451e-01, -3.0485e+02,\n",
      "        -1.2977e-01, -7.0730e+02, -9.3362e+01, -9.3711e+01, -6.6872e-02,\n",
      "        -1.0140e-01, -3.2561e+02, -3.4310e+02, -6.7093e-02, -1.3533e-01,\n",
      "        -3.0316e-02, -1.1304e-01, -6.3135e-02, -2.4785e+02, -9.8148e-03,\n",
      "        -6.0796e-02, -7.5869e-02, -1.1359e+02, -6.4346e-02, -2.0362e+02,\n",
      "        -7.6677e+02, -7.8222e-02, -3.1088e-02, -2.7552e-02, -1.0293e-01,\n",
      "        -8.0224e+02, -9.0567e+01, -1.2083e-01, -7.0959e+02, -3.3084e+02,\n",
      "        -2.0999e-02, -6.8546e+02, -4.6603e-02, -7.4879e+02, -1.0446e+03,\n",
      "        -6.3425e+02, -1.5357e-02, -1.3844e-01, -9.4725e-02, -1.8450e+01,\n",
      "        -4.9163e-02, -7.6112e+02, -4.1016e-02, -1.1866e-01, -3.3696e+02,\n",
      "        -8.1872e-02, -5.8007e+02, -1.7230e+02, -1.3740e-01, -1.3247e-02,\n",
      "        -4.4001e+02, -3.9218e-02, -5.9206e+02, -5.9906e+02, -8.4791e-02,\n",
      "        -1.6970e+02, -8.5796e+01, -7.1265e+02, -5.0104e-02, -3.8341e-02,\n",
      "        -2.0051e+01, -5.7639e-02, -1.4539e-01, -1.5136e-02, -4.7001e-02,\n",
      "        -3.9620e+02, -1.4986e-02, -5.9130e-02, -5.7956e-02, -1.2521e+01,\n",
      "        -5.7396e+02, -4.4641e+02, -4.4737e-02, -4.5421e-02, -4.8309e+01,\n",
      "        -7.3259e-02, -3.0447e-02, -1.0378e+03, -5.3119e+02, -6.0023e+02,\n",
      "        -9.9791e-02, -5.0206e+02, -7.0922e+02, -9.4699e-02, -7.9557e-02,\n",
      "        -5.1310e-02, -4.2920e+02, -8.9115e+02, -1.7559e-02, -9.0237e+02,\n",
      "        -3.2001e+02, -8.1004e-02, -8.3350e+02, -3.0272e-02, -5.3391e+02,\n",
      "        -7.7302e+02, -3.2719e+02, -1.1056e+03, -1.8163e-02, -4.3632e+02,\n",
      "        -8.1776e-02, -1.4500e-01, -8.8424e-02, -1.1967e-01, -4.1535e+02,\n",
      "        -7.0514e+02, -9.5946e-02, -4.9571e+02, -9.7454e+02, -1.1689e-01,\n",
      "        -1.7484e+02, -6.8557e-02, -7.2848e-02, -6.2633e+01, -1.4847e-01,\n",
      "        -4.9002e+02, -7.7232e+02, -6.6006e-02, -5.8472e+02, -1.0405e-01,\n",
      "        -1.6643e+02, -1.3031e-01, -7.8707e+02, -8.1421e-02, -2.6712e+02,\n",
      "        -5.2394e-02, -1.0268e-01, -9.3627e+02, -1.3302e-01, -5.1351e-02,\n",
      "        -1.0089e+03, -7.2652e-02, -1.7708e+02, -1.7040e-02, -1.4191e-01,\n",
      "        -1.3482e-01, -1.0699e-01, -1.4727e-01, -4.7649e+02, -2.5139e+02,\n",
      "        -7.1572e+02, -1.0350e+03, -1.9252e+01, -1.3047e-01, -1.2321e-01,\n",
      "        -1.0143e+03, -1.0216e+03, -1.5194e+02, -1.1754e+02, -1.2568e-01,\n",
      "        -1.0136e+03, -8.2974e+02, -8.8950e+02, -3.8180e+02, -3.5847e-02,\n",
      "        -8.4297e+02, -7.4020e+02, -5.8287e-02, -1.1251e+03, -6.4150e-02,\n",
      "        -1.3506e-01, -5.4998e-02, -1.4512e-01, -9.4411e+02, -1.4696e-01,\n",
      "        -1.2156e-01, -2.6838e+02, -3.6723e-02, -7.9709e-02, -5.1179e+02,\n",
      "        -5.4088e-02, -8.2402e+02, -1.0830e-01, -4.8566e+01, -1.3133e-01,\n",
      "        -4.1974e-02, -6.9722e-02, -7.0963e-02, -8.2180e-02, -3.3231e-02,\n",
      "        -3.5465e+02, -5.5669e-02, -1.2626e-01, -6.2449e-02, -5.3990e-03,\n",
      "        -1.4196e-03, -1.1883e-01, -1.1730e-01, -2.6701e+02, -7.7443e+02,\n",
      "        -1.0194e+03, -6.0047e-02, -9.1432e+02, -1.2830e-01, -1.8512e+02,\n",
      "        -9.6806e-02, -3.8470e-04, -1.4114e-01, -5.5277e+02, -7.7704e-02,\n",
      "        -1.3245e-01, -8.7127e+02, -5.6445e-02, -3.0286e+02, -5.9887e+02,\n",
      "        -2.1128e+02, -3.3881e+02, -7.9717e+02, -2.8000e+02, -5.5321e+02,\n",
      "        -1.2047e-01, -1.3232e-01, -4.4879e-02, -1.6602e-02, -4.9711e-02,\n",
      "        -5.3349e+02, -3.3815e-02, -6.5315e-02, -1.1784e-01, -7.7628e+02,\n",
      "        -5.8421e-02, -8.1859e+02, -1.2551e-01, -1.8611e-02, -8.5791e+01,\n",
      "        -3.1133e+02, -3.2894e-02, -2.6491e+02, -2.5952e+02, -2.6021e-02,\n",
      "        -1.1167e-01, -4.3751e-02, -5.2976e-02, -1.0546e+03, -9.5106e-02,\n",
      "        -3.6441e+02, -9.2377e-02, -2.7575e-02, -3.9839e+02, -2.9944e+02,\n",
      "        -7.4287e+02, -5.6998e-02, -8.3467e-02, -2.6730e+02, -3.0623e+02,\n",
      "        -5.0636e-02, -5.8474e+02, -7.2696e+01, -5.9405e+01, -1.1776e-01,\n",
      "        -4.9005e-02, -7.6367e+02, -8.0984e-02, -1.3993e-01, -2.3090e-02,\n",
      "        -1.4316e-01, -9.3635e-02, -7.2678e-02, -1.0991e-01, -8.0864e+02,\n",
      "        -9.4183e-02, -1.6527e+02, -6.4174e-02, -1.0905e-02, -5.7436e-02,\n",
      "        -5.0642e-02, -1.0349e+03, -5.4400e+02, -1.3515e-01, -8.5929e-02,\n",
      "        -7.0891e+02, -8.6094e+02, -2.9537e+02, -5.6772e+02, -1.8075e+02,\n",
      "        -5.9723e+02, -7.3341e+02, -1.2043e-01, -7.5334e+01, -4.1586e-02,\n",
      "        -3.8456e+02, -1.2940e-01, -2.8968e+02, -3.8769e+02, -1.3054e-01,\n",
      "        -7.6062e-02, -6.2069e-02, -1.1553e-01, -3.8876e-02, -8.8776e+02,\n",
      "        -8.7484e+02, -1.0440e-01, -4.5978e+01, -3.3915e-02, -7.1606e+02,\n",
      "        -1.3115e-01, -5.8590e-03, -3.6795e+02, -2.2216e+02, -9.9324e-02,\n",
      "        -6.0998e+02, -3.5670e-02, -1.4307e+02, -4.5912e+02, -1.6788e+02,\n",
      "        -1.6997e-02, -1.1417e-01, -7.7077e-02, -9.8053e-02, -9.6600e-02,\n",
      "        -1.2025e-01, -4.7477e+02, -1.3229e-01, -6.4779e+02, -4.3365e-02,\n",
      "        -9.4765e+02, -6.0401e+02, -1.4479e-02, -1.4316e-01, -1.4196e-01,\n",
      "        -8.3753e+02, -8.5961e+02, -8.0131e+02, -2.9244e+02, -2.3733e-02,\n",
      "        -1.3908e-01, -9.7584e-02, -9.5066e-02, -6.4942e-03, -1.2595e+02,\n",
      "        -6.0587e+02, -9.6298e+01, -6.5855e-02, -1.2353e-01, -7.2023e+02,\n",
      "        -6.7728e+02, -4.8918e+02, -1.0298e-01, -7.2166e+02, -1.3950e-01,\n",
      "        -6.6145e+02, -1.4890e-01, -5.8234e-02, -9.8778e-02, -1.1576e-01,\n",
      "        -3.0829e+02, -7.2547e+01, -9.7638e-02, -1.2953e-01, -7.6868e-02,\n",
      "        -1.4119e-01, -4.8533e-03, -1.2742e-01, -5.8475e-02, -8.6165e+02,\n",
      "        -8.4914e-02, -3.0357e-02, -7.8522e+02, -6.7785e+02, -6.9614e+02,\n",
      "        -2.8691e-02, -4.5944e+02, -1.2930e-01, -3.9731e+02, -1.0562e+03,\n",
      "        -4.2517e-02, -8.0273e+02, -2.0075e+02, -2.8972e+02, -7.6965e+02,\n",
      "        -1.6731e+02, -1.0513e+02, -1.0494e+01, -1.2324e+02, -1.6464e+02,\n",
      "        -6.9339e+02, -3.3415e-02, -5.4006e-02, -9.7860e+02, -5.2496e-02,\n",
      "        -9.4976e-02, -7.7176e-02, -4.5138e-02, -4.3396e-02, -3.9464e+02,\n",
      "        -1.9114e-01, -8.1811e+02, -1.0625e-01, -6.2448e-02, -2.8944e-02,\n",
      "        -1.1248e-01, -8.3659e-02, -7.9939e+02, -5.4578e-02, -9.5871e-02,\n",
      "        -3.9523e+02, -7.0999e-02, -7.7131e+01, -1.4302e-01, -1.4195e-01,\n",
      "        -1.0793e+02, -2.7342e+01, -1.3022e-01, -1.1491e-01, -7.1821e-02,\n",
      "        -1.7941e-01, -1.3767e-01, -2.9814e+02, -1.1886e+03, -1.2486e+03,\n",
      "        -4.6918e-02, -1.5968e-02, -5.4520e-02, -7.7227e-02, -5.6282e+02,\n",
      "        -3.2521e-02, -6.9852e+02, -1.1715e+03, -7.3930e-02, -1.2154e-01,\n",
      "        -4.4467e-02, -1.3067e-01, -2.3969e-02, -5.9403e+02, -1.2079e-01,\n",
      "        -2.3889e+02, -2.3605e+02, -1.6283e-02, -3.6923e+02, -2.2995e-02,\n",
      "        -3.6806e-02, -3.2617e+02, -1.2999e-01, -2.1325e+02, -1.1065e+03,\n",
      "        -3.2439e-01, -9.0844e+02, -5.4395e+02, -7.1967e-02, -5.8404e-02,\n",
      "        -7.1650e+02, -1.3402e-01, -4.1693e+02, -4.0899e+02, -1.4612e-01,\n",
      "        -1.1202e-01, -1.0762e-01, -2.6481e-02, -4.2589e+02, -4.9125e+02,\n",
      "        -2.2763e-02, -2.4014e+02, -7.6708e+02, -1.2107e-01, -1.4591e-01,\n",
      "        -9.0964e-02, -1.2645e-01, -9.0689e+02, -1.3290e-02, -2.9163e-02,\n",
      "        -9.1316e+02, -8.7479e-02, -7.4125e+02, -1.3641e-01, -5.4506e+02,\n",
      "        -2.4738e-02, -1.2245e-01, -6.0472e-03, -1.1168e-01, -8.6414e+02,\n",
      "        -6.0472e-02, -2.7763e-02, -9.5429e+02, -8.1247e-02, -6.0941e+01,\n",
      "        -6.7824e+02, -9.2129e+02, -1.0806e-01, -5.8843e-02, -3.9100e+02,\n",
      "        -2.1634e+01, -7.0542e+02, -1.0150e+03, -2.4480e-02, -1.3013e-01,\n",
      "        -5.1819e+02, -5.5158e+02, -3.4263e-02, -3.8250e-02, -8.9121e-02,\n",
      "        -4.1244e-02, -2.3419e-02, -2.9727e-02, -1.1182e-01, -8.6966e-02,\n",
      "        -1.2945e+02, -5.7766e+02, -9.6836e+01, -6.8110e-02, -7.7062e-02,\n",
      "        -9.1991e-02, -8.2766e+02, -6.4112e-02, -2.1909e-02, -6.8467e+02,\n",
      "        -3.5459e-02, -3.7824e+02, -1.3734e-01, -5.7223e+02, -1.3676e+02,\n",
      "        -7.7652e+02, -9.5966e+02, -1.1024e+03, -5.3400e+02, -7.3915e+02,\n",
      "        -1.0295e-01, -5.1779e+02, -1.8176e+02, -5.0939e+02, -1.9523e-02],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.1041e-02, -2.5803e-02, -3.6674e-02,  ..., -2.9410e-02,\n",
      "          9.5873e-03, -1.9765e-02],\n",
      "        [-2.8289e-02,  1.5577e-02, -1.8725e+01,  ..., -3.1967e+00,\n",
      "         -8.7878e+00,  3.0782e-02],\n",
      "        [-1.1902e-02,  8.6260e-03, -2.1488e-02,  ..., -7.2010e-03,\n",
      "         -2.1517e-02,  1.9937e-02],\n",
      "        ...,\n",
      "        [-1.8100e-02, -1.8129e-02, -6.9194e+00,  ..., -1.1929e+00,\n",
      "         -3.2117e+00, -2.9276e-02],\n",
      "        [ 1.2374e-02,  3.1128e-02,  1.7808e-02,  ...,  2.9079e-02,\n",
      "         -1.2838e-02,  2.7423e-02],\n",
      "        [-2.4229e-03,  2.2746e-03, -4.0393e+01,  ..., -6.8617e+00,\n",
      "         -1.8901e+01, -3.0041e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-3.9883e-02, -8.6493e+00, -1.4543e-02,  3.2636e+00, -6.5751e+00,\n",
      "        -6.6826e+00, -1.5089e+01, -5.0566e+00, -5.0510e+01, -2.8412e+01,\n",
      "         2.2710e+00, -1.9002e-01, -5.5752e-02, -1.8393e-03, -1.3386e-02,\n",
      "        -5.2002e-01, -5.8005e+00, -2.2622e-02, -7.9521e-03,  5.2738e+00,\n",
      "        -6.4308e-02, -1.4796e-02, -8.9873e-02, -7.8436e-01,  1.5971e+00,\n",
      "        -1.5989e+01, -2.7809e+01, -5.6320e-02, -2.0825e-02, -2.1958e-02,\n",
      "        -5.2224e-02,  7.1629e-01, -1.9330e+01, -2.6193e-02,  4.7206e+00,\n",
      "        -2.1533e-02, -1.9647e-02, -2.4940e-03, -1.4215e-01, -6.6230e-02,\n",
      "         4.7299e+00,  5.8570e+00, -1.9864e+01, -2.6742e-01, -3.3229e-02,\n",
      "        -1.7587e+01, -3.8250e-01, -9.7702e+00, -8.4448e-02, -9.6276e-02,\n",
      "        -5.7169e-01, -2.6561e-02, -5.7565e-02, -1.0807e+01, -2.0960e-02,\n",
      "        -1.5060e-01, -6.0338e-03, -2.8098e-02, -3.1097e+01, -1.3728e-02,\n",
      "        -3.3825e+01, -1.1047e+01,  5.0344e+00, -3.0002e-02,  5.6372e-01,\n",
      "        -2.0697e+01, -2.2751e-01, -1.1524e-01, -3.2250e+01, -2.3964e-02,\n",
      "         2.2227e+00,  3.3274e+00, -1.3040e-01, -2.0828e+01, -1.5902e-02,\n",
      "        -9.5183e-02,  5.1354e+00, -8.1483e-02, -2.3190e+01, -4.8471e-01,\n",
      "         1.0291e+00, -4.6626e-02, -1.5438e+01, -6.4914e+00, -2.8575e-02,\n",
      "        -3.7373e-01, -1.1129e-01, -2.2837e-02, -7.5573e-02, -9.7638e+00,\n",
      "        -1.2158e-02, -5.6648e-02, -8.5123e-02,  2.1972e+00, -1.5068e+01,\n",
      "        -1.9630e-01, -3.9585e-02, -2.6941e+01, -7.4685e+00, -1.3042e-02,\n",
      "        -1.6108e+01, -5.1007e+01, -3.1187e+01, -3.5859e-02, -1.6004e-02,\n",
      "        -2.3952e+01, -2.0813e-03, -2.5647e-03, -7.4676e-02, -3.1335e+01,\n",
      "        -7.2796e-02, -2.9898e+01, -7.1398e-02, -2.4348e-02, -1.3936e-02,\n",
      "        -2.6934e-02,  3.0437e+00, -6.9150e-03, -5.9113e+00, -6.2706e+00,\n",
      "        -1.4942e-02, -1.4244e+01, -9.2269e-02,  4.8275e+00, -2.5988e+01,\n",
      "        -1.6643e+01, -5.8293e+01, -5.4774e-02, -2.3210e+01, -7.7556e+00,\n",
      "        -1.0242e-02, -5.1870e-03, -1.6557e+01, -1.9619e-02,  2.7795e+00,\n",
      "        -9.1475e+00, -5.3034e+01,  2.8570e+00, -4.0271e-01, -7.1199e-02,\n",
      "         2.7379e+00, -1.3873e-02, -7.2233e-03, -2.8899e-02,  2.9112e+00,\n",
      "        -1.3213e+01, -1.6555e-03, -5.2937e-02, -3.6612e+01, -3.7442e+01,\n",
      "        -9.9503e-02, -1.4785e+01, -1.4968e-02, -2.5923e+01, -6.6800e-01,\n",
      "        -3.1710e+01,  1.8150e+00, -3.2975e+01, -8.1050e-02, -1.0160e-01,\n",
      "        -2.6369e+01, -2.0481e-02, -1.8340e-02, -6.4465e+00, -1.9779e+01,\n",
      "        -5.0516e-01, -1.1271e-01,  3.9578e+00, -3.2821e+01, -2.0594e+01,\n",
      "        -3.3880e+01, -1.4662e-01, -4.6192e-03, -1.0846e+01, -4.6222e-03,\n",
      "         3.2132e+00, -4.9613e+00, -4.0433e+01, -3.1073e+01, -2.9623e-02,\n",
      "        -7.4685e+01,  3.2856e+00, -1.7090e+01, -1.0690e+01, -1.3217e-01,\n",
      "         7.1652e+00, -2.7666e-02,  2.9265e+00, -2.5075e+01, -8.0047e-03,\n",
      "        -8.0414e-02, -2.7389e+01, -1.0441e-01, -6.1745e+01, -8.1472e-02,\n",
      "        -1.3267e+01, -2.9612e-02, -1.0561e-01, -8.2565e-02, -3.4450e+01,\n",
      "        -6.6075e+01, -1.7323e+01, -3.2182e-02, -1.8221e+01, -1.4799e-01,\n",
      "         8.3253e-01, -3.9946e+01, -4.4476e+01,  1.9966e+00, -2.8428e+01,\n",
      "        -7.3015e-02, -8.9016e+00,  1.3882e+01, -1.3707e+01, -6.0566e-02,\n",
      "        -4.7071e-03, -1.7278e+01, -1.2521e-02, -8.1653e-01,  1.6365e+00,\n",
      "        -6.8021e-04, -1.5336e-03, -5.5336e-03, -2.9289e-02, -3.5470e-04,\n",
      "        -2.5859e-02, -3.0517e-02, -1.7008e+01, -1.3349e+01, -7.4842e-03,\n",
      "        -2.6553e-02,  1.7974e+00, -2.2014e+01, -1.2220e-01, -3.6885e+01,\n",
      "        -3.4920e-02, -6.5771e-02, -1.0790e-01, -1.8248e-01, -4.3823e-02,\n",
      "        -3.3109e-03, -1.2605e+01, -7.2312e+00, -3.5109e+01, -1.1902e+01,\n",
      "        -1.0724e+01, -3.1363e+01, -1.4538e-01, -1.6846e+01, -4.1942e+00,\n",
      "        -1.9773e+01, -2.0156e-02, -1.2931e+01, -4.9345e-02, -1.3182e-02,\n",
      "        -2.2539e+01, -3.8690e+01, -2.9514e+01,  1.7408e+00, -2.6699e-02,\n",
      "        -5.7670e+01,  3.1871e+00, -4.7199e-02, -1.1434e+00,  3.6780e+00,\n",
      "        -1.2463e-02,  8.2690e-01,  2.1958e+00, -1.2312e+01, -5.9828e-02,\n",
      "        -5.2710e-04, -5.6429e-03,  1.1623e+00,  1.3236e+01, -5.1926e+01,\n",
      "        -2.0231e+01, -2.2907e+01, -1.5596e+01, -3.0703e+01, -9.3671e-01,\n",
      "        -2.7908e-02, -1.7561e+01, -1.8278e-02, -6.5038e+00, -3.1667e+01,\n",
      "        -2.6211e-02, -2.2384e+01, -2.8212e+01, -2.8270e+01, -1.5142e-02,\n",
      "        -2.0339e+01, -1.0519e-02, -2.8500e-02, -4.6150e-02, -2.9156e+01,\n",
      "        -7.8642e-02, -2.2983e-02, -6.4165e-03, -7.9438e-03, -3.0308e+01,\n",
      "        -2.8022e+00, -1.6581e-03,  5.0379e+00, -1.2003e-01, -3.2739e+01,\n",
      "        -2.4097e+01, -4.6232e+00, -9.5871e-02, -1.2965e-01, -1.7000e+01,\n",
      "        -8.3880e-02,  3.1479e+00, -2.0922e-03, -9.1395e-02, -4.2198e+01,\n",
      "        -2.2865e+01, -2.8418e-02, -2.0931e+01, -3.0431e-02, -3.0005e+01,\n",
      "        -1.7069e+01, -3.1824e+01, -6.1307e-02, -6.3143e+01, -3.7913e-02,\n",
      "        -4.5774e-02, -3.0421e-02, -3.0013e+01, -1.9327e+01, -3.7860e-01,\n",
      "        -9.1804e+00,  6.7626e+00, -1.4845e-02,  2.9641e+00, -1.5349e-02,\n",
      "        -1.4686e+01, -5.8675e-02, -1.9569e+01, -3.2273e-02, -3.6652e-03,\n",
      "        -8.6828e+00, -8.1704e-02, -4.6904e-02, -2.2260e-02,  4.9653e+00,\n",
      "        -1.3022e-02, -6.3352e-02, -2.1225e+01, -2.6248e-02, -4.2489e-02,\n",
      "        -1.7300e-02, -1.0169e-01, -6.9428e-02, -1.1600e-01, -2.2840e+01,\n",
      "        -2.3015e+01, -1.5669e+00, -8.1312e+00, -2.0422e-02, -9.4101e+00,\n",
      "         1.9208e+00, -2.8239e+01,  5.2740e+00, -3.1246e-03, -1.3487e+01,\n",
      "        -2.7893e-02, -2.1353e+01, -5.9261e-03, -3.9609e-02,  3.1836e+00,\n",
      "        -7.4617e+00, -2.9714e-02, -8.1806e+00,  1.0016e+00, -1.4605e-01,\n",
      "        -1.1631e+01, -3.5175e-01,  5.2783e-01, -2.1849e+01, -4.8852e-04,\n",
      "        -3.3225e+00, -1.3088e-02, -4.2932e-02, -5.0377e-02, -2.8712e-01,\n",
      "        -1.6982e-01, -8.0181e-03, -2.1356e+01, -2.7210e+01, -1.6425e+01,\n",
      "        -5.4129e-03, -1.0004e+01, -5.6718e-02, -3.3988e+01, -9.3065e-03,\n",
      "        -4.4174e+01, -2.7365e+01, -5.6603e-02, -7.8732e-02, -1.2979e-02,\n",
      "        -2.0721e-03,  5.4754e+00, -1.6310e-02, -1.9158e-02, -1.3343e-01,\n",
      "        -2.2055e+01, -5.4960e-03, -1.1841e-01, -1.7371e-01, -2.6835e+01,\n",
      "        -4.2146e-01, -3.8865e+01, -1.6835e-02, -3.8272e-02, -5.3164e-03,\n",
      "        -7.2038e-02, -6.7748e-03, -3.4966e+00, -4.9043e+01, -2.1652e-02,\n",
      "        -2.3756e+01, -1.7601e-03, -3.1562e-04, -5.4869e-03, -2.9494e+01,\n",
      "        -8.4148e-02, -7.5544e-02,  2.1318e+00,  5.4034e+00, -3.2233e-01,\n",
      "        -1.6656e+00, -1.0048e-01, -3.3195e+01, -2.0679e-04, -9.7036e-03,\n",
      "         7.7589e+00,  3.9832e+00, -8.1397e-01,  3.7348e+00, -1.0710e+00,\n",
      "        -2.6043e+00, -1.4920e-01, -4.6981e+01, -1.8820e+01, -1.2138e+01,\n",
      "        -1.1606e-01, -1.4857e+01, -9.5786e-03, -1.1626e-01, -9.4138e-02,\n",
      "        -5.4162e+00,  5.7979e+00, -7.0764e-03, -4.0097e+00, -2.5350e-02,\n",
      "        -1.2499e-01, -3.7812e+00, -1.7555e-02, -2.9450e-02, -2.1455e-02,\n",
      "        -6.6071e+00, -1.9376e+01, -1.3931e-02, -1.7941e-02, -3.1555e-02,\n",
      "        -9.0822e+00, -5.8949e-02, -9.6663e-03, -1.3793e-02, -6.1557e-02,\n",
      "        -1.9386e-02, -2.1699e+01, -2.7800e+01, -1.5425e+01, -2.0690e-02,\n",
      "         8.3228e-01, -3.1594e-02, -2.3063e+00, -8.1577e-02, -7.2906e-02,\n",
      "        -9.7777e-04, -4.3135e-03, -1.2861e+01, -2.6729e+01, -1.9218e-02,\n",
      "        -5.0237e-02, -2.6791e-02, -6.1263e+01, -1.2373e-01, -1.7021e+00,\n",
      "        -4.0137e+01, -4.1456e+01, -1.7290e+01, -1.9745e-04, -7.0140e-02,\n",
      "        -2.6622e-01, -2.9028e-01,  3.2549e+00, -2.3326e-01, -1.1320e+01,\n",
      "        -6.9883e-01,  2.5417e+00, -3.0419e-02, -1.7212e+01, -2.6245e-02,\n",
      "        -2.9321e+01, -1.4637e+01, -7.9100e-02, -2.2546e+01, -1.0056e-01,\n",
      "        -5.8448e+01, -1.7389e-03, -2.9043e-02, -3.0171e-02, -1.7326e-02,\n",
      "         1.0022e+01, -2.7687e+01,  1.5847e+00, -2.2766e+01, -1.4917e-03,\n",
      "        -1.6714e+01, -1.1733e+01, -1.2699e-01,  3.3939e+00, -1.1595e+01,\n",
      "        -7.2548e+00, -2.6217e-02, -3.6166e-03, -1.9010e+01, -1.4976e-03,\n",
      "        -1.1142e+01, -5.6947e-02, -5.4505e+01, -2.7794e-02, -1.9196e+01,\n",
      "        -3.9491e-02, -1.8749e-02, -4.5711e+01, -6.0051e+00, -1.0996e-01,\n",
      "         1.8239e+00, -3.7252e+01,  2.2072e+00, -1.4785e-01, -7.3168e+00,\n",
      "         8.8415e+00, -2.6874e-03, -6.6969e-02, -2.0006e+00, -1.3804e+01,\n",
      "        -5.7076e-03, -1.6034e-01,  2.9908e+00, -2.2363e-02, -2.8111e-02,\n",
      "        -7.1726e+01, -5.8786e-03, -1.4705e+00, -3.4690e+01, -1.9107e-02,\n",
      "        -8.0463e-02, -2.5798e+01, -4.3862e-01, -2.9378e+01, -3.5728e+01,\n",
      "        -3.3814e+01, -2.8841e+01, -5.4282e-02,  7.0825e-01,  5.7636e-01,\n",
      "         5.9323e+00, -1.2470e-01, -1.5782e-01, -1.6854e+01, -2.7604e+01,\n",
      "        -1.1100e+01,  4.4900e+00, -3.0914e+01, -1.4254e-01, -3.3624e+00,\n",
      "        -8.7910e-03, -2.2529e+01,  6.1297e+00, -8.3960e-01, -4.8778e+00,\n",
      "        -4.8866e+01, -2.5320e+00, -8.7523e+00,  2.9414e+00, -3.4023e-01,\n",
      "        -1.4697e+01, -3.2004e+01, -2.9317e+01, -2.2759e-02, -1.6368e-01,\n",
      "        -8.8257e-02, -5.5036e-02, -6.6863e-02, -7.6468e-02, -5.3430e-02,\n",
      "        -2.2487e-02, -5.7226e+00, -5.4211e+00, -9.3877e-02, -2.8379e-02,\n",
      "        -5.8593e-01, -5.2370e-02, -9.9621e-03, -1.2890e-02, -2.9831e+01,\n",
      "        -4.4784e-03, -4.5566e-02, -2.1780e-02, -3.4087e+00, -8.0248e+00,\n",
      "        -2.5174e-02, -4.9669e+00, -2.7941e-02, -1.0846e-01, -6.9378e-03,\n",
      "        -1.4446e+01, -2.0587e+00, -5.0468e+00, -8.8079e-02, -9.5588e-02,\n",
      "        -1.6554e+01, -3.8495e+01, -1.3147e-01, -7.6171e-02, -2.0986e-02,\n",
      "        -2.9334e-02, -5.0100e-02, -2.4860e-01, -2.2259e+01, -1.6766e+01,\n",
      "         4.7134e+00,  1.2662e+00, -2.7355e-02,  1.7451e+00, -8.3236e-03,\n",
      "         3.2419e+00,  3.3361e+00,  9.2512e-01, -4.9723e-03, -3.6270e+01,\n",
      "        -8.2219e+00, -1.9008e-02, -8.7200e-02, -7.1611e+00, -2.9268e-02,\n",
      "        -8.8934e-03, -1.3106e+00,  4.0494e+00, -1.4255e-01, -3.8819e+01,\n",
      "        -1.0030e+01, -7.8578e+00, -5.6041e-02, -5.7508e+00, -2.6766e-02,\n",
      "         7.7839e+00, -3.2215e+01,  5.3719e+00, -4.2847e+00, -5.2835e-02,\n",
      "        -2.0269e+01, -6.7050e-02, -1.9654e+01, -4.7261e-02, -1.2309e-01,\n",
      "         8.5878e+00, -9.3392e+00, -7.4217e-01, -2.8987e+01, -1.7760e-02,\n",
      "        -7.7446e-02, -4.1240e+01, -2.8200e+01, -5.8427e-02, -1.1721e+01,\n",
      "        -3.5836e-01,  2.7074e+00, -8.9659e-03, -1.2549e-01, -4.1388e-04,\n",
      "        -3.8218e+01, -4.8723e+00, -1.3110e-01, -1.0295e-01, -2.0819e-02,\n",
      "        -5.2138e+01,  5.0456e+00, -1.1724e+01, -5.3761e+00, -8.6885e-03,\n",
      "        -2.6452e+01, -1.4879e+01, -6.7790e-03, -2.9986e+00, -6.5284e+00,\n",
      "        -2.1440e+01, -5.2396e-02, -7.6527e+00, -5.2667e-02, -2.3074e+01,\n",
      "        -1.3421e-02, -2.6805e-02, -4.2194e+00, -6.2448e-03, -3.8546e+01,\n",
      "        -3.6270e+01, -7.2924e-03, -7.9852e-01, -2.3067e-02, -1.7680e-02,\n",
      "         8.4932e-01, -1.0202e-01, -2.3052e-02, -7.0433e+00, -2.5420e+00,\n",
      "        -4.3844e+01, -4.1406e+01, -1.1545e-01, -2.6669e-02, -1.1577e-02,\n",
      "        -1.0016e+01, -1.6861e-02, -2.8628e-02, -1.1877e-02, -1.9288e+01,\n",
      "        -2.7263e-02, -5.2721e-02, -1.2457e-01, -1.8096e-01, -1.2873e-02,\n",
      "        -2.1107e-02, -4.6332e+01, -2.5059e+01, -9.4041e+00,  4.8116e+00,\n",
      "        -8.9822e+00, -2.6553e+01, -3.4529e+01, -5.0340e+00, -6.8928e-01,\n",
      "        -3.9534e-04, -7.5622e+00, -1.1093e-01, -1.5859e+01, -1.4925e+01,\n",
      "         4.3148e+00, -2.6900e-02, -2.9798e-02, -1.3427e-01, -1.6915e-01,\n",
      "        -1.9695e-02, -1.3017e-02,  3.5547e+00, -1.6429e+01, -3.8457e-03,\n",
      "        -5.1834e-01, -3.5975e+01, -1.1077e+01, -2.4050e-02,  7.4830e-01,\n",
      "        -9.9746e-03, -4.4852e-03, -1.2473e+01, -2.8929e+01, -3.9641e+01,\n",
      "        -5.5664e-03, -2.6683e+01, -4.1503e+01, -6.0708e+00, -2.5959e+01,\n",
      "        -6.8556e-03, -2.9012e+01, -2.4533e-02, -7.8032e-03, -1.1906e-01,\n",
      "        -3.1593e-02, -1.9574e-02, -7.7392e+00, -6.4157e-02, -2.3429e+01,\n",
      "        -5.3884e+00, -6.2549e-01, -3.8080e+01, -9.1217e-02, -6.3290e+00,\n",
      "         1.6585e+00, -8.8230e-02, -9.1204e+00, -2.0434e-02, -1.9077e-01,\n",
      "        -2.8203e-02, -2.3720e-02, -6.3358e-02,  6.0786e+00, -2.0417e-01,\n",
      "        -3.4229e+01, -1.9179e+01, -4.8031e+01, -3.0686e-02, -1.1808e-02,\n",
      "        -3.4576e+01, -6.7233e-03, -9.1998e+00, -2.6225e+01, -3.6292e-03,\n",
      "        -7.6266e-02, -1.6203e+01,  3.8237e+00, -4.8052e-01, -3.4862e+01,\n",
      "        -3.6784e-02,  2.4865e+00, -1.1240e-02, -2.8898e-02, -2.7445e-02,\n",
      "        -1.1101e-02, -1.2958e+01, -9.0956e-02, -1.7202e+00, -1.7010e-02,\n",
      "        -4.7886e-03, -8.2721e-02,  7.8849e-01, -2.3136e-02, -5.3303e+00,\n",
      "        -1.5044e+01, -2.7751e-02, -1.4851e-02,  4.5962e+00,  4.7326e+00,\n",
      "        -2.4700e+01, -4.2956e-03, -1.2435e-01, -4.6786e+00, -1.2951e-01,\n",
      "        -5.1769e-02, -1.1689e+01, -9.3075e-02, -5.6058e-02, -1.7084e-01,\n",
      "        -8.8310e-02, -1.4313e-01, -7.9282e-03, -1.7219e-02,  3.6804e+00,\n",
      "         1.2412e+00, -1.5927e-02, -4.0265e+01, -4.8566e-02, -1.3228e-02,\n",
      "         4.0576e+00, -1.6917e-02, -6.8656e-03, -8.0865e-04, -8.1227e+00,\n",
      "        -4.2985e+01, -7.3924e+01, -8.6618e+00, -6.0316e-02, -3.0494e+00,\n",
      "        -2.9266e-02, -1.1936e+01, -9.1386e+00, -3.0296e-02, -3.8963e-01,\n",
      "        -2.8803e-02, -1.1305e-01,  4.8450e-01, -7.3155e+00,  6.0798e-01,\n",
      "         1.8356e+00, -3.1534e+01, -5.7518e-02, -9.7937e-02, -1.1360e+01,\n",
      "        -3.8860e+01, -1.1116e-01, -3.2101e-02, -9.3581e+00, -2.0314e+01,\n",
      "        -8.7460e-02, -3.0601e-02,  3.7681e+00, -3.0314e+01, -1.5638e-02,\n",
      "        -2.6502e+01, -2.2584e+01, -1.4015e-02, -1.8879e-02, -3.4261e+01,\n",
      "        -3.5463e-02,  6.2306e+00, -5.2292e-02,  2.6094e+00, -1.2706e-01,\n",
      "        -5.5872e-02,  7.8375e+00, -8.3426e-03, -4.9410e+01, -4.1551e-02,\n",
      "        -3.3034e+01, -5.3437e-02, -1.7527e-01, -1.4087e-03, -8.3710e-02,\n",
      "        -2.8278e-02, -1.7485e+01, -2.9423e-02, -2.2632e-03, -1.5662e+01,\n",
      "        -1.8720e-02, -1.8492e-03, -1.6855e-02, -9.8357e-02, -2.0387e+01,\n",
      "        -9.6736e-03, -3.0885e+00, -2.4467e+01, -2.3643e-02, -2.2985e+01,\n",
      "        -3.5305e+01, -8.8584e-02, -1.2586e-02, -4.9925e+00, -1.1566e-02,\n",
      "        -2.7862e+01, -3.1564e+01, -8.2111e-02, -8.6657e-02, -1.3616e+01,\n",
      "        -1.4031e+01, -2.6021e+01, -1.1313e-02, -3.6664e-01, -3.1939e-02,\n",
      "        -2.9538e-02, -1.4323e-02, -6.2403e+00, -6.9850e+01, -6.4997e-02,\n",
      "        -7.6601e-02, -1.2489e+01, -2.8044e-02,  2.0405e+00, -3.1736e-01,\n",
      "        -4.2650e-02, -1.8287e-02, -1.8866e-02, -1.8893e-02, -4.0966e+01,\n",
      "        -5.1310e-02, -2.9522e-02, -7.6389e+00, -2.5364e+01, -1.9879e-01,\n",
      "        -5.0505e-02, -1.4826e+01, -6.8930e+00, -8.3712e-02, -4.5901e-03,\n",
      "        -2.0527e-02, -1.9639e+01, -9.7827e+00,  1.6886e+00, -2.6352e+01,\n",
      "         2.0225e+00, -1.3419e-01, -7.8313e-02, -6.0294e+01, -1.1453e-01,\n",
      "        -5.2255e+01, -2.4817e-02, -3.2120e+01, -2.8951e+01, -2.6574e-02,\n",
      "        -5.2215e-01, -7.2843e-02, -3.5581e+01, -1.5018e-02, -1.8109e-01,\n",
      "         2.8251e+00, -1.5428e+01, -2.7997e+01, -2.3715e+01, -1.5880e+01,\n",
      "        -1.9429e+01, -4.5772e-02, -4.5870e+01, -1.6914e-02, -1.1904e+01,\n",
      "        -5.5704e-02, -5.4559e+00, -3.2169e+00, -1.3019e-02, -1.8719e+01],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 3.3731e-02, -6.7781e+01,  1.1424e-02,  ..., -2.3944e+01,\n",
      "         -3.0846e-02, -1.4216e+02],\n",
      "        [ 2.9102e-02, -6.8060e+01,  2.6227e-02,  ..., -2.4034e+01,\n",
      "         -1.7973e-02, -1.4283e+02],\n",
      "        [ 5.4798e-02, -6.8013e+01, -6.9180e-04,  ..., -2.4005e+01,\n",
      "         -1.7680e-02, -1.4265e+02],\n",
      "        ...,\n",
      "        [ 8.0320e-03, -6.8150e+01,  2.9101e-02,  ..., -2.4027e+01,\n",
      "          2.3599e-02, -1.4290e+02],\n",
      "        [ 4.6517e-02, -6.7705e+01,  5.5808e-03,  ..., -2.3893e+01,\n",
      "          2.3755e-03, -1.4202e+02],\n",
      "        [ 6.4631e-02, -6.8019e+01, -1.2911e-02,  ..., -2.4044e+01,\n",
      "         -6.7195e-03, -1.4265e+02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([11.8531, 11.8253, 11.8742, 11.8751, 11.8444, 11.8850, 11.8879, 11.8567,\n",
      "        11.7986, 11.7970, 11.7607], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
